package engine

import (
	"context"
	"fmt"
	"log"
	"reflect"
	"sync"
	"sync/atomic"
	"time"

	"github.com/LENAX/task-engine/pkg/core/cache"
	"github.com/LENAX/task-engine/pkg/core/dag"
	"github.com/LENAX/task-engine/pkg/core/executor"
	"github.com/LENAX/task-engine/pkg/core/saga"
	"github.com/LENAX/task-engine/pkg/core/task"
	"github.com/LENAX/task-engine/pkg/core/types"
	"github.com/LENAX/task-engine/pkg/core/workflow"
	"github.com/LENAX/task-engine/pkg/plugin"
	"github.com/LENAX/task-engine/pkg/storage"
)

// TaskStatusEvent ä»»åŠ¡çŠ¶æ€äº‹ä»¶ï¼ˆé€šè¿‡ channel ä¼ é€’ï¼‰
type TaskStatusEvent struct {
	TaskID      string      // ä»»åŠ¡ID
	Status      string      // Success, Failed, Timeout, subtask_added, ready
	Result      interface{} // ä»»åŠ¡ç»“æœï¼ˆSuccess æ—¶ï¼‰
	Error       error       // é”™è¯¯ä¿¡æ¯ï¼ˆFailed æ—¶ï¼‰
	IsTemplate  bool        // æ˜¯å¦ä¸ºæ¨¡æ¿ä»»åŠ¡
	IsSubTask   bool        // æ˜¯å¦ä¸ºå­ä»»åŠ¡
	ParentID    string      // çˆ¶ä»»åŠ¡IDï¼ˆå­ä»»åŠ¡ç‰¹æœ‰ï¼‰
	IsProcessed bool        // æ˜¯å¦å·²å¤„ç†ï¼ˆé¿å…é‡å¤è®¡æ•°ï¼‰
	Timestamp   time.Time   // äº‹ä»¶æ—¶é—´æˆ³
}

// TaskStatsUpdate ä»»åŠ¡ç»Ÿè®¡æ›´æ–°
type TaskStatsUpdate struct {
	Type       string // task_completed, task_failed, task_added
	TaskID     string
	Status     string
	IsTemplate bool
	IsSubTask  bool
}

// AtomicAddSubTasksEvent åŸå­æ€§å­ä»»åŠ¡æ·»åŠ äº‹ä»¶ï¼ˆåŒ…å«å¤šä¸ªå­ä»»åŠ¡ï¼‰
type AtomicAddSubTasksEvent struct {
	SubTasks  []workflow.Task // å­ä»»åŠ¡åˆ—è¡¨
	ParentID  string          // çˆ¶ä»»åŠ¡ID
	Timestamp time.Time       // äº‹ä»¶æ—¶é—´æˆ³
}

// SubTaskTracker å­ä»»åŠ¡è·Ÿè¸ªå™¨ï¼ˆç”¨äºç»“æœèšåˆï¼‰
type SubTaskTracker struct {
	SubTaskIDs     []string   // å­ä»»åŠ¡ ID åˆ—è¡¨
	CompletedCount int32      // å·²å®Œæˆæ•°é‡ï¼ˆatomicï¼‰
	FailedCount    int32      // å¤±è´¥æ•°é‡ï¼ˆatomicï¼‰
	TotalCount     int32      // æ€»æ•°é‡
	Results        sync.Map   // subTaskID -> SubTaskResult
	mu             sync.Mutex // ä¿æŠ¤ SubTaskIDs çš„å¹¶å‘è®¿é—®
}

// SubTaskResult å­ä»»åŠ¡ç»“æœ
type SubTaskResult struct {
	TaskID   string      // å­ä»»åŠ¡ ID
	TaskName string      // å­ä»»åŠ¡åç§°
	Status   string      // çŠ¶æ€ï¼šSuccess, Failed
	Result   interface{} // ç»“æœæ•°æ®
	Error    string      // é”™è¯¯ä¿¡æ¯ï¼ˆå¤±è´¥æ—¶ï¼‰
}

// LeveledTaskQueue äºŒç»´ä»»åŠ¡é˜Ÿåˆ—ï¼ˆæŒ‰æ‹“æ‰‘å±‚çº§ç»„ç»‡ï¼Œä½¿ç”¨ map[string]Taskï¼‰
type LeveledTaskQueue struct {
	queues        []map[string]workflow.Task // []map[string]Taskï¼Œæ¯ä¸ªå±‚çº§ä¸€ä¸ª map
	currentLevel  int32                      // atomic æ“ä½œï¼Œå½“å‰æ‰§è¡Œå±‚çº§
	maxLevel      int                        // æœ€å¤§å±‚çº§ï¼ˆåˆå§‹åŒ–æ—¶ç¡®å®šï¼‰
	mu            sync.RWMutex               // ä»…ä¿æŠ¤é˜Ÿåˆ—ç»“æ„å˜æ›´ï¼ˆå¾ˆå°‘ä½¿ç”¨ï¼‰
	sizes         []int32                    // atomicï¼Œæ¯ä¸ªå±‚çº§çš„å¾…æäº¤ä»»åŠ¡æ•°é‡
	runningCounts []int32                    // atomicï¼Œæ¯ä¸ªå±‚çº§æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡æ•°é‡
}

// NewLeveledTaskQueue åˆ›å»ºäºŒç»´ä»»åŠ¡é˜Ÿåˆ—ï¼ˆä½¿ç”¨ map[string]Taskï¼‰
func NewLeveledTaskQueue(maxLevel int) *LeveledTaskQueue {
	queues := make([]map[string]workflow.Task, maxLevel)
	sizes := make([]int32, maxLevel)
	runningCounts := make([]int32, maxLevel)
	for i := 0; i < maxLevel; i++ {
		queues[i] = make(map[string]workflow.Task)
	}
	return &LeveledTaskQueue{
		queues:        queues,
		currentLevel:  0,
		maxLevel:      maxLevel,
		sizes:         sizes,
		runningCounts: runningCounts,
	}
}

func (q *LeveledTaskQueue) addTask(level int, task workflow.Task) {
	taskID := task.GetID()

	// æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²ç»å­˜åœ¨äºå½“å‰å±‚çº§çš„é˜Ÿåˆ—ä¸­
	if _, exists := q.queues[level][taskID]; exists {
		return // ä»»åŠ¡å·²å­˜åœ¨äºå½“å‰å±‚çº§ï¼Œä¸é‡å¤æ·»åŠ 
	}

	// æ·»åŠ åˆ°ç›®æ ‡å±‚çº§
	q.queues[level][taskID] = task
	// å…³é”®ï¼šåœ¨é”å†…æ›´æ–° sizesï¼Œç¡®ä¿ä¸é˜Ÿåˆ—çŠ¶æ€ä¸€è‡´ï¼Œé¿å… IsEmpty è¯¯åˆ¤
	atomic.AddInt32(&q.sizes[level], 1)
}

// AddTask æ·»åŠ ä»»åŠ¡åˆ°æŒ‡å®šå±‚çº§ï¼ˆæ— é”ï¼Œé€šè¿‡ channel è°ƒç”¨ï¼‰
func (q *LeveledTaskQueue) AddTask(level int, task workflow.Task) {
	if level < 0 || level >= len(q.queues) {
		return
	}

	q.mu.Lock()
	defer q.mu.Unlock()

	q.addTask(level, task)
}

// AddTasks æ‰¹é‡æ·»åŠ ä»»åŠ¡åˆ°æŒ‡å®šå±‚çº§ï¼ˆæ— é”ï¼Œé€šè¿‡ channel è°ƒç”¨ï¼‰
func (q *LeveledTaskQueue) AddTasks(level int, tasks []workflow.Task) {
	if level < 0 || level >= len(q.queues) || len(tasks) == 0 {
		return
	}

	q.mu.Lock()
	defer q.mu.Unlock()

	for _, task := range tasks {
		q.addTask(level, task)
	}
}

// PopTasks ä»æŒ‡å®šå±‚çº§è·å–å¹¶ç§»é™¤ä»»åŠ¡ï¼ˆæ‰¹é‡è·å–ï¼Œè·å–æ—¶ç›´æ¥ä»é˜Ÿåˆ—ç§»é™¤ï¼‰
// ä»»åŠ¡è¢« Pop åè®¡å…¥ runningCountsï¼Œè¡¨ç¤ºæ­£åœ¨æ‰§è¡Œ
func (q *LeveledTaskQueue) PopTasks(level int, maxCount int) []workflow.Task {
	if level < 0 || level >= len(q.queues) {
		return nil
	}
	queue := q.queues[level]
	q.mu.Lock()
	defer q.mu.Unlock()

	tasks := make([]workflow.Task, 0, maxCount)
	count := 0
	for taskID, task := range queue {
		if count >= maxCount {
			break
		}
		tasks = append(tasks, task)
		delete(queue, taskID)
		atomic.AddInt32(&q.sizes[level], -1)
		atomic.AddInt32(&q.runningCounts[level], 1) // æ ‡è®°ä¸ºæ­£åœ¨æ‰§è¡Œ
		count++
	}
	return tasks
}

// RemoveTask ä»æŒ‡å®šå±‚çº§ç§»é™¤ä»»åŠ¡ï¼ˆO(1) æ—¶é—´å¤æ‚åº¦ï¼‰
func (q *LeveledTaskQueue) RemoveTask(level int, taskID string) {
	if level < 0 || level >= len(q.queues) {
		return
	}
	queue := q.queues[level]
	q.mu.Lock()
	if _, exists := queue[taskID]; exists {
		delete(queue, taskID)
		atomic.AddInt32(&q.sizes[level], -1)
	}
	q.mu.Unlock()
}

// TaskCompleted æ ‡è®°ä»»åŠ¡å®Œæˆï¼Œå‡å°‘ runningCounts
func (q *LeveledTaskQueue) TaskCompleted(level int) {
	if level < 0 || level >= len(q.runningCounts) {
		return
	}
	atomic.AddInt32(&q.runningCounts[level], -1)
}

// IsEmpty æ£€æŸ¥æŒ‡å®šå±‚çº§æ˜¯å¦ä¸ºç©ºï¼ˆåªæ£€æŸ¥å¾…æäº¤é˜Ÿåˆ—ï¼‰
func (q *LeveledTaskQueue) IsEmpty(level int) bool {
	if level < 0 || level >= len(q.queues) {
		return true
	}
	q.mu.Lock()
	defer q.mu.Unlock()
	return len(q.queues[level]) == 0
}

// IsLevelComplete æ£€æŸ¥æŒ‡å®šå±‚çº§æ˜¯å¦å®Œå…¨å®Œæˆï¼ˆé˜Ÿåˆ—ä¸ºç©ºä¸”æ— æ‰§è¡Œä¸­ä»»åŠ¡ï¼‰
func (q *LeveledTaskQueue) IsLevelComplete(level int) bool {
	if level < 0 || level >= len(q.queues) {
		return true
	}
	q.mu.Lock()
	isEmpty := len(q.queues[level]) == 0
	q.mu.Unlock()
	runningCount := atomic.LoadInt32(&q.runningCounts[level])
	return isEmpty && runningCount == 0
}

// GetRunningCount è·å–æŒ‡å®šå±‚çº§çš„æ‰§è¡Œä¸­ä»»åŠ¡æ•°
func (q *LeveledTaskQueue) GetRunningCount(level int) int32 {
	if level < 0 || level >= len(q.runningCounts) {
		return 0
	}
	return atomic.LoadInt32(&q.runningCounts[level])
}

// GetTaskIDsAtLevel è¿”å›æŒ‡å®šå±‚çº§é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡ ID åˆ—è¡¨ï¼ˆç”¨äºè¿›åº¦ API æš´éœ²å¾…æ‰§è¡Œä»»åŠ¡ï¼‰
func (q *LeveledTaskQueue) GetTaskIDsAtLevel(level int) []string {
	if level < 0 || level >= len(q.queues) {
		return nil
	}
	q.mu.Lock()
	defer q.mu.Unlock()
	queue := q.queues[level]
	ids := make([]string, 0, len(queue))
	for taskID := range queue {
		ids = append(ids, taskID)
	}
	return ids
}

// GetCurrentLevel è·å–å½“å‰å±‚çº§ï¼ˆatomic è¯»å–ï¼‰
func (q *LeveledTaskQueue) GetCurrentLevel() int {
	return int(atomic.LoadInt32(&q.currentLevel))
}

// AdvanceLevel æ¨è¿›å±‚çº§ï¼ˆatomic æ“ä½œï¼‰
func (q *LeveledTaskQueue) AdvanceLevel() {
	atomic.AddInt32(&q.currentLevel, 1)
}

// GetMaxLevel è·å–æœ€å¤§å±‚çº§ï¼ˆç”¨äºå¤–éƒ¨è®¿é—®ï¼‰
func (q *LeveledTaskQueue) GetMaxLevel() int {
	return q.maxLevel
}

// IsAllTasksCompleted åˆ¤æ–­æ˜¯å¦æ‰€æœ‰ä»»åŠ¡éƒ½å·²å®Œæˆ
// æ¡ä»¶ï¼šcurrentLevel >= len(queues) ä¸”æ‰€æœ‰é˜Ÿåˆ—éƒ½ä¸ºç©º
func (q *LeveledTaskQueue) IsAllTasksCompleted() (bool, error) {
	currentLevel := q.GetCurrentLevel()
	queueCount := len(q.queues)

	// å¦‚æœ currentLevel >= queueCountï¼Œè¯´æ˜å·²ç»å¤„ç†å®Œæ‰€æœ‰å±‚çº§
	if currentLevel >= queueCount {
		// æ£€æŸ¥æ‰€æœ‰é˜Ÿåˆ—æ˜¯å¦éƒ½ä¸ºç©º
		for i := 0; i < queueCount; i++ {
			if !q.IsEmpty(i) {
				// å¼‚å¸¸æƒ…å†µï¼šcurrentLevel >= queueCount ä½†é˜Ÿåˆ—ä¸æ˜¯ç©ºçš„
				return false, fmt.Errorf("å¼‚å¸¸ï¼šcurrentLevel (%d) >= queueCount (%d) ä½†é˜Ÿåˆ— level %d ä¸ä¸ºç©º",
					currentLevel, queueCount, i)
			}
		}
		// æ‰€æœ‰é˜Ÿåˆ—éƒ½ä¸ºç©ºï¼Œä»»åŠ¡å…¨éƒ¨å®Œæˆ
		return true, nil
	}

	// currentLevel < queueCountï¼Œè¿˜æœ‰ä»»åŠ¡æœªå®Œæˆ
	return false, nil
}

// TaskStatistics ä»»åŠ¡ç»Ÿè®¡ï¼ˆé€šè¿‡ channel æ›´æ–°ï¼Œé¿å…é”ï¼‰
type TaskStatistics struct {
	TotalTasks    int32 // atomicï¼Œæ€»ä»»åŠ¡æ•°
	StaticTasks   int32 // atomicï¼Œé™æ€ä»»åŠ¡æ•°
	SubTasks      int32 // atomicï¼Œå­ä»»åŠ¡æ•°
	SuccessTasks  int32 // atomicï¼ŒæˆåŠŸä»»åŠ¡æ•°
	FailedTasks   int32 // atomicï¼Œå¤±è´¥ä»»åŠ¡æ•°
	PendingTasks  int32 // atomicï¼Œç­‰å¾…ä»»åŠ¡æ•°
	TemplateTasks int32 // atomicï¼Œæ¨¡æ¿ä»»åŠ¡æ•°ï¼ˆå½“å‰å±‚çº§ï¼‰
}

// Update æ›´æ–°ç»Ÿè®¡ï¼ˆatomic æ“ä½œï¼‰
func (s *TaskStatistics) Update(update TaskStatsUpdate) {
	switch update.Type {
	case "task_completed":
		atomic.AddInt32(&s.SuccessTasks, 1)
		atomic.AddInt32(&s.PendingTasks, -1)
	case "task_failed":
		atomic.AddInt32(&s.FailedTasks, 1)
		atomic.AddInt32(&s.PendingTasks, -1)
	case "task_added":
		atomic.AddInt32(&s.TotalTasks, 1)
		atomic.AddInt32(&s.PendingTasks, 1)
		if update.IsSubTask {
			atomic.AddInt32(&s.SubTasks, 1)
		} else {
			atomic.AddInt32(&s.StaticTasks, 1)
		}
		if update.IsTemplate {
			atomic.AddInt32(&s.TemplateTasks, 1)
		}
	}
}

// éªŒè¯ç»Ÿè®¡æ•°æ˜¯å¦ä¸€è‡´ï¼š
// æ€»ä»»åŠ¡æ•° = é™æ€ä»»åŠ¡æ•° + å­ä»»åŠ¡æ•° = æˆåŠŸä»»åŠ¡æ•° + å¤±è´¥ä»»åŠ¡æ•° + ç­‰å¾…ä»»åŠ¡æ•°
func (s *TaskStatistics) Validate() bool {
	total := atomic.LoadInt32(&s.TotalTasks)
	static := atomic.LoadInt32(&s.StaticTasks)
	sub := atomic.LoadInt32(&s.SubTasks)
	success := atomic.LoadInt32(&s.SuccessTasks)
	failed := atomic.LoadInt32(&s.FailedTasks)
	pending := atomic.LoadInt32(&s.PendingTasks)

	// æ€»æ•° = é™æ€ä»»åŠ¡æ•° + å­ä»»åŠ¡æ•°
	match1 := total == (static + sub)
	if !match1 {
		return false
	}

	// æ€»æ•° = æˆåŠŸ + å¤±è´¥ + ç­‰å¾…
	match2 := total == (success + failed + pending)
	if !match2 {
		return false
	}

	return true
}

// WorkflowInstanceManagerV2 æ–°ç‰ˆWorkflowInstanceManagerï¼ˆåŸºäºç”Ÿäº§è€…æ¶ˆè´¹è€…æ¨¡å‹ï¼‰
type WorkflowInstanceManagerV2 struct {
	// åŸæœ‰å­—æ®µ
	instance             *workflow.WorkflowInstance
	workflow             *workflow.Workflow
	dag                  dag.DAG
	executor             executor.Executor
	aggregateRepo        storage.WorkflowAggregateRepository // èšåˆRepositoryï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
	taskRepo             storage.TaskRepository
	workflowInstanceRepo storage.WorkflowInstanceRepository
	registry             task.FunctionRegistry
	resultCache          cache.ResultCache
	ctx                  context.Context
	cancel               context.CancelFunc
	wg                   sync.WaitGroup

	// æ–°å¢ï¼šé€šé“é€šä¿¡ï¼ˆæ— é”ï¼‰
	taskStatusChan     chan TaskStatusEvent        // Executor -> Observer
	queueUpdateChan    chan TaskStatusEvent        // Observer -> QueueManager
	addSubTaskChan     chan AtomicAddSubTasksEvent // AddSubTask -> QueueManagerï¼ˆå­ä»»åŠ¡æ·»åŠ ä¸“ç”¨é€šé“ï¼Œæ”¯æŒæ‰¹é‡ï¼‰
	taskSubmissionChan chan []workflow.Task        // QueueManager -> Submission
	taskStatsChan      chan TaskStatsUpdate        // Observer -> Statistics

	// è¿è¡Œæ—¶ä»»åŠ¡å­˜å‚¨ï¼ˆåŠ¨æ€æ·»åŠ çš„å­ä»»åŠ¡ï¼Œä¸å­˜å‚¨åœ¨ workflow ä¸­ï¼‰
	runtimeTasks sync.Map // taskID -> workflow.Taskï¼ˆå­ä»»åŠ¡å­˜å‚¨ï¼‰

	// å­ä»»åŠ¡è·Ÿè¸ªå™¨ï¼ˆç”¨äºç»“æœèšåˆï¼ŒparentTaskID -> *SubTaskTrackerï¼‰
	subTaskTracker sync.Map

	// æ–°å¢ï¼šé˜Ÿåˆ—ç»“æ„
	taskQueue          *LeveledTaskQueue
	taskStats          *TaskStatistics
	templateTaskCounts []atomic.Int32 // æ¯å±‚çš„æ¨¡æ¿ä»»åŠ¡æ•°é‡ï¼ˆåˆå§‹åŒ–æ—¶ç»Ÿè®¡ï¼‰
	templateTaskCount  atomic.Int32   // å½“å‰å±‚çº§çš„æ¨¡æ¿ä»»åŠ¡è®¡æ•°å™¨ï¼ˆä» templateTaskCounts[currentLevel] åˆå§‹åŒ–ï¼‰

	// ä»»åŠ¡å®Œæˆæ£€æŸ¥ä¼˜åŒ–
	lastCompletionCheck int64 // atomicï¼Œä¸Šæ¬¡å®Œæˆæ£€æŸ¥çš„æ—¶é—´æˆ³ï¼ˆçº³ç§’ï¼‰ï¼Œç”¨äºå‡å°‘æ£€æŸ¥é¢‘ç‡

	contextData    sync.Map // ä¸Šä¸‹æ–‡æ•°æ®
	processedNodes sync.Map // å·²å¤„ç†ä»»åŠ¡æ ‡è®°ï¼ˆtaskID -> boolï¼‰
	runningTaskIDs sync.Map // æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡ IDï¼ˆtaskID -> struct{}ï¼‰ï¼Œç”¨äº GetProgress æš´éœ²æœªå®Œæˆä»»åŠ¡

	// å±‚çº§æ¨è¿›é”ï¼ˆä¿æŠ¤å±‚çº§æ¨è¿›çš„åŸå­æ€§ï¼‰
	levelAdvanceMu sync.Mutex // ä¿æŠ¤ canAdvanceLevel æ£€æŸ¥å’Œ advanceLevel æ‰§è¡Œçš„åŸå­æ€§

	// æ§åˆ¶ä¿¡å·ï¼ˆä¿ç•™ï¼‰
	controlSignalChan chan workflow.ControlSignal
	statusUpdateChan  chan string
	mu                sync.RWMutex // ä»…ä¿æŠ¤ instance çŠ¶æ€

	// SAGAäº‹åŠ¡åè°ƒå™¨ï¼ˆå¯é€‰ï¼Œæ¥å£ç±»å‹ï¼‰
	sagaCoordinator saga.Coordinator
	sagaEnabled     bool // æ˜¯å¦å¯ç”¨SAGA

	// æ’ä»¶ç®¡ç†å™¨ï¼ˆå¯é€‰ï¼Œæ¥å£ç±»å‹ï¼‰
	pluginManager plugin.PluginManager
}

// NewWorkflowInstanceManagerV2 åˆ›å»ºWorkflowInstanceManagerV2å®ä¾‹
func NewWorkflowInstanceManagerV2(
	instance *workflow.WorkflowInstance,
	wf *workflow.Workflow,
	exec executor.Executor,
	taskRepo storage.TaskRepository,
	workflowInstanceRepo storage.WorkflowInstanceRepository,
	registry task.FunctionRegistry,
	pluginManager plugin.PluginManager,
) (*WorkflowInstanceManagerV2, error) {
	// æ„å»ºDAG
	dagInstance, err := dag.BuildDAG(wf.GetTasks(), wf.GetDependencies())
	if err != nil {
		return nil, err
	}

	// æ£€æµ‹å¾ªç¯ä¾èµ–
	if err := dagInstance.DetectCycle(); err != nil {
		return nil, err
	}

	ctx, cancel := context.WithCancel(context.Background())

	// è®¡ç®—æ€»ä»»åŠ¡æ•°ï¼ˆç”¨äºè®¾ç½® channel å®¹é‡ï¼‰
	totalTasks := len(wf.GetTasks())
	channelCapacity := totalTasks * 2 // channel å®¹é‡ä¸ºæ€»ä»»åŠ¡æ•°é‡çš„ä¸¤å€
	if channelCapacity < 100 {
		channelCapacity = 100 // æœ€å°å®¹é‡ 100ï¼Œé¿å…è¿‡å°
	}

	// æ£€æŸ¥æ˜¯å¦éœ€è¦å¯ç”¨SAGAï¼ˆå¦‚æœæœ‰ä»»åŠ¡é…ç½®äº†è¡¥å¿å‡½æ•°ï¼‰
	sagaEnabled := false
	for _, t := range wf.GetTasks() {
		if t.GetCompensationFuncName() != "" {
			sagaEnabled = true
			break
		}
	}

	// å¦‚æœå¯ç”¨SAGAï¼Œåˆ›å»ºåè°ƒå™¨
	var sagaCoordinator saga.Coordinator
	if sagaEnabled && registry != nil {
		sagaCoordinator = saga.NewCoordinator(instance.ID, registry)
		log.Printf("WorkflowInstance %s: SAGAäº‹åŠ¡å·²å¯ç”¨", instance.ID)
	}

	manager := &WorkflowInstanceManagerV2{
		instance:             instance,
		workflow:             wf,
		dag:                  dagInstance,
		executor:             exec,
		taskRepo:             taskRepo,
		workflowInstanceRepo: workflowInstanceRepo,
		registry:             registry,
		resultCache:          cache.NewMemoryResultCache(),
		ctx:                  ctx,
		cancel:               cancel,

		// åˆå§‹åŒ– channelï¼ˆå®¹é‡ä¸ºæ€»ä»»åŠ¡æ•°é‡çš„ä¸¤å€ï¼‰
		taskStatusChan:     make(chan TaskStatusEvent, channelCapacity),
		queueUpdateChan:    make(chan TaskStatusEvent, channelCapacity),
		addSubTaskChan:     make(chan AtomicAddSubTasksEvent, channelCapacity), // å­ä»»åŠ¡æ·»åŠ ä¸“ç”¨é€šé“ï¼Œæ”¯æŒæ‰¹é‡
		taskSubmissionChan: make(chan []workflow.Task, channelCapacity),
		taskStatsChan:      make(chan TaskStatsUpdate, channelCapacity),

		// åˆå§‹åŒ–å…¶ä»–å­—æ®µ
		taskStats:         &TaskStatistics{},
		controlSignalChan: make(chan workflow.ControlSignal, 10),
		statusUpdateChan:  make(chan string, 10),
		sagaCoordinator:   sagaCoordinator,
		sagaEnabled:       sagaEnabled,
		pluginManager:     pluginManager,
	}

	log.Printf("WorkflowInstance %s: V2åˆå§‹åŒ–å®Œæˆï¼Œæ€»ä»»åŠ¡æ•°: %dï¼ŒChannel å®¹é‡: %d",
		instance.ID, totalTasks, channelCapacity)

	// åœ¨åˆå§‹åŒ–æ—¶æ³¨å†Œ InstanceManagerInterfaceV2 åˆ° registryï¼ˆåªæ³¨å†Œä¸€æ¬¡ï¼‰
	if registry != nil {
		managerInterface := &InstanceManagerInterfaceV2{
			manager: manager,
		}
		_ = registry.RegisterDependencyWithKey("InstanceManager", managerInterface)
	}

	return manager, nil
}

// NewWorkflowInstanceManagerV2WithAggregate åˆ›å»ºWorkflowInstanceManagerV2å®ä¾‹ï¼ˆä½¿ç”¨èšåˆRepositoryï¼‰
// aggregateRepo: èšåˆRepositoryï¼Œä¼˜å…ˆä½¿ç”¨ï¼Œç»Ÿä¸€ç®¡ç†äº‹åŠ¡æ“ä½œ
// taskRepo, workflowInstanceRepo: å…¼å®¹æ—§ç‰ˆRepositoryï¼Œå½“aggregateRepoä¸ºnilæ—¶ä½¿ç”¨
func NewWorkflowInstanceManagerV2WithAggregate(
	instance *workflow.WorkflowInstance,
	wf *workflow.Workflow,
	exec executor.Executor,
	aggregateRepo storage.WorkflowAggregateRepository,
	taskRepo storage.TaskRepository,
	workflowInstanceRepo storage.WorkflowInstanceRepository,
	registry task.FunctionRegistry,
	pluginManager plugin.PluginManager,
) (*WorkflowInstanceManagerV2, error) {
	// æ„å»ºDAG
	dagInstance, err := dag.BuildDAG(wf.GetTasks(), wf.GetDependencies())
	if err != nil {
		return nil, err
	}

	// æ£€æµ‹å¾ªç¯ä¾èµ–
	if err := dagInstance.DetectCycle(); err != nil {
		return nil, err
	}

	ctx, cancel := context.WithCancel(context.Background())

	// è®¡ç®—æ€»ä»»åŠ¡æ•°ï¼ˆç”¨äºè®¾ç½® channel å®¹é‡ï¼‰
	totalTasks := len(wf.GetTasks())
	channelCapacity := totalTasks * 2
	if channelCapacity < 100 {
		channelCapacity = 100
	}

	// æ£€æŸ¥æ˜¯å¦éœ€è¦å¯ç”¨SAGA
	sagaEnabled := false
	for _, t := range wf.GetTasks() {
		if t.GetCompensationFuncName() != "" {
			sagaEnabled = true
			break
		}
	}

	// å¦‚æœå¯ç”¨SAGAï¼Œåˆ›å»ºåè°ƒå™¨
	var sagaCoordinator saga.Coordinator
	if sagaEnabled && registry != nil {
		sagaCoordinator = saga.NewCoordinator(instance.ID, registry)
		log.Printf("WorkflowInstance %s: SAGAäº‹åŠ¡å·²å¯ç”¨", instance.ID)
	}

	manager := &WorkflowInstanceManagerV2{
		instance:             instance,
		workflow:             wf,
		dag:                  dagInstance,
		executor:             exec,
		aggregateRepo:        aggregateRepo, // è®¾ç½®èšåˆRepository
		taskRepo:             taskRepo,
		workflowInstanceRepo: workflowInstanceRepo,
		registry:             registry,
		resultCache:          cache.NewMemoryResultCache(),
		ctx:                  ctx,
		cancel:               cancel,

		taskStatusChan:     make(chan TaskStatusEvent, channelCapacity),
		queueUpdateChan:    make(chan TaskStatusEvent, channelCapacity),
		addSubTaskChan:     make(chan AtomicAddSubTasksEvent, channelCapacity),
		taskSubmissionChan: make(chan []workflow.Task, channelCapacity),
		taskStatsChan:      make(chan TaskStatsUpdate, channelCapacity),

		taskStats:         &TaskStatistics{},
		controlSignalChan: make(chan workflow.ControlSignal, 10),
		statusUpdateChan:  make(chan string, 10),
		sagaCoordinator:   sagaCoordinator,
		sagaEnabled:       sagaEnabled,
		pluginManager:     pluginManager,
	}

	log.Printf("WorkflowInstance %s: V2åˆå§‹åŒ–å®Œæˆï¼ˆèšåˆRepositoryæ¨¡å¼ï¼‰ï¼Œæ€»ä»»åŠ¡æ•°: %dï¼ŒChannel å®¹é‡: %d",
		instance.ID, totalTasks, channelCapacity)

	// åœ¨åˆå§‹åŒ–æ—¶æ³¨å†Œ InstanceManagerInterfaceV2 åˆ° registryï¼ˆåªæ³¨å†Œä¸€æ¬¡ï¼‰
	if registry != nil {
		managerInterface := &InstanceManagerInterfaceV2{
			manager: manager,
		}
		_ = registry.RegisterDependencyWithKey("InstanceManager", managerInterface)
	}

	return manager, nil
}

// Start å¯åŠ¨WorkflowInstanceæ‰§è¡Œï¼ˆå…¬å…±æ–¹æ³•ï¼Œå®ç°æ¥å£ï¼‰
func (m *WorkflowInstanceManagerV2) Start() {
	// æ›´æ–°çŠ¶æ€ä¸ºRunning
	m.mu.Lock()
	m.instance.Status = "Running"
	m.instance.StartTime = time.Now()
	m.mu.Unlock()

	// æŒä¹…åŒ–çŠ¶æ€
	ctx := context.Background()
	if err := m.updateWorkflowInstanceStatus(ctx, m.instance.ID, "Running", ""); err != nil {
		log.Printf("æ›´æ–°WorkflowInstanceçŠ¶æ€å¤±è´¥: %v", err)
	}

	// å‘é€çŠ¶æ€æ›´æ–°é€šçŸ¥
	select {
	case m.statusUpdateChan <- "Running":
	default:
		log.Printf("è­¦å‘Š: WorkflowInstance %s çŠ¶æ€æ›´æ–°é€šé“å·²æ»¡", m.instance.ID)
	}

	// è§¦å‘Workflowå¯åŠ¨æ’ä»¶
	if m.pluginManager != nil {
		pluginData := plugin.PluginData{
			Event:      plugin.EventWorkflowStarted,
			WorkflowID: m.instance.WorkflowID,
			InstanceID: m.instance.ID,
			TaskID:     "",
			TaskName:   "",
			Status:     "Running",
			Error:      nil,
			Data: map[string]interface{}{
				"workflow_name": m.workflow.Name,
			},
		}
		if err := m.pluginManager.Trigger(m.ctx, plugin.EventWorkflowStarted, pluginData); err != nil {
			log.Printf("è§¦å‘Workflowå¯åŠ¨æ’ä»¶å¤±è´¥: InstanceID=%s, Error=%v", m.instance.ID, err)
		}
	}

	// å¯åŠ¨ä¸‰ä¸ªæ ¸å¿ƒgoroutine
	m.wg.Add(1)
	go func() {
		defer m.wg.Done()
		m.taskObserverGoroutine()
	}()

	m.wg.Add(1)
	go func() {
		defer m.wg.Done()
		m.queueManagerGoroutine()
	}()

	m.wg.Add(1)
	go func() {
		defer m.wg.Done()
		m.taskSubmissionGoroutine()
	}()

	// å¯åŠ¨æ§åˆ¶ä¿¡å·å¤„ç†åç¨‹
	m.wg.Add(1)
	go func() {
		defer m.wg.Done()
		m.controlSignalGoroutine()
	}()
}

// taskObserverGoroutine çŠ¶æ€è§‚å¯Ÿå™¨ï¼ˆGoroutine 1ï¼‰
func (m *WorkflowInstanceManagerV2) taskObserverGoroutine() {

	// æ‰¹é‡å¤„ç†ç¼“å†²åŒº
	batchSize := 10
	batch := make([]TaskStatusEvent, 0, batchSize)
	ticker := time.NewTicker(1 * time.Millisecond) // æ‰¹é‡å¤„ç†é—´éš”ï¼ˆä¼˜åŒ–ï¼šå‡å°‘å»¶è¿Ÿï¼‰
	defer ticker.Stop()

	for {
		select {
		case <-m.ctx.Done():
			// å¤„ç†å‰©ä½™æ‰¹æ¬¡
			if len(batch) > 0 {
				m.processBatch(batch)
			}
			return

		case event := <-m.taskStatusChan:
			// æ·»åŠ åˆ°æ‰¹æ¬¡
			batch = append(batch, event)

			// æ‰¹æ¬¡æ»¡äº†ï¼Œç«‹å³å¤„ç†
			if len(batch) >= batchSize {
				m.processBatch(batch)
				batch = batch[:0]
			}

		case <-ticker.C:
			// å®šæ—¶å¤„ç†æ‰¹æ¬¡ï¼ˆé¿å…é•¿æ—¶é—´ç­‰å¾…ï¼‰
			if len(batch) > 0 {
				m.processBatch(batch)
				batch = batch[:0]
			}
		}
	}
}

// processBatch æ‰¹é‡å¤„ç†äº‹ä»¶
func (m *WorkflowInstanceManagerV2) processBatch(batch []TaskStatusEvent) {
	for _, event := range batch {
		// ç›´æ¥åŒæ­¥æ›´æ–°ç»Ÿè®¡ï¼ˆé¿å…ç«æ€æ¡ä»¶ï¼‰
		statsType := getStatsType(event.Status)
		if statsType != "" {
			m.taskStats.Update(TaskStatsUpdate{
				Type:       statsType,
				TaskID:     event.TaskID,
				Status:     event.Status,
				IsTemplate: event.IsTemplate,
				IsSubTask:  event.IsSubTask,
			})
		}

		// ä½¿ç”¨é˜»å¡å‘é€æˆ–å¸¦è¶…æ—¶çš„å‘é€ï¼Œç¡®ä¿äº‹ä»¶ä¸ä¸¢å¤±
		select {
		case m.queueUpdateChan <- event:
			// äº‹ä»¶å·²å‘é€
		case <-time.After(5 * time.Second):
			log.Printf("é”™è¯¯: queueUpdateChan å‘é€è¶…æ—¶ï¼Œäº‹ä»¶å¯èƒ½ä¸¢å¤±: TaskID=%s", event.TaskID)
		case <-m.ctx.Done():
			log.Printf("Context å·²å–æ¶ˆï¼Œåœæ­¢å‘é€äº‹ä»¶: TaskID=%s", event.TaskID)
			return
		}
	}
}

// getStatsType è·å–ç»Ÿè®¡ç±»å‹
func getStatsType(status string) string {
	switch status {
	case "Success":
		return "task_completed"
	case "Failed", "Timeout":
		return "task_failed"
	default:
		return ""
	}
}

// queueManagerGoroutine é˜Ÿåˆ—ç®¡ç†å™¨ï¼ˆGoroutine 2ï¼‰
func (m *WorkflowInstanceManagerV2) queueManagerGoroutine() {

	// åˆå§‹åŒ–ï¼šæ‰§è¡Œæ‹“æ‰‘æ’åºã€åˆå§‹åŒ–ä»»åŠ¡é˜Ÿåˆ—ã€æŒ‰å±‚çº§æ·»åŠ ä»»åŠ¡å¹¶ç»Ÿè®¡æ¨¡æ¿ä»»åŠ¡æ•°é‡
	m.initTaskQueue()

	// ä½¿ç”¨ templateTaskCounts slice åˆå§‹åŒ–å½“å‰ level çš„ templateTaskCountï¼ˆä½¿ç”¨ CAS é¿å…ç«æ€æ¡ä»¶ï¼‰
	currentLevel := m.taskQueue.GetCurrentLevel()
	if currentLevel < len(m.templateTaskCounts) {
		expectedValue := int32(0) // æœŸæœ›çš„æ—§å€¼ï¼ˆåˆå§‹åŒ–ä¸º0ï¼‰
		newValue := m.templateTaskCounts[currentLevel].Load()
		// ä½¿ç”¨ CAS åŸå­æ€§åœ°è®¾ç½® templateTaskCount
		if m.templateTaskCount.CompareAndSwap(expectedValue, newValue) {
			log.Printf("WorkflowInstance %s: åˆå§‹åŒ– Level %d çš„ templateTaskCount = %d",
				m.instance.ID, currentLevel, newValue)
		} else {
			// CAS å¤±è´¥ï¼Œè¯´æ˜å·²ç»è¢«å…¶ä»– goroutine åˆå§‹åŒ–ï¼Œç›´æ¥åŠ è½½å½“å‰å€¼
			currentValue := m.templateTaskCount.Load()
			log.Printf("WorkflowInstance %s: templateTaskCount å·²è¢«åˆå§‹åŒ–ï¼Œå½“å‰å€¼ = %d (Level %d)",
				m.instance.ID, currentValue, currentLevel)
		}
	}

	// å¯åŠ¨ç»Ÿè®¡æ›´æ–°å¤„ç†goroutineï¼ˆå¼‚æ­¥å¤„ç†ï¼Œä½†ä¼šåœ¨æ£€æŸ¥å®Œæˆå‰åŒæ­¥ï¼‰
	go func() {
		for {
			select {
			case <-m.ctx.Done():
				return
			case update := <-m.taskStatsChan:
				m.taskStats.Update(update)
			}
		}
	}()

	for {
		select {
		case <-m.ctx.Done():
			// å¤„ç†å‰©ä½™äº‹ä»¶
			m.drainQueueUpdateChan()
			return

		case update := <-m.taskStatsChan:
			// åŒæ­¥å¤„ç†ç»Ÿè®¡æ›´æ–°ï¼ˆä¼˜å…ˆå¤„ç†ï¼Œç¡®ä¿ç»Ÿè®¡å‡†ç¡®ï¼‰
			m.taskStats.Update(update)
			continue

		case atomicAddSubTasksEvent := <-m.addSubTaskChan:
			// å¤„ç†åŸå­æ€§å­ä»»åŠ¡æ·»åŠ äº‹ä»¶ï¼ˆä»ä¸“ç”¨ channel æ¥æ”¶ï¼‰
			// å¿…é¡»ä¿è¯æ¨¡æ¿ä»»åŠ¡æ‰§è¡Œçš„åŸå­æ€§
			m.handleAtomicAddSubTasks(atomicAddSubTasksEvent)
			// å­ä»»åŠ¡æ·»åŠ åï¼Œæ£€æŸ¥æ˜¯å¦å¯ä»¥æ¨è¿›å±‚çº§
			// æ³¨æ„ï¼šå­ä»»åŠ¡è¢«æ·»åŠ åˆ°å½“å‰å±‚çº§ï¼Œæ‰€ä»¥å½“å‰å±‚çº§ä¸ä¸ºç©ºï¼Œä¸ä¼šæ¨è¿›å±‚çº§
			// ä½†æ˜¯ï¼Œå¦‚æœæ¨¡æ¿ä»»åŠ¡è®¡æ•°ä¸º0ï¼Œä¸”å½“å‰å±‚çº§ä¸ºç©ºï¼Œè¯´æ˜æ‰€æœ‰å­ä»»åŠ¡éƒ½å·²å®Œæˆï¼Œå¯ä»¥æ¨è¿›
			m.tryAdvanceLevel()

		case event := <-m.queueUpdateChan:
			// æ ¹æ®äº‹ä»¶ç±»å‹å¤„ç†
			switch event.Status {
			case "Success", "Failed", "Timeout":
				// å¤„ç†ä»»åŠ¡å®Œæˆäº‹ä»¶
				m.handleTaskCompletion(event)
				// æ³¨æ„ï¼šä»»åŠ¡åœ¨åˆå§‹åŒ–æ—¶å·²ç»æŒ‰å±‚çº§æ·»åŠ åˆ°é˜Ÿåˆ—ä¸­ï¼Œä¸éœ€è¦åœ¨è¿™é‡Œå†æ·»åŠ 
			case "ready":
				// å¤„ç†å°±ç»ªä»»åŠ¡äº‹ä»¶ï¼ˆä¿ç•™ï¼Œä½†å¯èƒ½ä¸éœ€è¦ï¼‰
				// æ³¨æ„ï¼šä»»åŠ¡åœ¨åˆå§‹åŒ–æ—¶å·²ç»æŒ‰å±‚çº§æ·»åŠ åˆ°é˜Ÿåˆ—ä¸­ï¼Œä¸éœ€è¦åœ¨è¿™é‡Œå†æ·»åŠ 
			}

			// å…ˆæ·»åŠ æ–°ä»»åŠ¡ï¼Œå†æ£€æŸ¥å±‚çº§æ¨è¿›
			m.tryAdvanceLevel()

			// å…ˆå¤„ç†æ‰€æœ‰å¾…å¤„ç†çš„ç»Ÿè®¡æ›´æ–°ï¼ˆç¡®ä¿ç»Ÿè®¡å‡†ç¡®ï¼‰
			m.drainTaskStatsChan()

			// ä½¿ç”¨å¿«é€Ÿæ£€æŸ¥ï¼šä»TaskStatisticsè·å–å·²å®Œæˆä»»åŠ¡æ•°å’Œæ€»ä»»åŠ¡æ•°
			successCount := atomic.LoadInt32(&m.taskStats.SuccessTasks)
			failedCount := atomic.LoadInt32(&m.taskStats.FailedTasks)
			totalCount := atomic.LoadInt32(&m.taskStats.TotalTasks)
			completed := successCount + failedCount

			// å‡å°‘æ£€æŸ¥é¢‘ç‡ï¼šæ¯ 10ms æœ€å¤šæ£€æŸ¥ä¸€æ¬¡ï¼Œæˆ–å·²å®Œæˆæ•°è¾¾åˆ°æ€»ä»»åŠ¡æ•°æ—¶æ£€æŸ¥ï¼ˆä¼˜åŒ–ï¼šæ›´å¿«å“åº”ï¼‰
			now := time.Now().UnixNano()
			lastCheck := atomic.LoadInt64(&m.lastCompletionCheck)
			shouldCheck := false

			if completed >= totalCount && totalCount > 0 {
				// å·²å®Œæˆæ•°è¾¾åˆ°æ€»ä»»åŠ¡æ•°ï¼Œå¿…é¡»æ£€æŸ¥
				shouldCheck = true
			} else if now-lastCheck > 10*int64(time.Millisecond) {
				// è·ç¦»ä¸Šæ¬¡æ£€æŸ¥è¶…è¿‡ 10msï¼Œå¯ä»¥æ£€æŸ¥ï¼ˆä¼˜åŒ–ï¼šå‡å°‘å»¶è¿Ÿï¼‰
				shouldCheck = true
			}

			if shouldCheck {
				atomic.StoreInt64(&m.lastCompletionCheck, now)

				// è¯¦ç»†æ£€æŸ¥ï¼šéªŒè¯é˜Ÿåˆ—çŠ¶æ€
				allCompleted, err := m.checkAllTasksCompleted(completed, totalCount)
				if err != nil {
					log.Printf("é”™è¯¯: WorkflowInstance %s ä»»åŠ¡å®Œæˆæ£€æŸ¥å¼‚å¸¸: %v, completed=%d, total=%d",
						m.instance.ID, err, completed, totalCount)
					continue
				}

				// è°ƒè¯•æ—¥å¿—
				if completed >= totalCount && totalCount > 0 {
					currentLevel := m.taskQueue.GetCurrentLevel()
					maxLevel := m.taskQueue.GetMaxLevel()
					log.Printf("è°ƒè¯•: WorkflowInstance %s ä»»åŠ¡è®¡æ•°æ£€æŸ¥: completed=%d, total=%d, currentLevel=%d, maxLevel=%d",
						m.instance.ID, completed, totalCount, currentLevel, maxLevel)
					// æ£€æŸ¥é˜Ÿåˆ—çŠ¶æ€
					for i := 0; i < maxLevel; i++ {
						isEmpty := m.taskQueue.IsEmpty(i)
						size := atomic.LoadInt32(&m.taskQueue.sizes[i])
						log.Printf("è°ƒè¯•: Level %d: isEmpty=%v, size=%d", i, isEmpty, size)
					}
				}

				if allCompleted {
					// æ£€æŸ¥æ˜¯å¦æœ‰å¤±è´¥çš„ä»»åŠ¡
					hasFailedTask := false
					allTasks := m.workflow.GetTasks()
					log.Printf("ğŸ” [Workflowå®Œæˆæ£€æŸ¥] å¼€å§‹æ£€æŸ¥å¤±è´¥ä»»åŠ¡ï¼Œæ€»ä»»åŠ¡æ•°: %d", len(allTasks))
					for taskID, task := range allTasks {
						taskStatus := task.GetStatus()
						taskName := task.GetName()
						log.Printf("ğŸ” [Workflowå®Œæˆæ£€æŸ¥] æ£€æŸ¥ä»»åŠ¡: TaskID=%s, TaskName=%s, Status=%s", taskID, taskName, taskStatus)
						if taskStatus == "FAILED" {
							log.Printf("ğŸ” [Workflowå®Œæˆæ£€æŸ¥] âœ… å‘ç°å¤±è´¥ä»»åŠ¡: TaskID=%s, TaskName=%s, Status=%s", taskID, taskName, taskStatus)
							hasFailedTask = true
							break
						}
						// æ£€æŸ¥ contextData ä¸­çš„é”™è¯¯ä¿¡æ¯
						errorKey := fmt.Sprintf("%s:error", taskID)
						if _, hasError := m.contextData.Load(errorKey); hasError {
							log.Printf("ğŸ” [Workflowå®Œæˆæ£€æŸ¥] âœ… å‘ç°å¤±è´¥ä»»åŠ¡ï¼ˆé€šè¿‡errorKeyï¼‰: TaskID=%s, TaskName=%s", taskID, taskName)
							hasFailedTask = true
							break
						}
					}
					// ä¹Ÿæ£€æŸ¥è¿è¡Œæ—¶ä»»åŠ¡ï¼ˆåŠ¨æ€æ·»åŠ çš„å­ä»»åŠ¡ï¼‰
					if !hasFailedTask {
						m.runtimeTasks.Range(func(key, value interface{}) bool {
							if task, ok := value.(workflow.Task); ok {
								if task.GetStatus() == "FAILED" {
									log.Printf("ğŸ” [Workflowå®Œæˆæ£€æŸ¥] å‘ç°å¤±è´¥è¿è¡Œæ—¶ä»»åŠ¡: TaskID=%s, TaskName=%s", task.GetID(), task.GetName())
									hasFailedTask = true
									return false // åœæ­¢éå†
								}
								// æ£€æŸ¥ contextData ä¸­çš„é”™è¯¯ä¿¡æ¯
								errorKey := fmt.Sprintf("%s:error", task.GetID())
								if _, hasError := m.contextData.Load(errorKey); hasError {
									log.Printf("ğŸ” [Workflowå®Œæˆæ£€æŸ¥] å‘ç°å¤±è´¥è¿è¡Œæ—¶ä»»åŠ¡ï¼ˆé€šè¿‡errorKeyï¼‰: TaskID=%s, TaskName=%s", task.GetID(), task.GetName())
									hasFailedTask = true
									return false // åœæ­¢éå†
								}
							}
							return true
						})
					}

					// æ ¹æ®æ˜¯å¦æœ‰å¤±è´¥ä»»åŠ¡å†³å®šæœ€ç»ˆçŠ¶æ€
					finalStatus := "Success"
					if hasFailedTask {
						finalStatus = "Failed"
						m.mu.Lock()
						m.instance.Status = "Failed"
						m.instance.ErrorMessage = "éƒ¨åˆ†ä»»åŠ¡æ‰§è¡Œå¤±è´¥"
						m.mu.Unlock()

						// å¦‚æœå¯ç”¨äº†SAGAï¼Œè§¦å‘è¡¥å¿
						if m.sagaEnabled && m.sagaCoordinator != nil {
							ctx := context.Background()
							if err := m.sagaCoordinator.Compensate(ctx); err != nil {
								log.Printf("âš ï¸ [SAGA] WorkflowInstance %s, è¡¥å¿æ‰§è¡Œå¤±è´¥: %v", m.instance.ID, err)
							}
						}
					} else {
						m.mu.Lock()
						m.instance.Status = "Success"
						m.mu.Unlock()

						// å¦‚æœå¯ç”¨äº†SAGAï¼Œæäº¤äº‹åŠ¡
						if m.sagaEnabled && m.sagaCoordinator != nil {
							if err := m.sagaCoordinator.Commit(); err != nil {
								log.Printf("âš ï¸ [SAGA] WorkflowInstance %s, äº‹åŠ¡æäº¤å¤±è´¥: %v", m.instance.ID, err)
							}
						}
					}

					m.mu.Lock()
					now := time.Now()
					m.instance.EndTime = &now
					m.mu.Unlock()

					ctx := context.Background()
					m.saveAllTaskStatuses(ctx)
					if err := m.updateWorkflowInstanceStatus(ctx, m.instance.ID, finalStatus, ""); err != nil {
						log.Printf("æ›´æ–°WorkflowInstanceçŠ¶æ€å¤±è´¥: %v", err)
					}

					// å‘é€çŠ¶æ€æ›´æ–°é€šçŸ¥
					select {
					case m.statusUpdateChan <- finalStatus:
					default:
						log.Printf("è­¦å‘Š: WorkflowInstance %s çŠ¶æ€æ›´æ–°é€šé“å·²æ»¡", m.instance.ID)
					}

					// è§¦å‘Workflowå®Œæˆ/å¤±è´¥æ’ä»¶
					if m.pluginManager != nil {
						var event plugin.TriggerEvent
						if finalStatus == "Success" {
							event = plugin.EventWorkflowCompleted
						} else {
							event = plugin.EventWorkflowFailed
						}
						pluginData := plugin.PluginData{
							Event:      event,
							WorkflowID: m.instance.WorkflowID,
							InstanceID: m.instance.ID,
							TaskID:     "",
							TaskName:   "",
							Status:     finalStatus,
							Error:      nil,
							Data: map[string]interface{}{
								"workflow_name": m.workflow.Name,
								"total_tasks":   totalCount,
								"completed":     completed,
							},
						}
						if finalStatus == "Failed" {
							pluginData.Error = fmt.Errorf("éƒ¨åˆ†ä»»åŠ¡æ‰§è¡Œå¤±è´¥")
							pluginData.Data["error"] = "éƒ¨åˆ†ä»»åŠ¡æ‰§è¡Œå¤±è´¥"
						}
						if err := m.pluginManager.Trigger(m.ctx, event, pluginData); err != nil {
							log.Printf("è§¦å‘Workflow %sæ’ä»¶å¤±è´¥: InstanceID=%s, Error=%v", finalStatus, m.instance.ID, err)
						}
					}

					log.Printf("WorkflowInstance %s: æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼Œæœ€ç»ˆçŠ¶æ€: %s", m.instance.ID, finalStatus)
					return
				}
			}
		}
	}
}

// initTaskQueue åˆå§‹åŒ–ä»»åŠ¡é˜Ÿåˆ—ï¼ˆä½¿ç”¨ DAG æ‹“æ‰‘æ’åºç»“æœï¼‰
func (m *WorkflowInstanceManagerV2) initTaskQueue() {
	// 1. æ‰§è¡Œæ‹“æ‰‘æ’åº
	topoOrder, err := m.dag.TopologicalSort()
	if err != nil {
		log.Printf("WorkflowInstance %s: æ‹“æ‰‘æ’åºå¤±è´¥: %vï¼Œåˆ›å»ºç©ºé˜Ÿåˆ—", m.instance.ID, err)
		// å³ä½¿æ‹“æ‰‘æ’åºå¤±è´¥ï¼Œä¹Ÿåˆ›å»ºä¸€ä¸ªç©ºé˜Ÿåˆ—ï¼Œé¿å…åç»­ nil æŒ‡é’ˆå¼‚å¸¸
		maxLevel := 1
		m.taskQueue = NewLeveledTaskQueue(maxLevel)
		m.templateTaskCounts = make([]atomic.Int32, maxLevel)
		return
	}

	// 2. åˆå§‹åŒ–ä»»åŠ¡é˜Ÿåˆ—ï¼ˆå±‚çº§æ•° = æ‹“æ‰‘æ’åºçš„å±‚çº§æ•°ï¼‰
	maxLevel := len(topoOrder.Levels)

	// å¤„ç†ç©º Workflow
	if maxLevel == 0 {
		log.Printf("WorkflowInstance %s: Workflow ä¸ºç©ºï¼Œåˆ›å»ºç©ºé˜Ÿåˆ—", m.instance.ID)
		maxLevel = 1
		m.taskQueue = NewLeveledTaskQueue(maxLevel)
		m.templateTaskCounts = make([]atomic.Int32, maxLevel)
		return
	}

	m.taskQueue = NewLeveledTaskQueue(maxLevel)

	// è·å–æ‰€æœ‰ä»»åŠ¡
	allTasks := m.workflow.GetTasks()

	// 3. æŒ‰å±‚çº§é€å±‚æ·»åŠ ä»»åŠ¡ï¼Œå¹¶ç»Ÿè®¡è¯¥å±‚æ¨¡æ¿ä»»åŠ¡çš„æ•°é‡
	m.templateTaskCounts = make([]atomic.Int32, maxLevel)

	for level, taskIDs := range topoOrder.Levels {
		templateCount := int32(0)
		for _, taskID := range taskIDs {
			if task, exists := allTasks[taskID]; exists {
				// æ·»åŠ åˆ°å¯¹åº”å±‚çº§çš„é˜Ÿåˆ—
				m.taskQueue.AddTask(level, task)

				// è®°å½•ä»»åŠ¡åŸæœ¬çš„å±‚çº§ï¼ˆç”¨äºé‡è¯•æ—¶ä½¿ç”¨ï¼‰
				levelKey := fmt.Sprintf("%s:original_level", taskID)
				m.contextData.Store(levelKey, level)

				// ç»Ÿè®¡è¯¥å±‚çš„æ¨¡æ¿ä»»åŠ¡æ•°é‡
				if task.IsTemplate() {
					templateCount++
				}
			}
		}
		// ä¿å­˜è¯¥å±‚çš„æ¨¡æ¿ä»»åŠ¡æ•°é‡
		m.templateTaskCounts[level].Store(templateCount)
	}

	// 4. åˆå§‹åŒ–ä»»åŠ¡ç»Ÿè®¡ï¼ˆé€šè¿‡taskStatsChanå‘é€task_addedäº‹ä»¶ï¼‰
	for taskID := range allTasks {
		task := allTasks[taskID]
		select {
		case m.taskStatsChan <- TaskStatsUpdate{
			Type:       "task_added",
			TaskID:     taskID,
			IsTemplate: task.IsTemplate(),
			IsSubTask:  task.IsSubTask(),
		}:
		default:
			log.Printf("è­¦å‘Š: taskStatsChan å·²æ»¡ï¼Œä»»åŠ¡ç»Ÿè®¡æ›´æ–°å¯èƒ½ä¸¢å¤±: TaskID=%s", taskID)
		}
	}
	atomic.StoreInt64(&m.lastCompletionCheck, time.Now().UnixNano())

	log.Printf("WorkflowInstance %s: ä»»åŠ¡é˜Ÿåˆ—åˆå§‹åŒ–å®Œæˆï¼Œå±‚çº§æ•°: %dï¼Œæ€»ä»»åŠ¡æ•°: %d",
		m.instance.ID, maxLevel, len(allTasks))
	for level, _ := range m.templateTaskCounts {
		count := m.templateTaskCounts[level].Load()
		if count > 0 {
			log.Printf("  Level %d: %d ä¸ªæ¨¡æ¿ä»»åŠ¡", level, count)
		}
	}
}

// handleTaskCompletion å¤„ç†ä»»åŠ¡å®Œæˆäº‹ä»¶
func (m *WorkflowInstanceManagerV2) handleTaskCompletion(event TaskStatusEvent) {
	// ä»â€œæ­£åœ¨æ‰§è¡Œâ€é›†åˆç§»é™¤ï¼Œä¾› GetProgress æš´éœ²æœªå®Œæˆä»»åŠ¡
	m.runningTaskIDs.Delete(event.TaskID)

	// æ ‡è®°ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼Œå‡å°‘ runningCountsï¼ˆæ— è®ºæˆåŠŸæˆ–å¤±è´¥ï¼‰
	levelKey := fmt.Sprintf("%s:original_level", event.TaskID)
	if levelVal, ok := m.contextData.Load(levelKey); ok {
		if level, ok := levelVal.(int); ok {
			m.taskQueue.TaskCompleted(level)
		}
	}

	// å¤„ç†ä»»åŠ¡å¤±è´¥é‡è¯•é€»è¾‘
	if event.Status == "Failed" {
		m.handleTaskFailure(event)
		return
	}

	// å¤„ç†ä»»åŠ¡æˆåŠŸé€»è¾‘
	if event.Status == "Success" {
		m.handleTaskSuccess(event)
	}
}

// handleTaskSuccess å¤„ç†ä»»åŠ¡æˆåŠŸäº‹ä»¶
func (m *WorkflowInstanceManagerV2) handleTaskSuccess(event TaskStatusEvent) {
	// æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²ç»è¢«å¤„ç†è¿‡ï¼ˆé¿å…é‡å¤å¤„ç†ï¼‰
	// ä½¿ç”¨ LoadOrStore ç¡®ä¿åŸå­æ€§ï¼Œé¿å…å¹¶å‘æ—¶é‡å¤å¤„ç†
	if _, loaded := m.processedNodes.LoadOrStore(event.TaskID, true); loaded {
		return // å·²ç»å¤„ç†è¿‡ï¼Œç›´æ¥è¿”å›
	}

	// æ³¨æ„ï¼šä»»åŠ¡å®Œæˆè®¡æ•°å·²é€šè¿‡taskStatsChanåœ¨processBatchä¸­æ›´æ–°ï¼Œè¿™é‡Œä¸éœ€è¦å†è®¡æ•°
	// æ³¨æ„ï¼šæ¨¡æ¿ä»»åŠ¡è®¡æ•°ç»Ÿä¸€åœ¨ handleAtomicAddSubTasks ä¸­å¤„ç†ï¼Œè¿™é‡Œä¸å¤„ç†

	// ä¿å­˜ç»“æœåˆ°ä¸Šä¸‹æ–‡
	if event.Result != nil {
		m.contextData.Store(event.TaskID, event.Result)

		// ç¼“å­˜ç»“æœ
		if m.resultCache != nil {
			ttl := 1 * time.Hour
			_ = m.resultCache.Set(event.TaskID, event.Result, ttl)
		}
	}

	// å¦‚æœæ˜¯å­ä»»åŠ¡ï¼Œå¤„ç†å­ä»»åŠ¡å®Œæˆé€»è¾‘ï¼ˆè®°å½•ç»“æœï¼Œè§¦å‘èšåˆï¼‰
	if event.IsSubTask {
		m.handleSubTaskCompletion(event)
	}

	// å¦‚æœæ˜¯æ¨¡æ¿ä»»åŠ¡ï¼Œæ£€æŸ¥å¹¶æ‰¹é‡æ·»åŠ ç­‰å¾…ä¸­çš„å­ä»»åŠ¡
	// è¿™æ˜¯æ–°è®¾è®¡ä¸­çš„å…³é”®æ­¥éª¤ï¼šæ¨¡æ¿ä»»åŠ¡çš„ Job Function æ‰§è¡Œå®Œæ¯•åï¼Œè§¦å‘ç­‰å¾…ä¸­çš„å­ä»»åŠ¡æ·»åŠ 
	if event.IsTemplate {
		m.processPendingSubTasks(event.TaskID)
	}
}

// processPendingSubTasks å¤„ç†ç­‰å¾…ä¸­çš„å­ä»»åŠ¡ï¼ˆæ¨¡æ¿ä»»åŠ¡æˆåŠŸåè°ƒç”¨ï¼‰
func (m *WorkflowInstanceManagerV2) processPendingSubTasks(parentTaskID string) {
	subTasksKey := fmt.Sprintf("%s:subtasks", parentTaskID)
	subTasksValue, exists := m.contextData.Load(subTasksKey)
	if !exists {
		return // æ²¡æœ‰ç­‰å¾…ä¸­çš„å­ä»»åŠ¡
	}

	// ç±»å‹æ£€æŸ¥
	subTasksList, ok := subTasksValue.([]workflow.Task)
	if !ok {
		log.Printf("è­¦å‘Š: WorkflowInstance %s: contextData ä¸­çš„å­ä»»åŠ¡åˆ—è¡¨ç±»å‹é”™è¯¯ï¼ŒParentTaskID=%s", m.instance.ID, parentTaskID)
		m.contextData.Delete(subTasksKey)
		return
	}

	if len(subTasksList) == 0 {
		m.contextData.Delete(subTasksKey)
		return
	}

	// è·å–çˆ¶ä»»åŠ¡ä¿¡æ¯
	parentTask, exists := m.workflow.GetTasks()[parentTaskID]
	if !exists {
		log.Printf("è­¦å‘Š: WorkflowInstance %s: çˆ¶ä»»åŠ¡ä¸å­˜åœ¨ï¼ŒParentTaskID=%s", m.instance.ID, parentTaskID)
		return
	}

	// è·å–ç›®æ ‡å±‚çº§
	currentLevel := m.taskQueue.GetCurrentLevel()
	targetLevel := currentLevel

	// æ‰¹é‡æ·»åŠ å­ä»»åŠ¡åˆ°é˜Ÿåˆ—
	m.taskQueue.AddTasks(targetLevel, subTasksList)

	// å­˜å‚¨å­ä»»åŠ¡çš„å±‚çº§
	for _, subTask := range subTasksList {
		levelKey := fmt.Sprintf("%s:original_level", subTask.GetID())
		m.contextData.Store(levelKey, targetLevel)
	}

	// æ¸…ç©ºå·²æ”¶é›†çš„å­ä»»åŠ¡åˆ—è¡¨
	m.contextData.Delete(subTasksKey)

	log.Printf("WorkflowInstance %s: æ¨¡æ¿ä»»åŠ¡ %s æˆåŠŸåï¼Œæ‰¹é‡æ·»åŠ  %d ä¸ªç­‰å¾…ä¸­çš„å­ä»»åŠ¡åˆ° level %d",
		m.instance.ID, parentTaskID, len(subTasksList), targetLevel)

	// å‡å°‘æ¨¡æ¿ä»»åŠ¡è®¡æ•°
	if parentTask.IsTemplate() {
		m.decrementTemplateTaskCount(parentTaskID, targetLevel, len(subTasksList))
	}
}

// handleTaskFailure å¤„ç†ä»»åŠ¡å¤±è´¥äº‹ä»¶ï¼ˆæ”¯æŒé‡è¯•ï¼‰
func (m *WorkflowInstanceManagerV2) handleTaskFailure(event TaskStatusEvent) {
	// è·å–ä»»åŠ¡ä¿¡æ¯
	task, exists := m.workflow.GetTasks()[event.TaskID]
	if !exists {
		// å¯èƒ½æ˜¯è¿è¡Œæ—¶ä»»åŠ¡
		if runtimeTask, ok := m.runtimeTasks.Load(event.TaskID); ok {
			task = runtimeTask.(workflow.Task)
			exists = true
		}
	}
	if !exists {
		log.Printf("è­¦å‘Š: å¤±è´¥çš„ä»»åŠ¡ä¸å­˜åœ¨: TaskID=%s", event.TaskID)
		return
	}

	// æ£€æŸ¥æ˜¯å¦å¯ä»¥é‡è¯•
	retryCount := task.GetRetryCount()
	currentRetries := m.getTaskRetryCount(event.TaskID)

	if currentRetries < retryCount {
		// ä¼˜å…ˆä½¿ç”¨ä»»åŠ¡åŸæœ¬çš„å±‚çº§
		levelKey := fmt.Sprintf("%s:original_level", event.TaskID)
		originalLevel := -1
		if levelValue, exists := m.contextData.Load(levelKey); exists {
			if level, ok := levelValue.(int); ok {
				originalLevel = level
			}
		}

		currentLevel := m.taskQueue.GetCurrentLevel()
		targetLevel := currentLevel

		// ä¼˜å…ˆä½¿ç”¨åŸå±‚çº§ï¼Œä½†å¦‚æœåŸå±‚çº§ > å½“å‰å±‚çº§ï¼Œä½¿ç”¨å½“å‰å±‚çº§å¹¶è®°å½•è­¦å‘Š
		if originalLevel >= 0 {
			if originalLevel <= currentLevel {
				targetLevel = originalLevel
			} else {
				// åŸå±‚çº§ > å½“å‰å±‚çº§ï¼Œä½¿ç”¨å½“å‰å±‚çº§ï¼ˆä½†è®°å½•è­¦å‘Šï¼‰
				targetLevel = currentLevel
				log.Printf("è­¦å‘Š: WorkflowInstance %s: ä»»åŠ¡ %s åŸå±‚çº§ %d > å½“å‰å±‚çº§ %dï¼Œä½¿ç”¨å½“å‰å±‚çº§ %d è¿›è¡Œé‡è¯•",
					m.instance.ID, event.TaskID, originalLevel, currentLevel, targetLevel)
			}
		}

		// é‡ç½®ä»»åŠ¡çŠ¶æ€
		task.SetStatus("PENDING")

		// æ·»åŠ åˆ°ç›®æ ‡å±‚çº§é˜Ÿåˆ—
		m.taskQueue.AddTask(targetLevel, task)

		// å¢åŠ é‡è¯•è®¡æ•°
		m.incrementTaskRetryCount(event.TaskID)

		log.Printf("WorkflowInstance %s: ä»»åŠ¡ %s å¤±è´¥ï¼Œé‡è¯• %d/%dï¼Œæ·»åŠ åˆ° level %d (åŸå±‚çº§: %d)",
			m.instance.ID, event.TaskID, currentRetries+1, retryCount, targetLevel, originalLevel)

		// æ³¨æ„ï¼šä¸è°ƒç”¨ notifyTaskReadyï¼Œç»Ÿä¸€é€šè¿‡ fetchTasksFromQueue ä»é˜Ÿåˆ—è·å–ä»»åŠ¡
	} else {
		// è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè­¦å‘Šå¹¶ç§»é™¤ä»»åŠ¡
		errorMsg := "æœªçŸ¥é”™è¯¯"
		if event.Error != nil {
			errorMsg = event.Error.Error()
		}

		log.Printf("âš ï¸ è­¦å‘Š: WorkflowInstance %s: ä»»åŠ¡ %s (%s) å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° %dï¼Œå°†ç§»é™¤ä»»åŠ¡ã€‚é”™è¯¯: %s",
			m.instance.ID, event.TaskID, task.GetName(), retryCount, errorMsg)

		// ä»å½“å‰å±‚çº§é˜Ÿåˆ—ä¸­ç§»é™¤ä»»åŠ¡
		currentLevel := m.taskQueue.GetCurrentLevel()
		m.taskQueue.RemoveTask(currentLevel, event.TaskID)

		// ä¿å­˜é”™è¯¯ä¿¡æ¯åˆ°ä¸Šä¸‹æ–‡
		errorKey := fmt.Sprintf("%s:error", event.TaskID)
		m.contextData.Store(errorKey, fmt.Sprintf("è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•° %d: %s", retryCount, errorMsg))

		// æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºæœ€ç»ˆå¤±è´¥
		task.SetStatus("FAILED")

		// æ ‡è®°ä¸ºå·²å¤„ç†ï¼ˆæœ€ç»ˆå¤±è´¥ï¼‰
		m.processedNodes.Store(event.TaskID, true)

		// å¦‚æœæ˜¯æ¨¡æ¿ä»»åŠ¡ï¼Œå‡å°‘è®¡æ•°ï¼ˆæœ€ç»ˆå¤±è´¥ï¼‰
		if event.IsTemplate {
			m.templateTaskCounts[currentLevel].Add(-1)
		}

		// æ‰§è¡Œ Task çš„ Failed çŠ¶æ€ Handlerï¼ˆé‡è¦ï¼šè¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°æ—¶ä¹Ÿéœ€è¦è§¦å‘ï¼‰
		m.executeTaskFailedHandler(event.TaskID, task, errorMsg)

		// å¦‚æœæ˜¯å­ä»»åŠ¡ï¼Œå¤„ç†å­ä»»åŠ¡å¤±è´¥é€»è¾‘ï¼ˆè®°å½•ç»“æœï¼Œè§¦å‘èšåˆï¼‰
		if event.IsSubTask {
			m.handleSubTaskFailure(event)
		}

		// æ³¨æ„ï¼šä»»åŠ¡å¤±è´¥è®¡æ•°å·²é€šè¿‡taskStatsChanåœ¨processBatchä¸­æ›´æ–°ï¼Œè¿™é‡Œä¸éœ€è¦å†è®¡æ•°
	}
}

// getTaskRetryCount è·å–ä»»åŠ¡çš„é‡è¯•æ¬¡æ•°
func (m *WorkflowInstanceManagerV2) getTaskRetryCount(taskID string) int {
	retryKey := fmt.Sprintf("%s:retry_count", taskID)
	if count, exists := m.contextData.Load(retryKey); exists {
		if retryCount, ok := count.(int); ok {
			return retryCount
		}
	}
	return 0
}

// incrementTaskRetryCount å¢åŠ ä»»åŠ¡çš„é‡è¯•æ¬¡æ•°
func (m *WorkflowInstanceManagerV2) incrementTaskRetryCount(taskID string) {
	retryKey := fmt.Sprintf("%s:retry_count", taskID)
	currentCount := m.getTaskRetryCount(taskID)
	m.contextData.Store(retryKey, currentCount+1)
}

// canAdvanceLevel åˆ¤æ–­æ˜¯å¦å¯ä»¥æ¨è¿› currentLevelï¼ˆå†…éƒ¨æ–¹æ³•ï¼Œéœ€è¦åœ¨é”ä¿æŠ¤ä¸‹è°ƒç”¨ï¼‰
func (m *WorkflowInstanceManagerV2) canAdvanceLevel() bool {
	currentLevel := m.taskQueue.GetCurrentLevel()

	// 1. å½“å‰ level å¿…é¡»å®Œå…¨å®Œæˆï¼ˆé˜Ÿåˆ—ä¸ºç©ºä¸”æ— æ‰§è¡Œä¸­ä»»åŠ¡ï¼‰
	// ä½¿ç”¨ IsLevelComplete æ£€æŸ¥ï¼Œç¡®ä¿æ‰€æœ‰ä»»åŠ¡éƒ½å·²æ‰§è¡Œå®Œæ¯•
	if !m.taskQueue.IsLevelComplete(currentLevel) {
		runningCount := m.taskQueue.GetRunningCount(currentLevel)
		isEmpty := m.taskQueue.IsEmpty(currentLevel)
		log.Printf("è°ƒè¯•: canAdvanceLevel=falseï¼ŒcurrentLevel=%dï¼ŒisEmpty=%vï¼ŒrunningCount=%d",
			currentLevel, isEmpty, runningCount)
		return false
	}

	// 2. æ²¡æœ‰å¾…å¤„ç†çš„æ¨¡æ¿ä»»åŠ¡ï¼ˆä½¿ç”¨å½“å‰å±‚çº§çš„ templateTaskCountï¼‰
	if m.templateTaskCount.Load() > 0 {
		return false
	}

	// 3. æ£€æŸ¥å½“å‰å±‚çº§çš„æ‰€æœ‰æ¨¡æ¿ä»»åŠ¡çš„å­ä»»åŠ¡æ˜¯å¦éƒ½å·²å®Œæˆ
	if !m.allSubTasksCompleted(currentLevel) {
		log.Printf("è°ƒè¯•: canAdvanceLevel=falseï¼ŒcurrentLevel=%dï¼Œå­ä»»åŠ¡æœªå…¨éƒ¨å®Œæˆ", currentLevel)
		return false
	}

	// 4. æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€å±‚çº§
	if currentLevel >= m.taskQueue.GetMaxLevel() {
		return false
	}

	return true
}

// advanceLevel æ¨è¿› currentLevelï¼ˆå†…éƒ¨æ–¹æ³•ï¼Œéœ€è¦åœ¨é”ä¿æŠ¤ä¸‹è°ƒç”¨ï¼‰
func (m *WorkflowInstanceManagerV2) advanceLevel() {
	oldLevel := m.taskQueue.GetCurrentLevel()
	m.taskQueue.AdvanceLevel()
	newLevel := m.taskQueue.GetCurrentLevel()

	// ä½¿ç”¨ CAS ä» templateTaskCounts[newLevel] è¯»å–å¹¶è®¾ç½® templateTaskCountï¼ˆé¿å…ç«æ€æ¡ä»¶ï¼‰
	if newLevel < len(m.templateTaskCounts) {
		// è¯»å–æ—§å€¼ï¼ˆå½“å‰å±‚çº§çš„ templateTaskCountï¼Œåº”è¯¥ä¸º0ï¼‰
		oldValue := m.templateTaskCount.Load()
		newValue := m.templateTaskCounts[newLevel].Load()

		// ä½¿ç”¨ CAS åŸå­æ€§åœ°æ›´æ–° templateTaskCount
		// æœŸæœ›æ—§å€¼ä¸º oldValueï¼ˆå½“å‰å€¼ï¼‰ï¼Œæ–°å€¼ä¸º newValueï¼ˆæ–°å±‚çº§çš„æ¨¡æ¿ä»»åŠ¡æ•°ï¼‰
		if m.templateTaskCount.CompareAndSwap(oldValue, newValue) {
			log.Printf("WorkflowInstance %s: currentLevel ä» %d æ¨è¿›åˆ° %dï¼ŒtemplateTaskCount ä» %d æ›´æ–°ä¸º %d",
				m.instance.ID, oldLevel, newLevel, oldValue, newValue)
		} else {
			// CAS å¤±è´¥ï¼Œè¯´æ˜ templateTaskCount å·²è¢«å…¶ä»– goroutine ä¿®æ”¹
			// é‡æ–°è¯»å–å½“å‰å€¼å¹¶é‡è¯•
			currentValue := m.templateTaskCount.Load()
			if m.templateTaskCount.CompareAndSwap(currentValue, newValue) {
				log.Printf("WorkflowInstance %s: currentLevel ä» %d æ¨è¿›åˆ° %dï¼ŒtemplateTaskCount ä» %d æ›´æ–°ä¸º %d (é‡è¯•æˆåŠŸ)",
					m.instance.ID, oldLevel, newLevel, currentValue, newValue)
			} else {
				// é‡è¯•å¤±è´¥ï¼Œè®°å½•è­¦å‘Šä½†ç»§ç»­æ‰§è¡Œ
				log.Printf("è­¦å‘Š: WorkflowInstance %s: currentLevel ä» %d æ¨è¿›åˆ° %dï¼Œä½† templateTaskCount CAS æ›´æ–°å¤±è´¥ï¼Œå½“å‰å€¼ = %d",
					m.instance.ID, oldLevel, newLevel, m.templateTaskCount.Load())
			}
		}
	} else {
		log.Printf("WorkflowInstance %s: currentLevel ä» %d æ¨è¿›åˆ° %d (æ–°å±‚çº§è¶…å‡ºèŒƒå›´ï¼ŒtemplateTaskCount ä¿æŒä¸º %d)",
			m.instance.ID, oldLevel, newLevel, m.templateTaskCount.Load())
	}
}

// tryAdvanceLevel åŸå­åœ°æ£€æŸ¥å’Œæ¨è¿›å±‚çº§
func (m *WorkflowInstanceManagerV2) tryAdvanceLevel() bool {
	m.levelAdvanceMu.Lock()
	defer m.levelAdvanceMu.Unlock()

	if !m.canAdvanceLevel() {
		return false
	}

	m.advanceLevel()
	return true
}

// notifyTaskReady é€šçŸ¥ä»»åŠ¡å°±ç»ª
func (m *WorkflowInstanceManagerV2) notifyTaskReady(task workflow.Task) {
	select {
	case m.taskSubmissionChan <- []workflow.Task{task}:
	case <-time.After(5 * time.Second):
		log.Printf("è­¦å‘Š: taskSubmissionChan å‘é€è¶…æ—¶ï¼Œä»»åŠ¡å¯èƒ½ä¸¢å¤±: TaskID=%s", task.GetID())
	case <-m.ctx.Done():
		log.Printf("Context å·²å–æ¶ˆï¼Œåœæ­¢å‘é€ä»»åŠ¡: TaskID=%s", task.GetID())
	}
}

// checkAllTasksCompleted æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ä»»åŠ¡éƒ½å·²å®Œæˆ
func (m *WorkflowInstanceManagerV2) checkAllTasksCompleted(completedCount, totalCount int32) (bool, error) {
	// å…ˆéªŒè¯è®¡æ•°ä¸€è‡´æ€§
	if err := m.validateTaskCounts(); err != nil {
		return false, err
	}

	// å¿«é€Ÿæ£€æŸ¥ï¼šå·²å®Œæˆæ•°å¿…é¡» >= æ€»ä»»åŠ¡æ•°
	if completedCount < totalCount {
		return false, nil
	}

	// å¦‚æœå·²å®Œæˆæ•° >= æ€»ä»»åŠ¡æ•°ï¼Œå°è¯•æ¨è¿›åˆ°æœ€ç»ˆå±‚çº§ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
	// æŒç»­å°è¯•æ¨è¿›å±‚çº§ï¼Œç›´åˆ°æ— æ³•æ¨è¿›æˆ–åˆ°è¾¾æœ€å¤§å±‚çº§
	maxLevel := m.taskQueue.GetMaxLevel()
	for {
		currentLevel := m.taskQueue.GetCurrentLevel()
		if currentLevel >= maxLevel {
			break
		}
		// æ£€æŸ¥å½“å‰å±‚çº§æ˜¯å¦ä¸ºç©ºï¼Œå¦‚æœä¸ºç©ºåˆ™æ¨è¿›
		// ä½†æ˜¯ï¼Œå¦‚æœå½“å‰å±‚çº§è¿˜æœ‰ä»»åŠ¡ï¼ˆæ¯”å¦‚åŠ¨æ€æ·»åŠ çš„å­ä»»åŠ¡ï¼‰ï¼Œä¸åº”è¯¥æ¨è¿›
		if m.taskQueue.IsEmpty(currentLevel) && m.templateTaskCount.Load() == 0 {
			// ä½¿ç”¨ tryAdvanceLevel åŸå­æ€§åœ°æ£€æŸ¥å’Œæ¨è¿›
			if !m.tryAdvanceLevel() {
				// æ— æ³•æ¨è¿›ï¼Œé€€å‡ºå¾ªç¯
				break
			}
		} else {
			// å½“å‰å±‚çº§ä¸ä¸ºç©ºæˆ–è¿˜æœ‰æ¨¡æ¿ä»»åŠ¡ï¼Œæ— æ³•æ¨è¿›
			break
		}
	}

	// è¯¦ç»†æ£€æŸ¥ï¼šéªŒè¯é˜Ÿåˆ—çŠ¶æ€å’Œå±‚çº§
	isCompleted, err := m.taskQueue.IsAllTasksCompleted()
	if err != nil {
		log.Printf("WorkflowInstance %s: IsAllTasksCompleted æ£€æŸ¥å¼‚å¸¸: %v", m.instance.ID, err)
		return false, err
	}
	if isCompleted {
		// æ£€æŸ¥æ˜¯å¦æœ‰å¤±è´¥ä»»åŠ¡ï¼ˆç”¨äºæ—¥å¿—ï¼‰
		hasFailed := false
		allTasks := m.workflow.GetTasks()
		for taskID, task := range allTasks {
			if task.GetStatus() == "FAILED" {
				hasFailed = true
				log.Printf("WorkflowInstance %s: æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼Œä½†å‘ç°å¤±è´¥ä»»åŠ¡: TaskID=%s, TaskName=%s", m.instance.ID, taskID, task.GetName())
				break
			}
			errorKey := fmt.Sprintf("%s:error", taskID)
			if _, hasError := m.contextData.Load(errorKey); hasError {
				hasFailed = true
				log.Printf("WorkflowInstance %s: æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼Œä½†å‘ç°å¤±è´¥ä»»åŠ¡ï¼ˆé€šè¿‡errorKeyï¼‰: TaskID=%s, TaskName=%s", m.instance.ID, taskID, task.GetName())
				break
			}
		}
		if !hasFailed {
			log.Printf("WorkflowInstance %s: æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼Œæœ€ç»ˆçŠ¶æ€: Success", m.instance.ID)
		}
	}
	return isCompleted, nil
}

// validateTaskCounts éªŒè¯ä»»åŠ¡è®¡æ•°ä¸€è‡´æ€§
func (m *WorkflowInstanceManagerV2) validateTaskCounts() error {
	isValid := m.taskStats.Validate()
	if !isValid {
		return fmt.Errorf("ä»»åŠ¡ç»Ÿè®¡ä¸ä¸€è‡´")
	}
	return nil
}

// drainQueueUpdateChan å¤„ç†å‰©ä½™äº‹ä»¶
func (m *WorkflowInstanceManagerV2) drainQueueUpdateChan() {
	timeout := time.After(2 * time.Second)
	for {
		select {
		case event := <-m.queueUpdateChan:
			switch event.Status {
			case "Success", "Failed", "Timeout":
				m.handleTaskCompletion(event)
			case "ready":
				// æ³¨æ„ï¼šä»»åŠ¡åœ¨åˆå§‹åŒ–æ—¶å·²ç»æŒ‰å±‚çº§æ·»åŠ åˆ°é˜Ÿåˆ—ä¸­ï¼Œä¸éœ€è¦åœ¨è¿™é‡Œå†æ·»åŠ 
			}
		case <-timeout:
			log.Printf("WorkflowInstance %s: å¤„ç†å‰©ä½™äº‹ä»¶è¶…æ—¶", m.instance.ID)
			return
		default:
			return
		}
	}
}

// drainTaskStatsChan å¤„ç†æ‰€æœ‰å¾…å¤„ç†çš„ç»Ÿè®¡æ›´æ–°ï¼ˆéé˜»å¡ï¼‰
func (m *WorkflowInstanceManagerV2) drainTaskStatsChan() {
	for {
		select {
		case update := <-m.taskStatsChan:
			m.taskStats.Update(update)
		default:
			return
		}
	}
}

// taskSubmissionGoroutine ä»»åŠ¡æäº¤å™¨ï¼ˆGoroutine 3ï¼‰
func (m *WorkflowInstanceManagerV2) taskSubmissionGoroutine() {

	maxBatchSize := 10
	batch := make([]workflow.Task, 0, maxBatchSize)
	ticker := time.NewTicker(5 * time.Millisecond) // æ‰¹é‡æäº¤é—´éš”ï¼ˆä¼˜åŒ–ï¼šå‡å°‘å»¶è¿Ÿï¼Œæ›´å¿«å“åº”ï¼‰
	defer ticker.Stop()

	for {
		select {
		case <-m.ctx.Done():
			// æäº¤å‰©ä½™æ‰¹æ¬¡
			if len(batch) > 0 {
				m.submitBatch(batch)
			}
			return

		case tasks := <-m.taskSubmissionChan:
			// è¿›å…¥æäº¤ç®¡é“çš„ä»»åŠ¡ï¼ˆå«åŠ¨æ€ notifyTaskReadyï¼‰ç»Ÿä¸€è®¡å…¥â€œè¿è¡Œä¸­â€
			for _, t := range tasks {
				m.runningTaskIDs.Store(t.GetID(), struct{}{})
			}
			// æ·»åŠ åˆ°æ‰¹æ¬¡
			batch = append(batch, tasks...)

			// æ‰¹æ¬¡æ»¡äº†ï¼Œç«‹å³æäº¤
			if len(batch) >= maxBatchSize {
				m.submitBatch(batch)
				batch = batch[:0]
			}

		case <-ticker.C:
			// å®šæ—¶æäº¤æ‰¹æ¬¡
			if len(batch) > 0 {
				m.submitBatch(batch)
				batch = batch[:0]
			}

			// ä»é˜Ÿåˆ—è·å–ä»»åŠ¡ï¼ˆæ ¹æ® currentLevelï¼‰
			m.fetchTasksFromQueue()
		}
	}
}

// fetchTasksFromQueue ä»é˜Ÿåˆ—è·å–ä»»åŠ¡
func (m *WorkflowInstanceManagerV2) fetchTasksFromQueue() {
	// æ£€æŸ¥ taskQueue æ˜¯å¦å·²åˆå§‹åŒ–
	if m.taskQueue == nil {
		return
	}

	currentLevel := m.taskQueue.GetCurrentLevel()

	// ä» workflow è·å–æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°
	maxConcurrent := m.workflow.GetMaxConcurrentTask()
	if maxConcurrent <= 0 {
		maxConcurrent = 10 // é»˜è®¤å€¼
	}

	// ä»å½“å‰å±‚çº§è·å–å¹¶ç§»é™¤ä»»åŠ¡
	tasks := m.taskQueue.PopTasks(currentLevel, maxConcurrent)

	if len(tasks) > 0 {
		select {
		case m.taskSubmissionChan <- tasks:
			// æ¥æ”¶æ–¹ taskSubmissionGoroutine ä¼šç»Ÿä¸€è®¡å…¥ runningTaskIDs
		case <-time.After(5 * time.Second):
			log.Printf("è­¦å‘Š: taskSubmissionChan å‘é€è¶…æ—¶ï¼Œä»»åŠ¡åŠ å›é˜Ÿåˆ—: count=%d", len(tasks))
			for _, task := range tasks {
				m.taskQueue.AddTask(currentLevel, task)
			}
		case <-m.ctx.Done():
			log.Printf("Context å·²å–æ¶ˆï¼Œä»»åŠ¡åŠ å›é˜Ÿåˆ—: count=%d", len(tasks))
			for _, task := range tasks {
				m.taskQueue.AddTask(currentLevel, task)
			}
		}
	}
}

// checkDependencyFailed æ£€æŸ¥ä»»åŠ¡çš„ä¾èµ–æ˜¯å¦æœ‰å¤±è´¥çš„
// è¿”å›å¤±è´¥çš„ä¾èµ–ä»»åŠ¡åç§°ï¼Œå¦‚æœæ²¡æœ‰å¤±è´¥çš„ä¾èµ–åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
func (m *WorkflowInstanceManagerV2) checkDependencyFailed(t workflow.Task) string {
	deps := t.GetDependencies()
	for _, depName := range deps {
		depTaskID, exists := m.workflow.GetTaskIDByName(depName)
		if !exists {
			continue
		}

		// æ£€æŸ¥ä¾èµ–ä»»åŠ¡æ˜¯å¦å¤±è´¥
		var depTask workflow.Task
		if wfTask, exists := m.workflow.GetTasks()[depTaskID]; exists {
			depTask = wfTask
		} else if runtimeTask, ok := m.runtimeTasks.Load(depTaskID); ok {
			depTask = runtimeTask.(workflow.Task)
		}

		if depTask != nil && depTask.GetStatus() == "FAILED" {
			return depName
		}

		// ä¹Ÿæ£€æŸ¥ contextData ä¸­çš„é”™è¯¯ä¿¡æ¯ï¼ˆç”¨äºå¤„ç†çŠ¶æ€æœªåŠæ—¶æ›´æ–°çš„æƒ…å†µï¼‰
		errorKey := fmt.Sprintf("%s:error", depTaskID)
		if _, hasError := m.contextData.Load(errorKey); hasError {
			return depName
		}
	}
	return ""
}

// submitBatch æ‰¹é‡æäº¤ä»»åŠ¡åˆ° Executor
func (m *WorkflowInstanceManagerV2) submitBatch(batch []workflow.Task) {
	for _, task := range batch {
		taskID := task.GetID()
		taskName := task.GetName()

		// æ£€æŸ¥ä¾èµ–ä»»åŠ¡æ˜¯å¦æœ‰å¤±è´¥çš„ï¼Œå¦‚æœæœ‰åˆ™è·³è¿‡å½“å‰ä»»åŠ¡
		if failedDep := m.checkDependencyFailed(task); failedDep != "" {
			log.Printf("âš ï¸ WorkflowInstance %s: ä»»åŠ¡ %s (%s) çš„ä¾èµ–ä»»åŠ¡ %s å·²å¤±è´¥ï¼Œè·³è¿‡æ‰§è¡Œå¹¶æ ‡è®°ä¸ºå¤±è´¥",
				m.instance.ID, taskID, taskName, failedDep)

			// æ ‡è®°å½“å‰ä»»åŠ¡ä¸ºå¤±è´¥
			task.SetStatus("FAILED")
			m.processedNodes.Store(taskID, true)

			// ä¿å­˜é”™è¯¯ä¿¡æ¯
			errorKey := fmt.Sprintf("%s:error", taskID)
			m.contextData.Store(errorKey, fmt.Sprintf("ä¾èµ–ä»»åŠ¡ %s æ‰§è¡Œå¤±è´¥ï¼Œè·³è¿‡å½“å‰ä»»åŠ¡", failedDep))

			// å‘é€ä»»åŠ¡å¤±è´¥äº‹ä»¶
			m.runningTaskIDs.Delete(taskID) // æœªçœŸæ­£æäº¤ï¼Œä»è¿è¡Œä¸­ç§»é™¤
			select {
			case m.taskStatusChan <- TaskStatusEvent{
				TaskID:      taskID,
				Status:      "Failed",
				Error:       fmt.Errorf("ä¾èµ–ä»»åŠ¡ %s æ‰§è¡Œå¤±è´¥", failedDep),
				IsTemplate:  task.IsTemplate(),
				IsSubTask:   task.IsSubTask(),
				IsProcessed: false,
				Timestamp:   time.Now(),
			}:
			default:
				log.Printf("è­¦å‘Š: taskStatusChan å·²æ»¡ï¼Œä»»åŠ¡å¤±è´¥äº‹ä»¶å¯èƒ½ä¸¢å¤±: TaskID=%s", taskID)
			}
			continue
		}

		// æ¨¡æ¿ä»»åŠ¡çš„ Job Function æ­£å¸¸æ‰§è¡Œï¼ˆä¸å†è·³è¿‡ï¼‰
		// æ ¹æ®è®¾è®¡æ–‡æ¡£è¦æ±‚ï¼šç”¨æˆ·åº”è¯¥æŠŠä»»åŠ¡ç”Ÿæˆå‡½æ•°æ”¾åœ¨ Job Function ä¸­
		// Job Function å¯ä»¥ä» context å¼•ç”¨ä¹‹å‰ä»»åŠ¡çš„ç»“æœï¼Œå¹¶æ³¨å…¥ç»™å­ä»»åŠ¡
		if task.IsTemplate() {
			log.Printf("ğŸ“‹ WorkflowInstance %s: Task %s (%s) æ˜¯æ¨¡æ¿ä»»åŠ¡ï¼Œæ‰§è¡Œ Job Function ç”Ÿæˆå­ä»»åŠ¡",
				m.instance.ID, taskID, taskName)
		}

		// å‚æ•°æ ¡éªŒå’Œç»“æœæ˜ å°„
		if err := m.validateAndMapParams(task, taskID); err != nil {
			log.Printf("å‚æ•°æ ¡éªŒå¤±è´¥: TaskID=%s, Error=%v", taskID, err)
			m.runningTaskIDs.Delete(taskID)
			continue
		}

		// ä»ç¼“å­˜è·å–ä¸Šæ¸¸ä»»åŠ¡ç»“æœå¹¶æ³¨å…¥å‚æ•°
		if m.resultCache != nil {
			m.injectCachedResults(task, taskID)
		}

		// é€šè¿‡JobFuncNameä»registryè·å–JobFuncID
		if task.GetJobFuncID() == "" && m.registry != nil {
			task.SetJobFuncID(m.registry.GetIDByName(task.GetJobFuncName()))
		}

		// åˆ›å»º InstanceManager æ¥å£åŒ…è£…å™¨ï¼ˆç”¨äºæ¨¡æ¿ä»»åŠ¡åœ¨ Job Function ä¸­æ·»åŠ å­ä»»åŠ¡ï¼‰
		// æ³¨æ„ï¼šInstanceManagerInterfaceV2 å·²åœ¨åˆå§‹åŒ–æ—¶æ³¨å†Œåˆ° registryï¼Œè¿™é‡Œåªæ˜¯åˆ›å»ºå¼•ç”¨ç”¨äº PendingTask
		managerInterface := &InstanceManagerInterfaceV2{
			manager: m,
		}

		// ç¡®ä¿çŠ¶æ€ä¸ºPending
		task.SetStatus("PENDING")

		// åˆ›å»º executor.PendingTaskï¼ˆé€šè¿‡ InstanceManager å­—æ®µç›´æ¥ä¼ é€’å¼•ç”¨ï¼‰
		pendingTask := &executor.PendingTask{
			Task:            task,
			WorkflowID:      m.instance.WorkflowID,
			InstanceID:      m.instance.ID,
			Domain:          "",
			MaxRetries:      0,
			OnComplete:      m.createTaskCompleteHandler(taskID),
			OnError:         m.createTaskErrorHandler(taskID),
			InstanceManager: managerInterface,
		}

		// æäº¤åˆ°Executor
		if err := m.executor.SubmitTask(pendingTask); err != nil {
			log.Printf("æäº¤Taskåˆ°Executorå¤±è´¥: TaskID=%s, Error=%v", taskID, err)

			// æ£€æŸ¥é‡è¯•æ¬¡æ•°
			retryCount := task.GetRetryCount()
			currentRetries := m.getTaskRetryCount(taskID)

			if currentRetries < retryCount {
				// å¯ä»¥é‡è¯•ï¼šå°†ä»»åŠ¡æ·»åŠ å›å½“å‰ level çš„é˜Ÿåˆ—
				m.runningTaskIDs.Delete(taskID)
				currentLevel := m.taskQueue.GetCurrentLevel()
				m.incrementTaskRetryCount(taskID)
				m.taskQueue.AddTask(currentLevel, task)

				log.Printf("WorkflowInstance %s: ä»»åŠ¡ %s æäº¤å¤±è´¥ï¼Œé‡è¯• %d/%dï¼Œæ·»åŠ åˆ°å½“å‰ level %d",
					m.instance.ID, taskID, currentRetries+1, retryCount, currentLevel)
			} else {
				// è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè­¦å‘Šå¹¶ç§»é™¤ä»»åŠ¡
				m.runningTaskIDs.Delete(taskID)
				log.Printf("âš ï¸ è­¦å‘Š: WorkflowInstance %s: ä»»åŠ¡ %s (%s) æäº¤å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° %dï¼Œå°†ç§»é™¤ä»»åŠ¡ã€‚é”™è¯¯: %v",
					m.instance.ID, taskID, task.GetName(), retryCount, err)

				currentLevel := m.taskQueue.GetCurrentLevel()
				m.taskQueue.RemoveTask(currentLevel, taskID)

				errorKey := fmt.Sprintf("%s:error", taskID)
				m.contextData.Store(errorKey, fmt.Sprintf("æäº¤å¤±è´¥ï¼Œè¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•° %d: %v", retryCount, err))

				task.SetStatus("FAILED")
				m.processedNodes.Store(taskID, true)

				if task.IsTemplate() {
					m.templateTaskCounts[currentLevel].Add(-1)
				}

				// æ³¨æ„ï¼šä»»åŠ¡å¤±è´¥è®¡æ•°å·²é€šè¿‡taskStatsChanåœ¨processBatchä¸­æ›´æ–°ï¼Œè¿™é‡Œä¸éœ€è¦å†è®¡æ•°
			}
			continue
		}

		// è¿è¡Œä¸­å·²åœ¨ fetchTasksFromQueue å‡ºé˜Ÿæ—¶è®¡å…¥ï¼Œæ­¤å¤„æ— éœ€é‡å¤

		// æ›´æ–°ç»Ÿè®¡ï¼šä»»åŠ¡å·²æäº¤
		select {
		case m.taskStatsChan <- TaskStatsUpdate{
			Type:   "task_submitted",
			TaskID: taskID,
		}:
		default:
		}
	}
}

// validateAndMapParams æ ¡éªŒå‚æ•°å¹¶æ‰§è¡ŒresultMapping
func (m *WorkflowInstanceManagerV2) validateAndMapParams(t workflow.Task, taskID string) error {
	requiredParams := t.GetRequiredParams()
	resultMapping := t.GetResultMapping()

	// 1. æ£€æŸ¥å¿…éœ€å‚æ•°
	if len(requiredParams) > 0 {
		deps := t.GetDependencies()
		allParamsFound := true
		missingParams := make([]string, 0)

		for _, requiredParam := range requiredParams {
			found := false
			if t.GetParams()[requiredParam] != nil {
				found = true
			} else {
				for _, depName := range deps {
					depTaskID, exists := m.workflow.GetTaskIDByName(depName)
					if !exists {
						continue
					}
					if upstreamResultValue, exists := m.contextData.Load(depTaskID); exists {
						if upstreamResult, ok := upstreamResultValue.(map[string]interface{}); ok {
							if _, hasKey := upstreamResult[requiredParam]; hasKey {
								found = true
								break
							}
						}
					}
				}
			}

			if !found {
				allParamsFound = false
				missingParams = append(missingParams, requiredParam)
			}
		}

		if !allParamsFound {
			return fmt.Errorf("ç¼ºå°‘å¿…éœ€å‚æ•°: %v", missingParams)
		}
	}

	// 2. æ‰§è¡ŒresultMapping
	if len(resultMapping) > 0 {
		deps := t.GetDependencies()
		for targetParam, sourceField := range resultMapping {
			for _, depName := range deps {
				depTaskID, exists := m.workflow.GetTaskIDByName(depName)
				if !exists {
					continue
				}
				if upstreamResultValue, exists := m.contextData.Load(depTaskID); exists {
					if upstreamResult, ok := upstreamResultValue.(map[string]interface{}); ok {
						if sourceValue, hasKey := upstreamResult[sourceField]; hasKey {
							paramKey := fmt.Sprintf("%s:%s", taskID, targetParam)
							m.contextData.Store(paramKey, sourceValue)
							break
						}
					}
				}
			}
		}
	}

	return nil
}

// injectCachedResults ä»ç¼“å­˜è·å–ä¸Šæ¸¸ä»»åŠ¡ç»“æœå¹¶æ³¨å…¥å‚æ•°
func (m *WorkflowInstanceManagerV2) injectCachedResults(t workflow.Task, taskID string) {
	if m.resultCache == nil {
		return
	}

	resultMapping := t.GetResultMapping()
	requiredParams := t.GetRequiredParams()
	hasResultMapping := len(resultMapping) > 0

	deps := t.GetDependencies()
	for _, depName := range deps {
		depTaskID, exists := m.workflow.GetTaskIDByName(depName)
		if !exists {
			continue
		}

		cachedResult, found := m.resultCache.Get(depTaskID)
		if !found {
			continue
		}

		upstreamResult, ok := cachedResult.(map[string]interface{})
		if !ok {
			// åŒæ—¶ä½¿ç”¨ taskID å’Œ taskName ä½œä¸º keyï¼ˆä¿æŒå‘åå…¼å®¹ï¼ŒåŒæ—¶æ”¯æŒæŒ‰åç§°è®¿é—®ï¼‰
			cacheKeyByID := fmt.Sprintf("_cached_%s", depTaskID)
			cacheKeyByName := fmt.Sprintf("_cached_%s", depName)
			if _, exists := t.GetParam(cacheKeyByID); !exists {
				t.SetParam(cacheKeyByID, cachedResult)
			}
			if _, exists := t.GetParam(cacheKeyByName); !exists {
				t.SetParam(cacheKeyByName, cachedResult)
			}
			continue
		}

		if hasResultMapping {
			for targetParam, sourceField := range resultMapping {
				if sourceValue, hasKey := upstreamResult[sourceField]; hasKey {
					if _, exists := t.GetParam(targetParam); !exists {
						t.SetParam(targetParam, sourceValue)
					}
				}
			}
		} else {
			if len(requiredParams) > 0 {
				missingRequiredFields := make([]string, 0)
				for _, requiredParam := range requiredParams {
					if t.GetParams()[requiredParam] != nil {
						continue
					}
					if _, hasKey := upstreamResult[requiredParam]; !hasKey {
						missingRequiredFields = append(missingRequiredFields, requiredParam)
					}
				}
				if len(missingRequiredFields) > 0 {
					log.Printf("âš ï¸ WorkflowInstance %s: Task %s çš„å¿…éœ€å‚æ•°åœ¨ä¸Šæ¸¸ä»»åŠ¡ %s çš„ç»“æœä¸­ä¸å­˜åœ¨: %v (å»ºè®®é…ç½®ResultMapping)",
						m.instance.ID, taskID, depTaskID, missingRequiredFields)
				}
			}

			// åŒæ—¶ä½¿ç”¨ taskID å’Œ taskName ä½œä¸º keyï¼ˆä¿æŒå‘åå…¼å®¹ï¼ŒåŒæ—¶æ”¯æŒæŒ‰åç§°è®¿é—®ï¼‰
			cacheKeyByID := fmt.Sprintf("_cached_%s", depTaskID)
			cacheKeyByName := fmt.Sprintf("_cached_%s", depName)
			if _, exists := t.GetParam(cacheKeyByID); !exists {
				t.SetParam(cacheKeyByID, cachedResult)
			}
			if _, exists := t.GetParam(cacheKeyByName); !exists {
				t.SetParam(cacheKeyByName, cachedResult)
			}
		}
	}
}

// createTaskCompleteHandler åˆ›å»ºä»»åŠ¡å®Œæˆå¤„ç†å™¨
func (m *WorkflowInstanceManagerV2) createTaskCompleteHandler(taskID string) func(*executor.TaskResult) {
	return func(result *executor.TaskResult) {
		// æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²ç»è¢«å¤„ç†è¿‡ï¼ˆé¿å…é‡å¤å¤„ç†ï¼‰
		if _, processed := m.processedNodes.Load(taskID); processed {
			return // å·²ç»å¤„ç†è¿‡ï¼Œç›´æ¥è¿”å›
		}

		// æ›´æ–°workflow.Taskçš„çŠ¶æ€ä¸ºSuccess
		if workflowTask, exists := m.workflow.GetTasks()[taskID]; exists {
			workflowTask.SetStatus("SUCCESS")
		} else if runtimeTask, ok := m.runtimeTasks.Load(taskID); ok {
			runtimeTask.(workflow.Task).SetStatus("SUCCESS")
		}

		// æ‰§è¡ŒTaskçš„çŠ¶æ€Handlerï¼ˆSuccessçŠ¶æ€ï¼‰
		if m.registry != nil {
			var workflowTask workflow.Task
			var exists bool
			if workflowTask, exists = m.workflow.GetTasks()[taskID]; !exists {
				if runtimeTask, ok := m.runtimeTasks.Load(taskID); ok {
					workflowTask = runtimeTask.(workflow.Task)
					exists = true
				}
			}
			if !exists {
				return
			}

			statusHandlers := workflowTask.GetStatusHandlers()
			taskObj := task.NewTask(workflowTask.GetName(), workflowTask.GetDescription(), workflowTask.GetJobFuncID(), workflowTask.GetParams(), statusHandlers)
			taskObj.SetID(workflowTask.GetID())
			taskObj.SetJobFuncName(workflowTask.GetJobFuncName())
			taskObj.SetTimeoutSeconds(workflowTask.GetTimeoutSeconds())
			taskObj.SetRetryCount(workflowTask.GetRetryCount())
			taskObj.SetDependencies(workflowTask.GetDependencies())
			taskObj.SetStatus("SUCCESS")

			// InstanceManagerInterfaceV2 å·²åœ¨åˆå§‹åŒ–æ—¶æ³¨å†Œåˆ° registryï¼Œæ— éœ€é‡å¤æ³¨å†Œ
			if err := task.ExecuteTaskHandlerWithContext(
				m.registry,
				taskObj,
				"SUCCESS",
				m.instance.WorkflowID,
				m.instance.ID,
				result.Data,
				"",
			); err != nil {
				log.Printf("æ‰§è¡ŒTask Handlerå¤±è´¥: Task=%s, Status=Success, Error=%v", taskID, err)
			}
		}

		// å¦‚æœå¯ç”¨äº†SAGAï¼Œè®°å½•æˆåŠŸæ­¥éª¤
		if m.sagaEnabled && m.sagaCoordinator != nil {
			var workflowTask workflow.Task
			var exists bool
			if workflowTask, exists = m.workflow.GetTasks()[taskID]; !exists {
				if runtimeTask, ok := m.runtimeTasks.Load(taskID); ok {
					workflowTask = runtimeTask.(workflow.Task)
					exists = true
				}
			}
			if exists && workflowTask.GetCompensationFuncName() != "" {
				step := saga.NewTransactionStep(
					taskID,
					workflowTask.GetName(),
					"Success",
					workflowTask.GetCompensationFuncName(),
					workflowTask.GetCompensationFuncID(),
				)
				step.ExecutedAt = time.Now().Unix()
				m.sagaCoordinator.AddStep(step)
				m.sagaCoordinator.MarkStepSuccess(taskID)
			}
		}

		// è§¦å‘TaskæˆåŠŸæ’ä»¶
		if m.pluginManager != nil {
			var workflowTask workflow.Task
			var exists bool
			if workflowTask, exists = m.workflow.GetTasks()[taskID]; !exists {
				if runtimeTask, ok := m.runtimeTasks.Load(taskID); ok {
					workflowTask = runtimeTask.(workflow.Task)
					exists = true
				}
			}
			if exists {
				pluginData := plugin.PluginData{
					Event:      plugin.EventTaskSuccess,
					WorkflowID: m.instance.WorkflowID,
					InstanceID: m.instance.ID,
					TaskID:     taskID,
					TaskName:   workflowTask.GetName(),
					Status:     "SUCCESS",
					Error:      nil,
					Data: map[string]interface{}{
						"result": result.Data,
					},
				}
				if err := m.pluginManager.Trigger(m.ctx, plugin.EventTaskSuccess, pluginData); err != nil {
					log.Printf("è§¦å‘TaskæˆåŠŸæ’ä»¶å¤±è´¥: TaskID=%s, Error=%v", taskID, err)
				}
			}
		}

		// å‘é€ä»»åŠ¡å®Œæˆäº‹ä»¶åˆ°taskStatusChan
		isTemplate := false
		isSubTask := false
		parentID := ""
		if workflowTask, exists := m.workflow.GetTasks()[taskID]; exists {
			isTemplate = workflowTask.IsTemplate()
			isSubTask = workflowTask.IsSubTask()
		} else if runtimeTask, ok := m.runtimeTasks.Load(taskID); ok {
			isSubTask = runtimeTask.(workflow.Task).IsSubTask()
		}
		// è·å–å­ä»»åŠ¡çš„çˆ¶ä»»åŠ¡ID
		if isSubTask {
			parentKey := fmt.Sprintf("%s:parent_task_id", taskID)
			if parentValue, exists := m.contextData.Load(parentKey); exists {
				parentID = parentValue.(string)
			}
		}

		select {
		case m.taskStatusChan <- TaskStatusEvent{
			TaskID:      taskID,
			Status:      "Success",
			Result:      result.Data,
			IsTemplate:  isTemplate,
			IsSubTask:   isSubTask,
			ParentID:    parentID,
			IsProcessed: false,
			Timestamp:   time.Now(),
		}:
		case <-time.After(5 * time.Second):
			log.Printf("è­¦å‘Š: taskStatusChan å‘é€è¶…æ—¶ï¼Œä»»åŠ¡å®Œæˆäº‹ä»¶å¯èƒ½ä¸¢å¤±: TaskID=%s", taskID)
		case <-m.ctx.Done():
			return
		}
	}
}

// executeTaskFailedHandler æ‰§è¡Œä»»åŠ¡å¤±è´¥çš„ Handlerï¼ˆç”¨äºè¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°çš„åœºæ™¯ï¼‰
// æ³¨æ„ï¼šè¿™ä¸ªæ–¹æ³•ä¸ä¼šå‘é€ TaskStatusEventï¼Œå› ä¸ºäº‹ä»¶å·²ç»åœ¨ processBatch ä¸­å‘é€è¿‡
func (m *WorkflowInstanceManagerV2) executeTaskFailedHandler(taskID string, workflowTask workflow.Task, errorMsg string) {
	// æ‰§è¡Œ Task çš„çŠ¶æ€ Handlerï¼ˆFailed çŠ¶æ€ï¼‰
	if m.registry != nil {
		statusHandlers := workflowTask.GetStatusHandlers()
		taskObj := task.NewTask(workflowTask.GetName(), workflowTask.GetDescription(), workflowTask.GetJobFuncID(), workflowTask.GetParams(), statusHandlers)
		taskObj.SetID(workflowTask.GetID())
		taskObj.SetJobFuncName(workflowTask.GetJobFuncName())
		taskObj.SetTimeoutSeconds(workflowTask.GetTimeoutSeconds())
		taskObj.SetRetryCount(workflowTask.GetRetryCount())
		taskObj.SetDependencies(workflowTask.GetDependencies())
		taskObj.SetStatus("FAILED")

		if handlerErr := task.ExecuteTaskHandlerWithContext(
			m.registry,
			taskObj,
			"FAILED",
			m.instance.WorkflowID,
			m.instance.ID,
			nil,
			errorMsg,
		); handlerErr != nil {
			log.Printf("æ‰§è¡ŒTask Handlerå¤±è´¥: Task=%s, Status=Failed, Error=%v", taskID, handlerErr)
		}
	}

	// å¦‚æœå¯ç”¨äº† SAGAï¼Œè®°å½•å¤±è´¥æ­¥éª¤
	if m.sagaEnabled && m.sagaCoordinator != nil {
		step := saga.NewTransactionStep(
			taskID,
			workflowTask.GetName(),
			"Failed",
			workflowTask.GetCompensationFuncName(),
			workflowTask.GetCompensationFuncID(),
		)
		step.ExecutedAt = time.Now().Unix()
		m.sagaCoordinator.AddStep(step)
		m.sagaCoordinator.MarkStepFailed(taskID)
		log.Printf("ğŸ” [SAGA] å·²è®°å½•å¤±è´¥æ­¥éª¤ï¼ˆè¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼‰: TaskID=%s, TaskName=%s", taskID, workflowTask.GetName())
	}
}

// createTaskErrorHandler åˆ›å»ºä»»åŠ¡é”™è¯¯å¤„ç†å™¨
func (m *WorkflowInstanceManagerV2) createTaskErrorHandler(taskID string) func(error) {
	return func(err error) {
		// ä¿å­˜é”™è¯¯ä¿¡æ¯åˆ°contextDataï¼ˆç”¨äºworkflowå¤±è´¥åˆ¤æ–­ï¼‰
		errorKey := fmt.Sprintf("%s:error", taskID)
		m.contextData.Store(errorKey, err.Error())

		// æ›´æ–°workflow.Taskçš„çŠ¶æ€ä¸ºFailed
		if workflowTask, exists := m.workflow.GetTasks()[taskID]; exists {
			workflowTask.SetStatus("FAILED")
		} else if runtimeTask, ok := m.runtimeTasks.Load(taskID); ok {
			runtimeTask.(workflow.Task).SetStatus("FAILED")
		}

		// æ‰§è¡ŒTaskçš„çŠ¶æ€Handlerï¼ˆFailedçŠ¶æ€ï¼‰
		if m.registry != nil {
			var workflowTask workflow.Task
			var exists bool
			if workflowTask, exists = m.workflow.GetTasks()[taskID]; !exists {
				if runtimeTask, ok := m.runtimeTasks.Load(taskID); ok {
					workflowTask = runtimeTask.(workflow.Task)
					exists = true
				}
			}
			if !exists {
				return
			}

			statusHandlers := workflowTask.GetStatusHandlers()
			taskObj := task.NewTask(workflowTask.GetName(), workflowTask.GetDescription(), workflowTask.GetJobFuncID(), workflowTask.GetParams(), statusHandlers)
			taskObj.SetID(workflowTask.GetID())
			taskObj.SetJobFuncName(workflowTask.GetJobFuncName())
			taskObj.SetTimeoutSeconds(workflowTask.GetTimeoutSeconds())
			taskObj.SetRetryCount(workflowTask.GetRetryCount())
			taskObj.SetDependencies(workflowTask.GetDependencies())
			taskObj.SetStatus("FAILED")

			if handlerErr := task.ExecuteTaskHandlerWithContext(
				m.registry,
				taskObj,
				"FAILED",
				m.instance.WorkflowID,
				m.instance.ID,
				nil,
				err.Error(),
			); handlerErr != nil {
				log.Printf("æ‰§è¡ŒTask Handlerå¤±è´¥: Task=%s, Status=Failed, Error=%v", taskID, handlerErr)
			}
		}

		// å¦‚æœå¯ç”¨äº†SAGAï¼Œè®°å½•å¤±è´¥æ­¥éª¤
		if m.sagaEnabled && m.sagaCoordinator != nil {
			var workflowTask workflow.Task
			var exists bool
			if workflowTask, exists = m.workflow.GetTasks()[taskID]; !exists {
				if runtimeTask, ok := m.runtimeTasks.Load(taskID); ok {
					workflowTask = runtimeTask.(workflow.Task)
					exists = true
				}
			}
			if exists {
				step := saga.NewTransactionStep(
					taskID,
					workflowTask.GetName(),
					"Failed",
					workflowTask.GetCompensationFuncName(),
					workflowTask.GetCompensationFuncID(),
				)
				step.ExecutedAt = time.Now().Unix()
				m.sagaCoordinator.AddStep(step)
				m.sagaCoordinator.MarkStepFailed(taskID)
				log.Printf("ğŸ” [SAGA] å·²è®°å½•å¤±è´¥æ­¥éª¤: TaskID=%s, TaskName=%s", taskID, workflowTask.GetName())
			}
		}

		// è§¦å‘Taskå¤±è´¥æ’ä»¶
		if m.pluginManager != nil {
			var workflowTask workflow.Task
			var exists bool
			if workflowTask, exists = m.workflow.GetTasks()[taskID]; !exists {
				if runtimeTask, ok := m.runtimeTasks.Load(taskID); ok {
					workflowTask = runtimeTask.(workflow.Task)
					exists = true
				}
			}
			if exists {
				pluginData := plugin.PluginData{
					Event:      plugin.EventTaskFailed,
					WorkflowID: m.instance.WorkflowID,
					InstanceID: m.instance.ID,
					TaskID:     taskID,
					TaskName:   workflowTask.GetName(),
					Status:     "FAILED",
					Error:      err,
					Data: map[string]interface{}{
						"error": err.Error(),
					},
				}
				if triggerErr := m.pluginManager.Trigger(m.ctx, plugin.EventTaskFailed, pluginData); triggerErr != nil {
					log.Printf("è§¦å‘Taskå¤±è´¥æ’ä»¶å¤±è´¥: TaskID=%s, Error=%v", taskID, triggerErr)
				}
			}
		}

		// å‘é€ä»»åŠ¡å¤±è´¥äº‹ä»¶åˆ°taskStatusChan
		isTemplate := false
		isSubTask := false
		parentID := ""
		if workflowTask, exists := m.workflow.GetTasks()[taskID]; exists {
			isTemplate = workflowTask.IsTemplate()
			isSubTask = workflowTask.IsSubTask()
		} else if runtimeTask, ok := m.runtimeTasks.Load(taskID); ok {
			isSubTask = runtimeTask.(workflow.Task).IsSubTask()
		}
		// è·å–å­ä»»åŠ¡çš„çˆ¶ä»»åŠ¡ID
		if isSubTask {
			parentKey := fmt.Sprintf("%s:parent_task_id", taskID)
			if parentValue, exists := m.contextData.Load(parentKey); exists {
				parentID = parentValue.(string)
			}
		}

		select {
		case m.taskStatusChan <- TaskStatusEvent{
			TaskID:      taskID,
			Status:      "Failed",
			Error:       err,
			IsTemplate:  isTemplate,
			IsSubTask:   isSubTask,
			ParentID:    parentID,
			IsProcessed: false,
			Timestamp:   time.Now(),
		}:
		case <-time.After(5 * time.Second):
			log.Printf("è­¦å‘Š: taskStatusChan å‘é€è¶…æ—¶ï¼Œä»»åŠ¡å¤±è´¥äº‹ä»¶å¯èƒ½ä¸¢å¤±: TaskID=%s", taskID)
		case <-m.ctx.Done():
			return
		}
	}
}

// InstanceManagerInterfaceV2 å®ç°InstanceManageræ¥å£çš„åŒ…è£…å™¨
type InstanceManagerInterfaceV2 struct {
	manager *WorkflowInstanceManagerV2
}

// AddSubTask æ·»åŠ å­ä»»åŠ¡
func (i *InstanceManagerInterfaceV2) AddSubTask(subTask types.Task, parentTaskID string) error {
	return i.manager.AddSubTask(subTask, parentTaskID)
}

// AtomicAddSubTasks åŸå­æ€§åœ°æ·»åŠ å¤šä¸ªå­ä»»åŠ¡
func (i *InstanceManagerInterfaceV2) AtomicAddSubTasks(subTasks []types.Task, parentTaskID string) error {
	return i.manager.AtomicAddSubTasks(subTasks, parentTaskID)
}

// controlSignalGoroutine æ§åˆ¶ä¿¡å·å¤„ç†åç¨‹
func (m *WorkflowInstanceManagerV2) controlSignalGoroutine() {
	for {
		select {
		case <-m.ctx.Done():
			log.Printf("WorkflowInstance %s: æ§åˆ¶ä¿¡å·å¤„ç†åç¨‹é€€å‡º", m.instance.ID)
			return
		case signal := <-m.controlSignalChan:
			switch signal {
			case workflow.SignalPause:
				m.handlePause()
			case workflow.SignalResume:
				m.handleResume()
			case workflow.SignalTerminate:
				m.handleTerminate()
			}
		}
	}
}

// handlePause å¤„ç†æš‚åœä¿¡å·
func (m *WorkflowInstanceManagerV2) handlePause() {
	m.mu.Lock()
	m.instance.Status = "Paused"
	m.mu.Unlock()

	ctx := context.Background()
	m.saveAllTaskStatuses(ctx)

	breakpointValue := m.CreateBreakpoint()
	breakpoint, ok := breakpointValue.(*workflow.BreakpointData)
	if !ok {
		log.Printf("WorkflowInstance %s æ–­ç‚¹æ•°æ®ç±»å‹è½¬æ¢å¤±è´¥", m.instance.ID)
		return
	}
	if m.workflowInstanceRepo != nil {
		m.workflowInstanceRepo.UpdateBreakpoint(ctx, m.instance.ID, breakpoint)
	}
	if err := m.updateWorkflowInstanceStatus(ctx, m.instance.ID, "Paused", ""); err != nil {
		log.Printf("æ›´æ–°WorkflowInstanceçŠ¶æ€å¤±è´¥: %v", err)
	}

	// è§¦å‘Workflowæš‚åœæ’ä»¶
	if m.pluginManager != nil {
		pluginData := plugin.PluginData{
			Event:      plugin.EventWorkflowPaused,
			WorkflowID: m.instance.WorkflowID,
			InstanceID: m.instance.ID,
			TaskID:     "",
			TaskName:   "",
			Status:     "Paused",
			Error:      nil,
			Data: map[string]interface{}{
				"workflow_name": m.workflow.Name,
			},
		}
		if err := m.pluginManager.Trigger(m.ctx, plugin.EventWorkflowPaused, pluginData); err != nil {
			log.Printf("è§¦å‘Workflowæš‚åœæ’ä»¶å¤±è´¥: InstanceID=%s, Error=%v", m.instance.ID, err)
		}
	}

	select {
	case m.statusUpdateChan <- "Paused":
	default:
	}

	log.Printf("WorkflowInstance %s: å·²æš‚åœ", m.instance.ID)
}

// handleResume å¤„ç†æ¢å¤ä¿¡å·
func (m *WorkflowInstanceManagerV2) handleResume() {
	m.mu.Lock()
	m.instance.Status = "Running"
	m.mu.Unlock()

	ctx := context.Background()
	if err := m.updateWorkflowInstanceStatus(ctx, m.instance.ID, "Running", ""); err != nil {
		log.Printf("æ›´æ–°WorkflowInstanceçŠ¶æ€å¤±è´¥: %v", err)
	}

	// é‡æ–°å¯åŠ¨ä»»åŠ¡æäº¤åç¨‹ï¼ˆå¦‚æœå·²åœæ­¢ï¼‰
	// æ³¨æ„ï¼šV2ç‰ˆæœ¬ä¸­ï¼Œgoroutineç”±ctxæ§åˆ¶ï¼Œæ¢å¤æ—¶ä¸éœ€è¦é‡æ–°å¯åŠ¨

	select {
	case m.statusUpdateChan <- "Running":
	default:
	}

	// è§¦å‘Workflowæ¢å¤æ’ä»¶
	if m.pluginManager != nil {
		pluginData := plugin.PluginData{
			Event:      plugin.EventWorkflowResumed,
			WorkflowID: m.instance.WorkflowID,
			InstanceID: m.instance.ID,
			TaskID:     "",
			TaskName:   "",
			Status:     "Running",
			Error:      nil,
			Data: map[string]interface{}{
				"workflow_name": m.workflow.Name,
			},
		}
		if err := m.pluginManager.Trigger(m.ctx, plugin.EventWorkflowResumed, pluginData); err != nil {
			log.Printf("è§¦å‘Workflowæ¢å¤æ’ä»¶å¤±è´¥: InstanceID=%s, Error=%v", m.instance.ID, err)
		}
	}

	log.Printf("WorkflowInstance %s: å·²æ¢å¤", m.instance.ID)
}

// handleTerminate å¤„ç†ç»ˆæ­¢ä¿¡å·
func (m *WorkflowInstanceManagerV2) handleTerminate() {
	m.mu.Lock()
	m.instance.Status = "Terminated"
	m.instance.ErrorMessage = "ç”¨æˆ·ç»ˆæ­¢"
	now := time.Now()
	m.instance.EndTime = &now
	m.mu.Unlock()

	ctx := context.Background()
	m.saveAllTaskStatuses(ctx)
	if err := m.updateWorkflowInstanceStatus(ctx, m.instance.ID, "Terminated", ""); err != nil {
		log.Printf("æ›´æ–°WorkflowInstanceçŠ¶æ€å¤±è´¥: %v", err)
	}

	select {
	case m.statusUpdateChan <- "Terminated":
	default:
	}

	// å–æ¶ˆcontextï¼Œåœæ­¢æ‰€æœ‰åç¨‹
	m.cancel()

	// è§¦å‘Workflowç»ˆæ­¢æ’ä»¶
	if m.pluginManager != nil {
		pluginData := plugin.PluginData{
			Event:      plugin.EventWorkflowTerminated,
			WorkflowID: m.instance.WorkflowID,
			InstanceID: m.instance.ID,
			TaskID:     "",
			TaskName:   "",
			Status:     "Terminated",
			Error:      fmt.Errorf("ç”¨æˆ·ç»ˆæ­¢"),
			Data: map[string]interface{}{
				"workflow_name": m.workflow.Name,
				"reason":        "ç”¨æˆ·ç»ˆæ­¢",
			},
		}
		if err := m.pluginManager.Trigger(m.ctx, plugin.EventWorkflowTerminated, pluginData); err != nil {
			log.Printf("è§¦å‘Workflowç»ˆæ­¢æ’ä»¶å¤±è´¥: InstanceID=%s, Error=%v", m.instance.ID, err)
		}
	}

	log.Printf("WorkflowInstance %s: å·²ç»ˆæ­¢", m.instance.ID)
}

// handleSubTaskAdded å¤„ç†å­ä»»åŠ¡æ·»åŠ äº‹ä»¶
// handleAtomicAddSubTasks å¤„ç†åŸå­æ€§å­ä»»åŠ¡æ·»åŠ äº‹ä»¶ï¼ˆå…³é”®æ”¹è¿›ï¼šä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰å­ä»»åŠ¡ï¼‰
// ä¿è¯æ¨¡æ¿ä»»åŠ¡æ·»åŠ å­ä»»åŠ¡çš„åŸå­æ€§
func (m *WorkflowInstanceManagerV2) handleAtomicAddSubTasks(event AtomicAddSubTasksEvent) {
	subTasks := event.SubTasks
	parentTaskID := event.ParentID

	// æ£€æŸ¥çˆ¶ä»»åŠ¡æ˜¯å¦å­˜åœ¨
	parentTask, exists := m.workflow.GetTasks()[parentTaskID]
	if !exists {
		log.Printf("è­¦å‘Š: çˆ¶ä»»åŠ¡ä¸å­˜åœ¨: ParentID=%s", parentTaskID)
		return
	}

	// å¤„ç†ç©ºå­ä»»åŠ¡åˆ—è¡¨ï¼šå¦‚æœæ¨¡æ¿ä»»åŠ¡æ²¡æœ‰ç”Ÿæˆå­ä»»åŠ¡ï¼Œéœ€è¦å‡å°‘è®¡æ•°
	// æ³¨æ„ï¼šåœ¨æ–°è®¾è®¡ä¸­ï¼Œæ¨¡æ¿ä»»åŠ¡çš„æˆåŠŸäº‹ä»¶ç”± createTaskCompleteHandler å‘é€ï¼Œè¿™é‡Œåªå‡å°‘è®¡æ•°
	if len(subTasks) == 0 {
		if parentTask.IsTemplate() {
			log.Printf("WorkflowInstance %s: æ¨¡æ¿ä»»åŠ¡ %s æ²¡æœ‰ç”Ÿæˆå­ä»»åŠ¡", m.instance.ID, parentTaskID)
			// å‡å°‘æ¨¡æ¿ä»»åŠ¡è®¡æ•°ï¼ˆæ²¡æœ‰å­ä»»åŠ¡ï¼‰
			currentLevel := m.taskQueue.GetCurrentLevel()
			m.decrementTemplateTaskCount(parentTaskID, currentLevel, 0)
		} else {
			log.Printf("è­¦å‘Š: WorkflowInstance %s: æ”¶åˆ°ç©ºçš„å­ä»»åŠ¡åˆ—è¡¨ï¼ŒParentID=%s", m.instance.ID, parentTaskID)
		}
		return
	}

	// æ³¨æ„ï¼šæ¨¡æ¿ä»»åŠ¡è®¡æ•°ç»Ÿä¸€åœ¨è¿™é‡Œå¤„ç†ï¼Œä¸ä¾èµ– handleTaskSuccess

	// é˜²æ­¢åµŒå¥—æ¨¡æ¿ä»»åŠ¡ï¼šå¦‚æœçˆ¶ä»»åŠ¡æ˜¯æ¨¡æ¿ä»»åŠ¡ï¼Œå­ä»»åŠ¡ä¸èƒ½æ˜¯æ¨¡æ¿ä»»åŠ¡
	// æ¡ä»¶ï¼šrecursiveTemplateTask := parent.isTemplate && any(subTask.isTemplate)
	for _, subTask := range subTasks {
		if parentTask.IsTemplate() && subTask.IsTemplate() {
			log.Printf("âš ï¸ é”™è¯¯: WorkflowInstance %s: æ£€æµ‹åˆ°åµŒå¥—æ¨¡æ¿ä»»åŠ¡ï¼Œçˆ¶ä»»åŠ¡ %s æ˜¯æ¨¡æ¿ä»»åŠ¡ï¼Œå­ä»»åŠ¡ %s ä¹Ÿæ˜¯æ¨¡æ¿ä»»åŠ¡ï¼Œä¸å…è®¸æ·»åŠ ï¼ˆé˜²æ­¢é€’å½’æ¨¡æ¿ä»»åŠ¡ï¼‰",
				m.instance.ID, parentTaskID, subTask.GetName())
			return
		}
	}

	// å­˜å‚¨æ‰€æœ‰å­ä»»åŠ¡åˆ°è¿è¡Œæ—¶ä»»åŠ¡ï¼ŒåŒæ—¶è®°å½•çˆ¶ä»»åŠ¡ID
	for _, subTask := range subTasks {
		m.runtimeTasks.Store(subTask.GetID(), subTask)
		// å­˜å‚¨å­ä»»åŠ¡çš„çˆ¶ä»»åŠ¡IDï¼ˆç”¨äºå­ä»»åŠ¡å®Œæˆæ—¶æŸ¥æ‰¾è·Ÿè¸ªå™¨ï¼‰
		parentKey := fmt.Sprintf("%s:parent_task_id", subTask.GetID())
		m.contextData.Store(parentKey, parentTaskID)
	}

	// åˆå§‹åŒ–æˆ–æ›´æ–°å­ä»»åŠ¡è·Ÿè¸ªå™¨ï¼ˆç”¨äºç»“æœèšåˆï¼‰
	var tracker *SubTaskTracker
	if existingTracker, exists := m.subTaskTracker.Load(parentTaskID); exists {
		// å·²å­˜åœ¨è·Ÿè¸ªå™¨ï¼Œè¿½åŠ å­ä»»åŠ¡
		tracker = existingTracker.(*SubTaskTracker)
		tracker.mu.Lock()
		for _, subTask := range subTasks {
			tracker.SubTaskIDs = append(tracker.SubTaskIDs, subTask.GetID())
		}
		atomic.AddInt32(&tracker.TotalCount, int32(len(subTasks)))
		tracker.mu.Unlock()
	} else {
		// åˆ›å»ºæ–°çš„è·Ÿè¸ªå™¨
		tracker = &SubTaskTracker{
			SubTaskIDs: make([]string, 0, len(subTasks)),
			TotalCount: int32(len(subTasks)),
		}
		for _, subTask := range subTasks {
			tracker.SubTaskIDs = append(tracker.SubTaskIDs, subTask.GetID())
		}
		m.subTaskTracker.Store(parentTaskID, tracker)
	}
	log.Printf("WorkflowInstance %s: åˆå§‹åŒ–å­ä»»åŠ¡è·Ÿè¸ªå™¨ï¼Œçˆ¶ä»»åŠ¡: %sï¼Œå­ä»»åŠ¡æ•°é‡: %d",
		m.instance.ID, parentTaskID, len(subTasks))

	// æ‰¹é‡æ›´æ–°ä»»åŠ¡ç»Ÿè®¡ï¼ˆé€šè¿‡taskStatsChanå‘é€task_addedäº‹ä»¶ï¼‰
	for _, subTask := range subTasks {
		select {
		case m.taskStatsChan <- TaskStatsUpdate{
			Type:       "task_added",
			TaskID:     subTask.GetID(),
			IsTemplate: false, // å­ä»»åŠ¡ä¸èƒ½æ˜¯æ¨¡æ¿ä»»åŠ¡
			IsSubTask:  true,
		}:
		default:
			log.Printf("è­¦å‘Š: taskStatsChan å·²æ»¡ï¼Œå­ä»»åŠ¡ç»Ÿè®¡æ›´æ–°å¯èƒ½ä¸¢å¤±: TaskID=%s", subTask.GetID())
		}
	}

	// æ£€æŸ¥æ‰€æœ‰å­ä»»åŠ¡çš„ä¾èµ–æ˜¯å¦å·²æ»¡è¶³
	allDepsProcessed := true

	// æ£€æŸ¥çˆ¶ä»»åŠ¡æ˜¯å¦å·²å®Œæˆ
	// æ³¨æ„ï¼šåœ¨æ–°è®¾è®¡ä¸­ï¼Œä¸å†åœ¨è¿™é‡Œå°†æ¨¡æ¿ä»»åŠ¡æ ‡è®°ä¸ºå·²å¤„ç†
	// è®© createTaskCompleteHandler æ¥å¤„ç†ï¼Œè¿™æ · Success Handler å¯ä»¥æ­£å¸¸æ‰§è¡Œ
	if _, processed := m.processedNodes.Load(parentTaskID); !processed {
		// å¯¹äºæ¨¡æ¿ä»»åŠ¡ï¼Œæ£€æŸ¥çŠ¶æ€æ¥åˆ¤æ–­æ˜¯å¦å·²å®Œæˆï¼ˆJob Function æ­£åœ¨æ‰§è¡Œä¸­çš„ç«æ€æƒ…å†µï¼‰
		if parentTask.IsTemplate() {
			parentStatus := parentTask.GetStatus()
			if parentStatus == "SUCCESS" || parentStatus == "Success" {
				// æ¨¡æ¿ä»»åŠ¡çŠ¶æ€æ˜¯ SUCCESSï¼Œä¾èµ–å·²æ»¡è¶³ï¼ˆä½†ä¸æ ‡è®°ä¸ºå·²å¤„ç†ï¼Œè®© createTaskCompleteHandler å¤„ç†ï¼‰
				// allDepsProcessed = true (ä¿æŒä¸º true)
			} else {
				allDepsProcessed = false
			}
		} else {
			allDepsProcessed = false
		}
	}

	// æ£€æŸ¥æ‰€æœ‰å­ä»»åŠ¡é€šè¿‡GetDependencies()å£°æ˜çš„å…¶ä»–ä¾èµ–
	if allDepsProcessed {
		for _, subTask := range subTasks {
			subTaskDeps := subTask.GetDependencies()
			for _, depName := range subTaskDeps {
				depTaskID, exists := m.workflow.GetTaskIDByName(depName)
				if !exists {
					allDepsProcessed = false
					break
				}
				if _, processed := m.processedNodes.Load(depTaskID); !processed {
					allDepsProcessed = false
					break
				}
			}
			if !allDepsProcessed {
				break
			}
		}
	}

	// è·å–çˆ¶ä»»åŠ¡çš„åŸå§‹å±‚çº§ï¼ˆä»contextDataä¸­è·å–ï¼Œåœ¨initTaskQueueä¸­ä¿å­˜ï¼‰
	parentLevel := -1
	levelKey := fmt.Sprintf("%s:original_level", parentTaskID)
	if levelValue, exists := m.contextData.Load(levelKey); exists {
		if level, ok := levelValue.(int); ok {
			parentLevel = level
		}
	}

	// ç¡®å®šç›®æ ‡å±‚çº§
	currentLevel := m.taskQueue.GetCurrentLevel()
	targetLevel := currentLevel
	if parentLevel >= 0 {
		if parentLevel < currentLevel {
			targetLevel = currentLevel
			log.Printf("è­¦å‘Š: WorkflowInstance %s: çˆ¶ä»»åŠ¡å±‚çº§ %d < å½“å‰å±‚çº§ %dï¼Œå­ä»»åŠ¡æ·»åŠ åˆ°å½“å‰å±‚çº§ %d",
				m.instance.ID, parentLevel, currentLevel, targetLevel)
		} else if parentLevel == currentLevel {
			targetLevel = parentLevel
		} else {
			targetLevel = currentLevel
		}
	}

	// å¦‚æœæ‰€æœ‰å­ä»»åŠ¡çš„ä¾èµ–éƒ½å·²æ»¡è¶³ï¼Œç›´æ¥æ‰¹é‡æ·»åŠ åˆ°é˜Ÿåˆ—
	// æ³¨æ„ï¼šå¤„ç†æ ‡è®°å·²åœ¨å‡½æ•°å¼€å§‹æ—¶è®¾ç½®ï¼ˆå¦‚æœæ˜¯æ¨¡æ¿ä»»åŠ¡ï¼‰
	if allDepsProcessed {
		// ç›´æ¥æ‰¹é‡æ·»åŠ åˆ°é˜Ÿåˆ—ï¼ˆåŸå­æ€§æ“ä½œï¼‰
		m.taskQueue.AddTasks(targetLevel, subTasks)

		// å­˜å‚¨å­ä»»åŠ¡çš„å±‚çº§ï¼ˆç”¨äº TaskCompleted æ—¶å‡å°‘ runningCountsï¼‰
		for _, subTask := range subTasks {
			levelKey := fmt.Sprintf("%s:original_level", subTask.GetID())
			m.contextData.Store(levelKey, targetLevel)
		}

		log.Printf("WorkflowInstance %s: åŸå­æ€§åœ°æ‰¹é‡æ·»åŠ  %d ä¸ªå­ä»»åŠ¡åˆ° level %dï¼Œä¾èµ–å·²æ»¡è¶³", m.instance.ID, len(subTasks), targetLevel)

		// å¦‚æœçˆ¶ä»»åŠ¡æ˜¯æ¨¡æ¿ä»»åŠ¡ï¼Œå‡å°‘æ¨¡æ¿ä»»åŠ¡è®¡æ•°
		if parentTask.IsTemplate() {
			m.decrementTemplateTaskCount(parentTaskID, targetLevel, len(subTasks))
		}
	} else {
		// ä¾èµ–æœªæ»¡è¶³ï¼Œå­˜å‚¨åˆ°contextDataç­‰å¾…åç»­å¤„ç†
		subTasksKey := fmt.Sprintf("%s:subtasks", parentTaskID)
		var subTasksList []workflow.Task
		if existing, exists := m.contextData.Load(subTasksKey); exists {
			// æ·»åŠ ç±»å‹æ£€æŸ¥ï¼Œé¿å… panic
			if list, ok := existing.([]workflow.Task); ok {
				subTasksList = list
			} else {
				log.Printf("è­¦å‘Š: WorkflowInstance %s: contextData ä¸­çš„å­ä»»åŠ¡åˆ—è¡¨ç±»å‹é”™è¯¯ï¼Œé‡æ–°åˆ›å»º", m.instance.ID)
				subTasksList = make([]workflow.Task, 0)
			}
		} else {
			subTasksList = make([]workflow.Task, 0)
		}
		// ä½¿ç”¨ append åˆ›å»ºæ–°åˆ‡ç‰‡ï¼Œé¿å…å¹¶å‘ä¿®æ”¹é—®é¢˜
		subTasksList = append(subTasksList, subTasks...)
		m.contextData.Store(subTasksKey, subTasksList)
		log.Printf("WorkflowInstance %s: %d ä¸ªå­ä»»åŠ¡å·²æ·»åŠ ï¼Œç­‰å¾…ä¾èµ–æ»¡è¶³ï¼ˆçˆ¶ä»»åŠ¡: %sï¼‰", m.instance.ID, len(subTasks), parentTaskID)
		// æ³¨æ„ï¼šåœ¨æ–°è®¾è®¡ä¸­ï¼Œæ¨¡æ¿ä»»åŠ¡çš„æˆåŠŸäº‹ä»¶ç”± createTaskCompleteHandler å‘é€
		// è¿™é‡Œä¸å†è®¾ç½®çŠ¶æ€æˆ–å‘é€äº‹ä»¶
	}

	// å¦‚æœçˆ¶ä»»åŠ¡æ˜¯æ¨¡æ¿ä»»åŠ¡ï¼Œå¤„ç†æ¨¡æ¿ä»»åŠ¡é€»è¾‘
	// æ³¨æ„ï¼šåœ¨æ–°è®¾è®¡ä¸­ï¼Œæ¨¡æ¿ä»»åŠ¡çš„ Job Function ä¼šè¢«æ­£å¸¸æ‰§è¡Œï¼ŒæˆåŠŸäº‹ä»¶ç”± createTaskCompleteHandler å‘é€
	// è¿™é‡Œä¸å†å‘é€æˆåŠŸäº‹ä»¶ï¼Œåªå¤„ç†å­ä»»åŠ¡æ·»åŠ åçš„ä¾èµ–æ£€æŸ¥
	if parentTask.IsTemplate() {
		// å¦‚æœä¾èµ–æœªæ»¡è¶³ï¼Œå°è¯•æ‰¹é‡æ·»åŠ å­ä»»åŠ¡ï¼ˆç”¨äºå¤„ç†åç»­ä¾èµ–æ»¡è¶³çš„æƒ…å†µï¼‰
		if !allDepsProcessed {
			m.tryBatchAddSubTasks(parentTaskID, parentTask, targetLevel)
		}
	}
}

// decrementTemplateTaskCount å‡å°‘æ¨¡æ¿ä»»åŠ¡è®¡æ•°ï¼ˆç»Ÿä¸€æ–¹æ³•ï¼‰
func (m *WorkflowInstanceManagerV2) decrementTemplateTaskCount(parentTaskID string, targetLevel int, subTaskCount int) {
	key := fmt.Sprintf("%s:template_count_decremented", parentTaskID)
	if _, decremented := m.contextData.LoadOrStore(key, true); !decremented {
		// ä½¿ç”¨ CAS åŸå­æ€§åœ°å‡å°‘ templateTaskCount
		for {
			oldValue := m.templateTaskCount.Load()
			if oldValue <= 0 {
				log.Printf("è­¦å‘Š: templateTaskCount <= 0ï¼Œæ— æ³•å‡å°‘ï¼ŒParentTaskID=%s", parentTaskID)
				break
			}
			newValue := oldValue - 1
			if m.templateTaskCount.CompareAndSwap(oldValue, newValue) {
				// CAS æˆåŠŸï¼ŒåŒæ—¶æ›´æ–° templateTaskCounts[currentLevel]ï¼ˆç»Ÿä¸€ä½¿ç”¨ currentLevelï¼‰
				currentLevel := m.taskQueue.GetCurrentLevel()
				if currentLevel < len(m.templateTaskCounts) {
					m.templateTaskCounts[currentLevel].Store(newValue)
				}
				log.Printf("WorkflowInstance %s: æ¨¡æ¿ä»»åŠ¡ %s çš„æ‰€æœ‰å­ä»»åŠ¡ï¼ˆ%dä¸ªï¼‰å·²æ‰¹é‡æ·»åŠ åˆ° level %dï¼ŒtemplateTaskCount ä» %d å‡å°‘åˆ° %d",
					m.instance.ID, parentTaskID, subTaskCount, targetLevel, oldValue, newValue)
				break
			}
			// CAS å¤±è´¥ï¼Œé‡è¯•
		}
	}
}

// tryBatchAddSubTasks å°è¯•æ‰¹é‡æ·»åŠ å­ä»»åŠ¡
// å½“ä¾èµ–æ»¡è¶³æ—¶ï¼Œæ‰¹é‡æ·»åŠ å­ä»»åŠ¡åˆ°é˜Ÿåˆ—
func (m *WorkflowInstanceManagerV2) tryBatchAddSubTasks(parentTaskID string, parentTask workflow.Task, targetLevel int) {
	subTasksKey := fmt.Sprintf("%s:subtasks", parentTaskID)
	subTasksValue, exists := m.contextData.Load(subTasksKey)
	if !exists {
		return
	}

	// æ·»åŠ ç±»å‹æ£€æŸ¥ï¼Œé¿å… panic
	subTasksList, ok := subTasksValue.([]workflow.Task)
	if !ok {
		log.Printf("è­¦å‘Š: WorkflowInstance %s: contextData ä¸­çš„å­ä»»åŠ¡åˆ—è¡¨ç±»å‹é”™è¯¯ï¼ŒParentTaskID=%s", m.instance.ID, parentTaskID)
		m.contextData.Delete(subTasksKey)
		return
	}

	if len(subTasksList) == 0 {
		return
	}

	// æ£€æŸ¥å½“å‰å±‚çº§
	currentLevel := m.taskQueue.GetCurrentLevel()
	if currentLevel != targetLevel {
		// å±‚çº§å·²æ¨è¿›ï¼Œä¸éœ€è¦æ£€æŸ¥
		return
	}

	// æ£€æŸ¥æ‰€æœ‰å­ä»»åŠ¡çš„ä¾èµ–æ˜¯å¦å·²æ»¡è¶³
	allDepsProcessed := true
	if _, processed := m.processedNodes.Load(parentTaskID); !processed {
		allDepsProcessed = false
	}

	// æ£€æŸ¥æ‰€æœ‰å­ä»»åŠ¡é€šè¿‡GetDependencies()å£°æ˜çš„å…¶ä»–ä¾èµ–
	if allDepsProcessed {
		for _, subTask := range subTasksList {
			subTaskDeps := subTask.GetDependencies()
			for _, depName := range subTaskDeps {
				depTaskID, exists := m.workflow.GetTaskIDByName(depName)
				if !exists {
					allDepsProcessed = false
					break
				}
				if _, processed := m.processedNodes.Load(depTaskID); !processed {
					allDepsProcessed = false
					break
				}
			}
			if !allDepsProcessed {
				break
			}
		}
	}

	// åªæœ‰å½“æ‰€æœ‰ä¾èµ–éƒ½æ»¡è¶³æ—¶ï¼Œæ‰æ‰¹é‡æ·»åŠ å­ä»»åŠ¡
	if allDepsProcessed {
		// æ‰¹é‡æ·»åŠ å­ä»»åŠ¡
		m.taskQueue.AddTasks(targetLevel, subTasksList)

		// å­˜å‚¨å­ä»»åŠ¡çš„å±‚çº§ï¼ˆç”¨äº TaskCompleted æ—¶å‡å°‘ runningCountsï¼‰
		for _, subTask := range subTasksList {
			levelKey := fmt.Sprintf("%s:original_level", subTask.GetID())
			m.contextData.Store(levelKey, targetLevel)
		}

		// æ¸…ç©ºå·²æ”¶é›†çš„å­ä»»åŠ¡åˆ—è¡¨
		m.contextData.Delete(subTasksKey)

		// å¦‚æœçˆ¶ä»»åŠ¡æ˜¯æ¨¡æ¿ä»»åŠ¡ï¼Œå‡å°‘æ¨¡æ¿ä»»åŠ¡è®¡æ•°
		if parentTask.IsTemplate() {
			m.decrementTemplateTaskCount(parentTaskID, targetLevel, len(subTasksList))
		}
	}
}

// AddSubTask åŠ¨æ€æ·»åŠ å­ä»»åŠ¡åˆ°WorkflowInstanceï¼ˆå…¬å…±æ–¹æ³•ï¼Œå®ç°æ¥å£ï¼‰
func (m *WorkflowInstanceManagerV2) AddSubTask(subTask types.Task, parentTaskID string) error {
	if subTask == nil {
		return fmt.Errorf("å­Taskä¸èƒ½ä¸ºç©º")
	}
	if subTask.GetID() == "" {
		return fmt.Errorf("å­Task IDä¸èƒ½ä¸ºç©º")
	}
	if subTask.GetName() == "" {
		return fmt.Errorf("å­Taskåç§°ä¸èƒ½ä¸ºç©º")
	}

	// ç±»å‹è½¬æ¢ï¼štypes.Task -> workflow.Task
	workflowTask, ok := subTask.(workflow.Task)
	if !ok {
		return fmt.Errorf("å­Taskç±»å‹è½¬æ¢å¤±è´¥")
	}

	// è®¾ç½®isSubTaskæ ‡å¿—
	workflowTask.SetSubTask(true)

	// ä½¿ç”¨Workflowçš„AddSubTaskæ–¹æ³•ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
	if err := m.workflow.AddSubTask(workflowTask, parentTaskID); err != nil {
		return err
	}

	// å‘é€å­ä»»åŠ¡æ·»åŠ äº‹ä»¶åˆ°ä¸“ç”¨channelï¼ˆç»Ÿä¸€äº‹ä»¶å¤„ç†æ¨¡å¼ï¼Œå°†å•ä¸ªå­ä»»åŠ¡åŒ…è£…æˆæ•°ç»„ï¼‰
	select {
	case m.addSubTaskChan <- AtomicAddSubTasksEvent{
		SubTasks:  []workflow.Task{workflowTask}, // å°†å•ä¸ªå­ä»»åŠ¡åŒ…è£…æˆæ•°ç»„
		ParentID:  parentTaskID,
		Timestamp: time.Now(),
	}:
		// äº‹ä»¶å·²å‘é€
	case <-time.After(5 * time.Second):
		log.Printf("è­¦å‘Š: addSubTaskChan å‘é€è¶…æ—¶ï¼Œå­ä»»åŠ¡æ·»åŠ äº‹ä»¶å¯èƒ½ä¸¢å¤±: TaskID=%s", workflowTask.GetID())
		return fmt.Errorf("å­ä»»åŠ¡æ·»åŠ äº‹ä»¶å‘é€è¶…æ—¶")
	case <-m.ctx.Done():
		return fmt.Errorf("Context å·²å–æ¶ˆ")
	}

	return nil
}

// AtomicAddSubTasks åŸå­æ€§åœ°æ·»åŠ å¤šä¸ªå­ä»»åŠ¡åˆ°WorkflowInstanceï¼ˆå…¬å…±æ–¹æ³•ï¼Œå®ç°æ¥å£ï¼‰
// ä¿è¯è¦ä¹ˆå…¨éƒ¨æˆåŠŸï¼Œè¦ä¹ˆå…¨éƒ¨å¤±è´¥ï¼ˆå›æ»šï¼‰
func (m *WorkflowInstanceManagerV2) AtomicAddSubTasks(subTasks []types.Task, parentTaskID string) error {
	if len(subTasks) == 0 {
		return nil // ç©ºåˆ—è¡¨ï¼Œç›´æ¥è¿”å›æˆåŠŸ
	}

	// éªŒè¯æ‰€æœ‰å­ä»»åŠ¡
	for i, subTask := range subTasks {
		// ä½¿ç”¨åå°„æ£€æŸ¥æ¥å£æ˜¯å¦ä¸ºnilï¼ˆå¤„ç†æ¥å£ç±»å‹çš„nilï¼‰
		if subTask == nil {
			return fmt.Errorf("å­ä»»åŠ¡[%d]ä¸èƒ½ä¸ºç©º", i)
		}
		// ä½¿ç”¨åå°„æ£€æŸ¥æ¥å£çš„åº•å±‚å€¼æ˜¯å¦ä¸ºnil
		rv := reflect.ValueOf(subTask)
		if rv.Kind() == reflect.Interface || rv.Kind() == reflect.Ptr {
			if rv.IsNil() {
				return fmt.Errorf("å­ä»»åŠ¡[%d]ä¸èƒ½ä¸ºç©º", i)
			}
		}
		// å®‰å…¨åœ°è°ƒç”¨GetID
		taskID := subTask.GetID()
		if taskID == "" {
			return fmt.Errorf("å­ä»»åŠ¡[%d] IDä¸èƒ½ä¸ºç©º", i)
		}
		taskName := subTask.GetName()
		if taskName == "" {
			return fmt.Errorf("å­ä»»åŠ¡[%d]åç§°ä¸èƒ½ä¸ºç©º", i)
		}
	}

	// ç±»å‹è½¬æ¢ï¼štypes.Task -> workflow.Task
	workflowTasks := make([]workflow.Task, 0, len(subTasks))
	for _, subTask := range subTasks {
		workflowTask, ok := subTask.(workflow.Task)
		if !ok {
			return fmt.Errorf("å­ä»»åŠ¡ç±»å‹è½¬æ¢å¤±è´¥: TaskID=%s", subTask.GetID())
		}
		workflowTasks = append(workflowTasks, workflowTask)
	}

	// è®°å½•å·²æ·»åŠ çš„å­ä»»åŠ¡ï¼Œç”¨äºå›æ»š
	addedSubTasks := make([]workflow.Task, 0, len(workflowTasks))

	// ç¬¬ä¸€æ­¥ï¼šæ·»åŠ æ‰€æœ‰å­ä»»åŠ¡åˆ°Workflowï¼ˆå¦‚æœå¤±è´¥ï¼Œå›æ»šï¼‰
	for _, subTask := range workflowTasks {
		// è®¾ç½®isSubTaskæ ‡å¿—
		subTask.SetSubTask(true)

		// ä½¿ç”¨Workflowçš„AddSubTaskæ–¹æ³•ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
		if err := m.workflow.AddSubTask(subTask, parentTaskID); err != nil {
			// å›æ»šå·²æ·»åŠ çš„å­ä»»åŠ¡
			for _, addedTask := range addedSubTasks {
				m.workflow.Tasks.Delete(addedTask.GetID())
				m.workflow.Dependencies.Delete(addedTask.GetID())
				// ä»TaskNameIndexä¸­åˆ é™¤
				if taskName := addedTask.GetName(); taskName != "" {
					m.workflow.TaskNameIndex.Delete(taskName)
				}
			}
			return fmt.Errorf("æ·»åŠ å­ä»»åŠ¡åˆ°Workflowå¤±è´¥: %w", err)
		}
		addedSubTasks = append(addedSubTasks, subTask)
	}

	// ç¬¬äºŒæ­¥ï¼šå‘é€åŸå­æ€§å­ä»»åŠ¡æ·»åŠ äº‹ä»¶åˆ°ä¸“ç”¨channelï¼ˆç»Ÿä¸€äº‹ä»¶å¤„ç†æ¨¡å¼ï¼Œä¸€æ¬¡æ€§æäº¤æ‰€æœ‰ä»»åŠ¡ï¼‰
	// å¦‚æœäº‹ä»¶å‘é€å¤±è´¥ï¼Œå›æ»šæ‰€æœ‰å·²æ·»åŠ çš„å­ä»»åŠ¡
	select {
	case m.addSubTaskChan <- AtomicAddSubTasksEvent{
		SubTasks:  workflowTasks, // ä¸€æ¬¡æ€§æäº¤æ‰€æœ‰å­ä»»åŠ¡
		ParentID:  parentTaskID,
		Timestamp: time.Now(),
	}:
		// äº‹ä»¶å·²å‘é€
		log.Printf("WorkflowInstance %s: åŸå­æ€§åœ°æ‰¹é‡æ·»åŠ  %d ä¸ªå­ä»»åŠ¡æˆåŠŸï¼Œçˆ¶ä»»åŠ¡: %s", m.instance.ID, len(workflowTasks), parentTaskID)
		return nil
	case <-time.After(5 * time.Second):
		// å‘é€è¶…æ—¶ï¼Œå›æ»šæ‰€æœ‰å·²æ·»åŠ çš„å­ä»»åŠ¡
		for _, addedTask := range addedSubTasks {
			m.workflow.Tasks.Delete(addedTask.GetID())
			m.workflow.Dependencies.Delete(addedTask.GetID())
			// ä»TaskNameIndexä¸­åˆ é™¤
			if taskName := addedTask.GetName(); taskName != "" {
				m.workflow.TaskNameIndex.Delete(taskName)
			}
		}
		log.Printf("è­¦å‘Š: addSubTaskChan å‘é€è¶…æ—¶ï¼ŒåŸå­æ€§å­ä»»åŠ¡æ·»åŠ äº‹ä»¶å¯èƒ½ä¸¢å¤±: ParentID=%s, Count=%d", parentTaskID, len(workflowTasks))
		return fmt.Errorf("åŸå­æ€§å­ä»»åŠ¡æ·»åŠ äº‹ä»¶å‘é€è¶…æ—¶")
	case <-m.ctx.Done():
		// Contextå·²å–æ¶ˆï¼Œå›æ»šæ‰€æœ‰å·²æ·»åŠ çš„å­ä»»åŠ¡
		for _, addedTask := range addedSubTasks {
			m.workflow.Tasks.Delete(addedTask.GetID())
			m.workflow.Dependencies.Delete(addedTask.GetID())
			// ä»TaskNameIndexä¸­åˆ é™¤
			if taskName := addedTask.GetName(); taskName != "" {
				m.workflow.TaskNameIndex.Delete(taskName)
			}
		}
		return fmt.Errorf("Context å·²å–æ¶ˆ")
	}
}

// Shutdown ä¼˜é›…å…³é—­WorkflowInstanceManagerï¼ˆå…¬å…±æ–¹æ³•ï¼Œå®ç°æ¥å£ï¼‰
func (m *WorkflowInstanceManagerV2) Shutdown() {
	// å–æ¶ˆcontextï¼Œé€šçŸ¥æ‰€æœ‰åç¨‹é€€å‡º
	m.cancel()

	// ç­‰å¾…æ‰€æœ‰åç¨‹å®Œæˆï¼ˆæœ€å¤šç­‰å¾…30ç§’ï¼‰
	done := make(chan struct{})
	go func() {
		m.wg.Wait()
		close(done)
	}()

	select {
	case <-done:
		log.Printf("WorkflowInstance %s: æ‰€æœ‰åç¨‹å·²é€€å‡º", m.instance.ID)
	case <-time.After(30 * time.Second):
		log.Printf("WorkflowInstance %s: ç­‰å¾…åç¨‹é€€å‡ºè¶…æ—¶", m.instance.ID)
	}
}

// GetControlSignalChannel è·å–æ§åˆ¶ä¿¡å·é€šé“ï¼ˆå…¬å…±æ–¹æ³•ï¼Œå®ç°æ¥å£ï¼‰
func (m *WorkflowInstanceManagerV2) GetControlSignalChannel() interface{} {
	return m.controlSignalChan
}

// GetStatusUpdateChannel è·å–çŠ¶æ€æ›´æ–°é€šé“ï¼ˆå…¬å…±æ–¹æ³•ï¼Œå®ç°æ¥å£ï¼‰
func (m *WorkflowInstanceManagerV2) GetStatusUpdateChannel() <-chan string {
	return m.statusUpdateChan
}

// GetInstanceID è·å–WorkflowInstance IDï¼ˆå…¬å…±æ–¹æ³•ï¼Œå®ç°æ¥å£ï¼‰
func (m *WorkflowInstanceManagerV2) GetInstanceID() string {
	m.mu.RLock()
	defer m.mu.RUnlock()
	return m.instance.ID
}

// GetStatus è·å–WorkflowInstanceçŠ¶æ€ï¼ˆå…¬å…±æ–¹æ³•ï¼Œå®ç°æ¥å£ï¼‰
func (m *WorkflowInstanceManagerV2) GetStatus() string {
	m.mu.RLock()
	defer m.mu.RUnlock()
	return m.instance.Status
}

// GetProgress è·å–å½“å‰å®ä¾‹çš„å†…å­˜ä¸­ä»»åŠ¡è¿›åº¦ï¼ˆå…¬å…±æ–¹æ³•ï¼Œå®ç°æ¥å£ï¼‰
// ä» taskStats åŸå­è¯»å–ï¼ŒåŒ…å«åŠ¨æ€å­ä»»åŠ¡ï¼Œç”¨äºè¿è¡Œä¸­å®ä¾‹çš„å®æ—¶è¿›åº¦å±•ç¤º
// RunningTaskIDs / PendingTaskIDs ç”¨äºæ’æŸ¥è¿›åº¦å¡åœ¨ 99.x% æ—¶å®šä½æœªå®Œæˆä»»åŠ¡
func (m *WorkflowInstanceManagerV2) GetProgress() types.ProgressSnapshot {
	total := int(atomic.LoadInt32(&m.taskStats.TotalTasks))
	completed := int(atomic.LoadInt32(&m.taskStats.SuccessTasks))
	failed := int(atomic.LoadInt32(&m.taskStats.FailedTasks))
	pending := int(atomic.LoadInt32(&m.taskStats.PendingTasks))
	running := total - completed - failed - pending
	if running < 0 {
		running = 0
	}
	var runningIDs, pendingIDs []string
	if m.taskQueue != nil {
		currentLevel := m.taskQueue.GetCurrentLevel()
		pendingIDs = m.taskQueue.GetTaskIDsAtLevel(currentLevel)
	}
	m.runningTaskIDs.Range(func(key, _ interface{}) bool {
		runningIDs = append(runningIDs, key.(string))
		return true
	})
	return types.ProgressSnapshot{
		Total:          total,
		Completed:      completed,
		Running:        running,
		Failed:         failed,
		Pending:        pending,
		RunningTaskIDs: runningIDs,
		PendingTaskIDs: pendingIDs,
	}
}

// Context è·å–contextï¼ˆå…¬å…±æ–¹æ³•ï¼Œå®ç°æ¥å£ï¼‰
func (m *WorkflowInstanceManagerV2) Context() context.Context {
	return m.ctx
}

// CreateBreakpoint åˆ›å»ºæ–­ç‚¹æ•°æ®ï¼ˆå…¬å…±æ–¹æ³•ï¼Œå®ç°æ¥å£ï¼‰
func (m *WorkflowInstanceManagerV2) CreateBreakpoint() interface{} {
	completedTaskNames := make([]string, 0)
	m.processedNodes.Range(func(key, value interface{}) bool {
		taskID := key.(string)
		if t, exists := m.workflow.GetTasks()[taskID]; exists {
			completedTaskNames = append(completedTaskNames, t.GetName())
		} else if runtimeTask, ok := m.runtimeTasks.Load(taskID); ok {
			completedTaskNames = append(completedTaskNames, runtimeTask.(workflow.Task).GetName())
		}
		return true
	})

	runningTaskNames := make([]string, 0)

	// DAGå¿«ç…§ï¼ˆç®€åŒ–å¤„ç†ï¼‰
	dagSnapshot := make(map[string]interface{})
	// è·å–DAGçš„èŠ‚ç‚¹æ•°ï¼ˆç®€åŒ–å¤„ç†ï¼‰
	allTasks := m.workflow.GetTasks()
	dagSnapshot["node_count"] = len(allTasks)

	// å°† sync.Map è½¬æ¢ä¸º map[string]interface{} ç”¨äºåºåˆ—åŒ–
	contextDataMap := make(map[string]interface{})
	m.contextData.Range(func(key, value interface{}) bool {
		if keyStr, ok := key.(string); ok {
			contextDataMap[keyStr] = value
		}
		return true
	})

	return &workflow.BreakpointData{
		CompletedTaskNames: completedTaskNames,
		RunningTaskNames:   runningTaskNames,
		DAGSnapshot:        dagSnapshot,
		ContextData:        contextDataMap,
		LastUpdateTime:     time.Now(),
	}
}

// RestoreFromBreakpoint ä»æ–­ç‚¹æ•°æ®æ¢å¤WorkflowInstanceçŠ¶æ€ï¼ˆå…¬å…±æ–¹æ³•ï¼Œå®ç°æ¥å£ï¼‰
func (m *WorkflowInstanceManagerV2) RestoreFromBreakpoint(breakpoint interface{}) error {
	if breakpoint == nil {
		return nil
	}

	bp, ok := breakpoint.(*workflow.BreakpointData)
	if !ok {
		return fmt.Errorf("æ–­ç‚¹æ•°æ®ç±»å‹é”™è¯¯ï¼ŒæœŸæœ› *workflow.BreakpointData")
	}

	// 1. æ¢å¤å·²å®Œæˆçš„Taskåˆ—è¡¨
	m.processedNodes = sync.Map{}
	for _, taskName := range bp.CompletedTaskNames {
		if taskID, exists := m.workflow.GetTaskIDByName(taskName); exists {
			m.processedNodes.Store(taskID, true)
		}
	}

	// 2. æ¢å¤ä¸Šä¸‹æ–‡æ•°æ®
	m.contextData = sync.Map{}
	if bp.ContextData != nil {
		for k, v := range bp.ContextData {
			m.contextData.Store(k, v)
		}
	}

	// 3. é‡æ–°åˆå§‹åŒ–ä»»åŠ¡é˜Ÿåˆ—ï¼ˆåŸºäºå·²å®Œæˆçš„Taskï¼‰
	// æ³¨æ„ï¼šV2ç‰ˆæœ¬ä½¿ç”¨é˜Ÿåˆ—ï¼Œéœ€è¦é‡æ–°åˆå§‹åŒ–
	m.initTaskQueue()

	// 4. æ¢å¤ä»»åŠ¡ç»Ÿè®¡ï¼ˆé€šè¿‡taskStatsChanå‘é€task_completedäº‹ä»¶ï¼‰
	// æ³¨æ„ï¼šå·²å®Œæˆçš„ä»»åŠ¡åœ¨initTaskQueueä¸­å·²ç»é€šè¿‡task_addedäº‹ä»¶æ·»åŠ åˆ°ç»Ÿè®¡ä¸­
	// è¿™é‡Œéœ€è¦ä¸ºå·²å®Œæˆçš„ä»»åŠ¡å‘é€task_completedäº‹ä»¶
	for _, taskName := range bp.CompletedTaskNames {
		if taskID, exists := m.workflow.GetTaskIDByName(taskName); exists {
			// æ£€æŸ¥ä»»åŠ¡çŠ¶æ€ï¼Œç¡®å®šæ˜¯æˆåŠŸè¿˜æ˜¯å¤±è´¥
			task := m.workflow.GetTasks()[taskID]
			status := "task_completed"
			if task.GetStatus() == "FAILED" {
				status = "task_failed"
			}
			select {
			case m.taskStatsChan <- TaskStatsUpdate{
				Type:       status,
				TaskID:     taskID,
				IsTemplate: task.IsTemplate(),
				IsSubTask:  task.IsSubTask(),
			}:
			default:
				log.Printf("è­¦å‘Š: taskStatsChan å·²æ»¡ï¼Œä»»åŠ¡ç»Ÿè®¡æ¢å¤å¯èƒ½ä¸¢å¤±: TaskID=%s", taskID)
			}
		}
	}

	return nil
}

// saveAllTaskStatuses æ‰¹é‡ä¿å­˜æ‰€æœ‰ä»»åŠ¡çŠ¶æ€åˆ°æ•°æ®åº“ï¼ˆåªä¿å­˜é¢„å®šä¹‰ä»»åŠ¡ï¼Œè·³è¿‡åŠ¨æ€ä»»åŠ¡ï¼‰
func (m *WorkflowInstanceManagerV2) saveAllTaskStatuses(ctx context.Context) {
	// å¦‚æœæ²¡æœ‰ä»»ä½•Repositoryï¼Œè·³è¿‡ä¿å­˜
	if m.aggregateRepo == nil && m.taskRepo == nil {
		log.Printf("âš ï¸ è­¦å‘Šï¼WorkflowInstance %s: æ²¡æœ‰å¯ç”¨çš„Repositoryï¼Œè·³è¿‡ä¿å­˜", m.instance.ID)
		return
	}

	allTasks := m.workflow.GetTasks()
	savedCount := 0
	skippedCount := 0

	// è·å–å·²å­˜åœ¨çš„ä»»åŠ¡å®ä¾‹ï¼ˆç”¨äºæ¯”è¾ƒçŠ¶æ€ï¼‰
	var taskInstanceMap map[string]*storage.TaskInstance
	if m.aggregateRepo != nil {
		_, taskInstances, err := m.aggregateRepo.GetWorkflowInstanceWithTasks(ctx, m.instance.ID)
		if err != nil {
			log.Printf("âš ï¸ WorkflowInstance %s: æŸ¥è¯¢ä»»åŠ¡å®ä¾‹å¤±è´¥: %v", m.instance.ID, err)
			return
		}
		taskInstanceMap = make(map[string]*storage.TaskInstance)
		for _, ti := range taskInstances {
			taskInstanceMap[ti.ID] = ti
		}
	} else if m.taskRepo != nil {
		taskInstances, err := m.taskRepo.GetByWorkflowInstanceID(ctx, m.instance.ID)
		if err != nil {
			log.Printf("âš ï¸ WorkflowInstance %s: æŸ¥è¯¢ä»»åŠ¡å®ä¾‹å¤±è´¥: %v", m.instance.ID, err)
			return
		}
		taskInstanceMap = make(map[string]*storage.TaskInstance)
		for _, ti := range taskInstances {
			taskInstanceMap[ti.ID] = ti
		}
	}

	for taskID, workflowTask := range allTasks {
		// è·³è¿‡åŠ¨æ€ç”Ÿæˆçš„å­ä»»åŠ¡ï¼ˆä¸ä¿å­˜åˆ°æ•°æ®åº“ï¼‰
		if workflowTask.IsSubTask() {
			skippedCount++
			continue
		}

		existingTask, exists := taskInstanceMap[taskID]
		if !exists {
			log.Printf("âš ï¸ WorkflowInstance %s: Task %s ä¸åœ¨æ•°æ®åº“ä¸­ï¼Œè·³è¿‡ä¿å­˜", m.instance.ID, taskID)
			skippedCount++
			continue
		}

		currentStatus := workflowTask.GetStatus()
		if currentStatus == "" {
			if _, processed := m.processedNodes.Load(taskID); processed {
				errorKey := fmt.Sprintf("%s:error", taskID)
				if _, hasError := m.contextData.Load(errorKey); hasError {
					currentStatus = "Failed"
				} else {
					currentStatus = "Success"
				}
			} else {
				continue
			}
		}

		if existingTask.Status == currentStatus {
			continue
		}

		var updateErr error
		if currentStatus == "Failed" {
			errorKey := fmt.Sprintf("%s:error", taskID)
			errorMsg := ""
			if errorValue, hasError := m.contextData.Load(errorKey); hasError {
				if errStr, ok := errorValue.(string); ok {
					errorMsg = errStr
				}
			}
			updateErr = m.updateTaskInstanceStatusWithError(ctx, taskID, currentStatus, errorMsg)
		} else {
			updateErr = m.updateTaskInstanceStatus(ctx, taskID, currentStatus)
		}

		if updateErr != nil {
			log.Printf("âš ï¸ WorkflowInstance %s: æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥: TaskID=%s, Status=%s, Error=%v",
				m.instance.ID, taskID, currentStatus, updateErr)
		} else {
			savedCount++
		}
	}

	if savedCount > 0 || skippedCount > 0 {
		log.Printf("ğŸ“Š WorkflowInstance %s: æ‰¹é‡ä¿å­˜ä»»åŠ¡çŠ¶æ€å®Œæˆ - å·²ä¿å­˜: %d, è·³è¿‡åŠ¨æ€ä»»åŠ¡: %d",
			m.instance.ID, savedCount, skippedCount)
	}
}

// ==================== RepositoryæŠ½è±¡æ–¹æ³•ï¼ˆæ”¯æŒèšåˆRepositoryï¼‰ ====================

// updateWorkflowInstanceStatus æ›´æ–°WorkflowInstanceçŠ¶æ€ï¼ˆä¼˜å…ˆä½¿ç”¨èšåˆRepositoryï¼‰
func (m *WorkflowInstanceManagerV2) updateWorkflowInstanceStatus(ctx context.Context, instanceID, status, errorMsg string) error {
	// ä¼˜å…ˆä½¿ç”¨èšåˆRepository
	if m.aggregateRepo != nil {
		// èšåˆRepositoryä¸æ”¯æŒå•ç‹¬æ›´æ–°WorkflowInstanceçŠ¶æ€ï¼Œä½¿ç”¨åŸºç¡€Repository
		// æ³¨ï¼šèšåˆRepositoryä¸»è¦ç”¨äºäº‹åŠ¡æ“ä½œï¼ŒçŠ¶æ€æ›´æ–°ä»ä½¿ç”¨åŸæœ‰Repository
	}
	// ä½¿ç”¨åŸæœ‰Repository
	if m.workflowInstanceRepo != nil {
		return m.workflowInstanceRepo.UpdateStatus(ctx, instanceID, status)
	}
	return nil
}

// updateTaskInstanceStatus æ›´æ–°TaskInstanceçŠ¶æ€ï¼ˆä¼˜å…ˆä½¿ç”¨èšåˆRepositoryï¼‰
func (m *WorkflowInstanceManagerV2) updateTaskInstanceStatus(ctx context.Context, taskID, status string) error {
	// ä¼˜å…ˆä½¿ç”¨èšåˆRepository
	if m.aggregateRepo != nil {
		return m.aggregateRepo.UpdateTaskInstanceStatus(ctx, taskID, status)
	}
	// ä½¿ç”¨åŸæœ‰Repository
	if m.taskRepo != nil {
		return m.taskRepo.UpdateStatus(ctx, taskID, status)
	}
	return nil
}

// updateTaskInstanceStatusWithError æ›´æ–°TaskInstanceçŠ¶æ€å’Œé”™è¯¯ä¿¡æ¯ï¼ˆä¼˜å…ˆä½¿ç”¨èšåˆRepositoryï¼‰
func (m *WorkflowInstanceManagerV2) updateTaskInstanceStatusWithError(ctx context.Context, taskID, status, errorMsg string) error {
	// ä¼˜å…ˆä½¿ç”¨èšåˆRepository
	if m.aggregateRepo != nil {
		return m.aggregateRepo.UpdateTaskInstanceStatusWithError(ctx, taskID, status, errorMsg)
	}
	// ä½¿ç”¨åŸæœ‰Repository
	if m.taskRepo != nil {
		return m.taskRepo.UpdateStatusWithError(ctx, taskID, status, errorMsg)
	}
	return nil
}

// ==================== å­ä»»åŠ¡ç»“æœèšåˆç›¸å…³æ–¹æ³• ====================

// handleSubTaskCompletion å¤„ç†å­ä»»åŠ¡å®Œæˆäº‹ä»¶ï¼ˆè®°å½•ç»“æœï¼Œè§¦å‘èšåˆï¼‰
func (m *WorkflowInstanceManagerV2) handleSubTaskCompletion(event TaskStatusEvent) {
	// è·å–å­ä»»åŠ¡ä¿¡æ¯
	var subTask workflow.Task
	if runtimeTask, ok := m.runtimeTasks.Load(event.TaskID); ok {
		subTask = runtimeTask.(workflow.Task)
	} else {
		log.Printf("è­¦å‘Š: WorkflowInstance %s: å­ä»»åŠ¡ %s åœ¨ runtimeTasks ä¸­ä¸å­˜åœ¨", m.instance.ID, event.TaskID)
		return
	}

	// è·å–çˆ¶ä»»åŠ¡ID
	parentTaskID := event.ParentID
	if parentTaskID == "" {
		// å°è¯•ä» contextData ä¸­è·å–çˆ¶ä»»åŠ¡ID
		parentKey := fmt.Sprintf("%s:parent_task_id", event.TaskID)
		if parentValue, exists := m.contextData.Load(parentKey); exists {
			parentTaskID = parentValue.(string)
		}
	}
	if parentTaskID == "" {
		// å°è¯•ä»å­ä»»åŠ¡çš„ä¾èµ–ä¸­è·å–çˆ¶ä»»åŠ¡ID
		deps := subTask.GetDependencies()
		if len(deps) > 0 {
			// å‡è®¾ç¬¬ä¸€ä¸ªä¾èµ–æ˜¯çˆ¶ä»»åŠ¡
			if taskID, exists := m.workflow.GetTaskIDByName(deps[0]); exists {
				parentTaskID = taskID
			}
		}
	}

	if parentTaskID == "" {
		log.Printf("è­¦å‘Š: WorkflowInstance %s: æ— æ³•ç¡®å®šå­ä»»åŠ¡ %s çš„çˆ¶ä»»åŠ¡ID", m.instance.ID, event.TaskID)
		return
	}

	// è·å–å­ä»»åŠ¡è·Ÿè¸ªå™¨
	trackerValue, exists := m.subTaskTracker.Load(parentTaskID)
	if !exists {
		log.Printf("è­¦å‘Š: WorkflowInstance %s: çˆ¶ä»»åŠ¡ %s çš„å­ä»»åŠ¡è·Ÿè¸ªå™¨ä¸å­˜åœ¨", m.instance.ID, parentTaskID)
		return
	}
	tracker := trackerValue.(*SubTaskTracker)

	// è®°å½•å­ä»»åŠ¡ç»“æœ
	subTaskResult := SubTaskResult{
		TaskID:   event.TaskID,
		TaskName: subTask.GetName(),
		Status:   event.Status,
		Result:   event.Result,
	}
	tracker.Results.Store(event.TaskID, subTaskResult)

	// å¢åŠ å®Œæˆè®¡æ•°ï¼ˆatomicï¼‰
	completedCount := atomic.AddInt32(&tracker.CompletedCount, 1)
	log.Printf("WorkflowInstance %s: å­ä»»åŠ¡ %s å®Œæˆï¼Œçˆ¶ä»»åŠ¡ %s è¿›åº¦: %d/%d",
		m.instance.ID, event.TaskID, parentTaskID, completedCount, tracker.TotalCount)

	// æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å­ä»»åŠ¡éƒ½å·²å®Œæˆ
	if completedCount >= tracker.TotalCount {
		// æ‰€æœ‰å­ä»»åŠ¡å®Œæˆï¼Œè§¦å‘ç»“æœèšåˆ
		m.aggregateSubTaskResults(parentTaskID, tracker)
	}
}

// handleSubTaskFailure å¤„ç†å­ä»»åŠ¡å¤±è´¥äº‹ä»¶ï¼ˆè®°å½•ç»“æœï¼Œå¯èƒ½è§¦å‘èšåˆï¼‰
func (m *WorkflowInstanceManagerV2) handleSubTaskFailure(event TaskStatusEvent) {
	// è·å–å­ä»»åŠ¡ä¿¡æ¯
	var subTask workflow.Task
	if runtimeTask, ok := m.runtimeTasks.Load(event.TaskID); ok {
		subTask = runtimeTask.(workflow.Task)
	} else {
		log.Printf("è­¦å‘Š: WorkflowInstance %s: å­ä»»åŠ¡ %s åœ¨ runtimeTasks ä¸­ä¸å­˜åœ¨", m.instance.ID, event.TaskID)
		return
	}

	// è·å–çˆ¶ä»»åŠ¡ID
	parentTaskID := event.ParentID
	if parentTaskID == "" {
		// å°è¯•ä» contextData ä¸­è·å–çˆ¶ä»»åŠ¡ID
		parentKey := fmt.Sprintf("%s:parent_task_id", event.TaskID)
		if parentValue, exists := m.contextData.Load(parentKey); exists {
			parentTaskID = parentValue.(string)
		}
	}
	if parentTaskID == "" {
		deps := subTask.GetDependencies()
		if len(deps) > 0 {
			if taskID, exists := m.workflow.GetTaskIDByName(deps[0]); exists {
				parentTaskID = taskID
			}
		}
	}

	if parentTaskID == "" {
		log.Printf("è­¦å‘Š: WorkflowInstance %s: æ— æ³•ç¡®å®šå­ä»»åŠ¡ %s çš„çˆ¶ä»»åŠ¡ID", m.instance.ID, event.TaskID)
		return
	}

	// è·å–å­ä»»åŠ¡è·Ÿè¸ªå™¨
	trackerValue, exists := m.subTaskTracker.Load(parentTaskID)
	if !exists {
		log.Printf("è­¦å‘Š: WorkflowInstance %s: çˆ¶ä»»åŠ¡ %s çš„å­ä»»åŠ¡è·Ÿè¸ªå™¨ä¸å­˜åœ¨", m.instance.ID, parentTaskID)
		return
	}
	tracker := trackerValue.(*SubTaskTracker)

	// è®°å½•å­ä»»åŠ¡å¤±è´¥ç»“æœ
	errorMsg := ""
	if event.Error != nil {
		errorMsg = event.Error.Error()
	}
	subTaskResult := SubTaskResult{
		TaskID:   event.TaskID,
		TaskName: subTask.GetName(),
		Status:   "Failed",
		Result:   nil,
		Error:    errorMsg,
	}
	tracker.Results.Store(event.TaskID, subTaskResult)

	// å¢åŠ å®Œæˆè®¡æ•°å’Œå¤±è´¥è®¡æ•°ï¼ˆatomicï¼‰
	atomic.AddInt32(&tracker.FailedCount, 1)
	completedCount := atomic.AddInt32(&tracker.CompletedCount, 1)
	log.Printf("WorkflowInstance %s: å­ä»»åŠ¡ %s å¤±è´¥ï¼Œçˆ¶ä»»åŠ¡ %s è¿›åº¦: %d/%d",
		m.instance.ID, event.TaskID, parentTaskID, completedCount, tracker.TotalCount)

	// æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å­ä»»åŠ¡éƒ½å·²å®Œæˆï¼ˆåŒ…æ‹¬å¤±è´¥çš„ï¼‰
	if completedCount >= tracker.TotalCount {
		// æ‰€æœ‰å­ä»»åŠ¡å®Œæˆï¼Œè§¦å‘ç»“æœèšåˆ
		m.aggregateSubTaskResults(parentTaskID, tracker)
	}
}

// aggregateSubTaskResults èšåˆå­ä»»åŠ¡ç»“æœåˆ°çˆ¶ä»»åŠ¡
func (m *WorkflowInstanceManagerV2) aggregateSubTaskResults(parentTaskID string, tracker *SubTaskTracker) {
	log.Printf("WorkflowInstance %s: å¼€å§‹èšåˆçˆ¶ä»»åŠ¡ %s çš„å­ä»»åŠ¡ç»“æœ", m.instance.ID, parentTaskID)

	// æ”¶é›†æ‰€æœ‰å­ä»»åŠ¡ç»“æœ
	subtaskResults := make([]map[string]interface{}, 0, len(tracker.SubTaskIDs))
	allSucceeded := true

	for _, subTaskID := range tracker.SubTaskIDs {
		if resultValue, exists := tracker.Results.Load(subTaskID); exists {
			result := resultValue.(SubTaskResult)
			subtaskResults = append(subtaskResults, map[string]interface{}{
				"task_id":   result.TaskID,
				"task_name": result.TaskName,
				"status":    result.Status,
				"result":    result.Result,
				"error":     result.Error,
			})
			if result.Status != "Success" {
				allSucceeded = false
			}
		}
	}

	// è·å–çˆ¶ä»»åŠ¡çš„åŸå§‹ç»“æœ
	var parentResult map[string]interface{}
	if existingResult, exists := m.contextData.Load(parentTaskID); exists {
		if result, ok := existingResult.(map[string]interface{}); ok {
			parentResult = result
		} else {
			// å¦‚æœçˆ¶ä»»åŠ¡ç»“æœä¸æ˜¯ map ç±»å‹ï¼ŒåŒ…è£…å®ƒ
			parentResult = map[string]interface{}{
				"original_result": existingResult,
			}
		}
	} else {
		parentResult = make(map[string]interface{})
	}

	// æ³¨å…¥å­ä»»åŠ¡èšåˆç»“æœ
	parentResult["subtask_results"] = subtaskResults
	parentResult["subtask_count"] = len(tracker.SubTaskIDs)
	parentResult["all_subtasks_succeeded"] = allSucceeded

	// æ›´æ–° contextData
	m.contextData.Store(parentTaskID, parentResult)

	// æ›´æ–° resultCache
	if m.resultCache != nil {
		ttl := 1 * time.Hour
		_ = m.resultCache.Set(parentTaskID, parentResult, ttl)
	}

	log.Printf("WorkflowInstance %s: çˆ¶ä»»åŠ¡ %s çš„å­ä»»åŠ¡ç»“æœèšåˆå®Œæˆï¼Œå…± %d ä¸ªå­ä»»åŠ¡ï¼Œå…¨éƒ¨æˆåŠŸ: %v",
		m.instance.ID, parentTaskID, len(subtaskResults), allSucceeded)
}

// allSubTasksCompleted æ£€æŸ¥å½“å‰å±‚çº§çš„æ‰€æœ‰æ¨¡æ¿ä»»åŠ¡çš„å­ä»»åŠ¡æ˜¯å¦éƒ½å·²å®Œæˆ
func (m *WorkflowInstanceManagerV2) allSubTasksCompleted(currentLevel int) bool {
	allCompleted := true

	// éå†æ‰€æœ‰å­ä»»åŠ¡è·Ÿè¸ªå™¨
	m.subTaskTracker.Range(func(key, value interface{}) bool {
		parentTaskID := key.(string)
		tracker := value.(*SubTaskTracker)

		// æ£€æŸ¥çˆ¶ä»»åŠ¡æ˜¯å¦åœ¨å½“å‰å±‚çº§
		levelKey := fmt.Sprintf("%s:original_level", parentTaskID)
		if levelValue, exists := m.contextData.Load(levelKey); exists {
			if level, ok := levelValue.(int); ok && level == currentLevel {
				// æ£€æŸ¥å­ä»»åŠ¡æ˜¯å¦å…¨éƒ¨å®Œæˆ
				completedCount := atomic.LoadInt32(&tracker.CompletedCount)
				if completedCount < tracker.TotalCount {
					log.Printf("WorkflowInstance %s: çˆ¶ä»»åŠ¡ %s çš„å­ä»»åŠ¡æœªå…¨éƒ¨å®Œæˆ: %d/%d",
						m.instance.ID, parentTaskID, completedCount, tracker.TotalCount)
					allCompleted = false
					return false // åœæ­¢éå†
				}
			}
		}
		return true
	})

	return allCompleted
}
