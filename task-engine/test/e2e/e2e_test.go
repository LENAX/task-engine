// Package e2e æä¾›ç«¯åˆ°ç«¯æµ‹è¯•
// æ”¯æŒä¸¤ç§æ¨¡å¼ï¼šmockæ¨¡å¼å’ŒçœŸå®æ¨¡å¼
// é€šè¿‡ç¯å¢ƒå˜é‡ E2E_MODE æ§åˆ¶ï¼šmockï¼ˆé»˜è®¤ï¼‰æˆ– real
// çœŸå®æ¨¡å¼éœ€è¦è®¾ç½® TUSHARE_TOKEN ç¯å¢ƒå˜é‡
package e2e

import (
	"context"
	"database/sql"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net/http"
	"os"
	"path/filepath"
	"regexp"
	"strings"
	"sync"
	"testing"
	"time"

	"github.com/PuerkitoBio/goquery"
	_ "github.com/mattn/go-sqlite3"
	"github.com/stevelan1995/task-engine/internal/storage/sqlite"
	"github.com/stevelan1995/task-engine/pkg/core/builder"
	"github.com/stevelan1995/task-engine/pkg/core/engine"
	"github.com/stevelan1995/task-engine/pkg/core/task"
	"github.com/stevelan1995/task-engine/pkg/core/workflow"
)

// é«˜å¹¶å‘ HTTP å®¢æˆ·ç«¯ï¼ˆæ”¯æŒ 50+ å¹¶å‘è¿æ¥ï¼‰
// åŸºäº DefaultTransport ä¿®æ”¹ï¼Œä¿ç•™ä»£ç†å’Œ DNS é…ç½®
var httpClient = func() *http.Client {
	// å¤åˆ¶é»˜è®¤ Transport çš„é…ç½®
	transport := http.DefaultTransport.(*http.Transport).Clone()
	// å¢åŠ å¹¶å‘è¿æ¥æ•°
	transport.MaxIdleConns = 100
	transport.MaxIdleConnsPerHost = 100
	transport.MaxConnsPerHost = 100
	transport.IdleConnTimeout = 90 * time.Second
	return &http.Client{
		Timeout:   30 * time.Second,
		Transport: transport,
	}
}()

// ==================== æµ‹è¯•é…ç½® ====================

// E2EConfig E2Eæµ‹è¯•é…ç½®
type E2EConfig struct {
	Mode           string // mock æˆ– real
	TushareToken   string // Tushare API Tokenï¼ˆçœŸå®æ¨¡å¼éœ€è¦ï¼‰
	DocServerURL   string // æ–‡æ¡£æœåŠ¡å™¨URL
	APIServerURL   string // APIæœåŠ¡å™¨URL
	MetadataDBPath string // å…ƒæ•°æ®æ•°æ®åº“è·¯å¾„
	StockDBPath    string // è‚¡ç¥¨æ•°æ®æ•°æ®åº“è·¯å¾„
	StartDate      string // æ•°æ®å¼€å§‹æ—¥æœŸ
	EndDate        string // æ•°æ®ç»“æŸæ—¥æœŸ
	MaxAPICrawl    int    // æœ€å¤§çˆ¬å–APIæ•°é‡ï¼ˆ0è¡¨ç¤ºä¸é™åˆ¶ï¼‰
}

// getE2EConfig è·å–E2Eæµ‹è¯•é…ç½®
func getE2EConfig(t *testing.T) *E2EConfig {
	mode := os.Getenv("E2E_MODE")
	if mode == "" {
		mode = "mock"
	}

	cfg := &E2EConfig{
		Mode:      mode,
		StartDate: "20251201",
		EndDate:   "20251231",
	}

	if mode == "real" {
		// ä¼˜å…ˆä½¿ç”¨ QDHUB_TUSHARE_TOKENï¼Œå…¶æ¬¡ TUSHARE_TOKEN
		cfg.TushareToken = os.Getenv("QDHUB_TUSHARE_TOKEN")
		if cfg.TushareToken == "" {
			cfg.TushareToken = os.Getenv("TUSHARE_TOKEN")
		}
		if cfg.TushareToken == "" {
			t.Skip("çœŸå®æ¨¡å¼éœ€è¦è®¾ç½® QDHUB_TUSHARE_TOKEN æˆ– TUSHARE_TOKEN ç¯å¢ƒå˜é‡")
		}
		fmt.Println("cfg.TushareToken", cfg.TushareToken)
		// æ¸…ç†tokenä¸­å¯èƒ½çš„æ¢è¡Œç¬¦
		cfg.TushareToken = strings.TrimSpace(cfg.TushareToken)
		cfg.DocServerURL = "https://tushare.pro"
		cfg.APIServerURL = "http://api.tushare.pro"
		cfg.MaxAPICrawl = 0 // 0 è¡¨ç¤ºä¸é™åˆ¶ï¼Œå…¨é‡çˆ¬å–
	}

	// è®¾ç½®æ•°æ®åº“è·¯å¾„
	dataDir := filepath.Join(os.TempDir(), "task-engine-e2e", time.Now().Format("20060102150405"))
	os.MkdirAll(dataDir, 0755)
	cfg.MetadataDBPath = filepath.Join(dataDir, "metadata.db")
	cfg.StockDBPath = filepath.Join(dataDir, "stock_data.db")

	return cfg
}

// ==================== E2Eæµ‹è¯•ä¸Šä¸‹æ–‡ ====================

// E2EContext E2Eæµ‹è¯•ä¸Šä¸‹æ–‡
type E2EContext struct {
	Config      *E2EConfig
	Engine      *engine.Engine
	Registry    task.FunctionRegistry
	DocServer   *MockTushareDocServer
	APIServer   *MockTushareAPIServer
	MetadataDB  *sql.DB
	StockDB     *sql.DB
	CrawlResult *CrawlResult
	cleanup     func()
	// ç”¨äºå¹¶å‘æ”¶é›†å­ä»»åŠ¡ç»“æœçš„äº’æ–¥é”å’Œæ”¶é›†å™¨
	crawlResultMu  sync.Mutex
	crawlCollector *CrawlResultCollector
}

// CrawlResultCollector ç”¨äºæ”¶é›†å¹¶å‘çˆ¬å–çš„APIè¯¦æƒ…ç»“æœ
type CrawlResultCollector struct {
	Provider   DataProvider
	Catalogs   []APICatalog
	Params     []APIParam
	DataFields []APIDataField
	mu         sync.Mutex
}

// setupE2E è®¾ç½®E2Eæµ‹è¯•ç¯å¢ƒ
func setupE2E(t *testing.T) *E2EContext {
	cfg := getE2EConfig(t)

	ctx := &E2EContext{
		Config: cfg,
	}

	// åˆ›å»ºä¸´æ—¶æ•°æ®åº“ç›®å½•ç”¨äºengine
	tmpDir := t.TempDir()
	engineDBPath := filepath.Join(tmpDir, "engine.db")

	// åˆ›å»ºRepository
	repos, err := sqlite.NewRepositories(engineDBPath)
	if err != nil {
		t.Fatalf("åˆ›å»ºRepositoryå¤±è´¥: %v", err)
	}

	// åˆ›å»ºEngineï¼ˆçœŸå®æ¨¡å¼ä½¿ç”¨50å¹¶å‘ï¼Œmockæ¨¡å¼ä½¿ç”¨10ï¼‰
	workerCount := 10
	if cfg.Mode == "real" {
		workerCount = 50
	}
	eng, err := engine.NewEngine(workerCount, 60, repos.Workflow, repos.WorkflowInstance, repos.Task)
	if err != nil {
		t.Fatalf("åˆ›å»ºEngineå¤±è´¥: %v", err)
	}
	ctx.Engine = eng

	// è·å–Registry
	ctx.Registry = eng.GetRegistry()

	// å¯åŠ¨mockæœåŠ¡å™¨ï¼ˆå¦‚æœæ˜¯mockæ¨¡å¼ï¼‰
	if cfg.Mode == "mock" {
		ctx.DocServer = NewMockTushareDocServer()
		cfg.DocServerURL = ctx.DocServer.Start()

		ctx.APIServer = NewMockTushareAPIServer("test_token")
		cfg.APIServerURL = ctx.APIServer.Start()
		cfg.TushareToken = "test_token"
	}

	// å¯åŠ¨Engine
	if err := eng.Start(context.Background()); err != nil {
		t.Fatalf("å¯åŠ¨Engineå¤±è´¥: %v", err)
	}

	// æ³¨å†Œä»»åŠ¡å‡½æ•°
	registerE2EFunctions(t, ctx)

	ctx.cleanup = func() {
		eng.Stop()
		repos.Close()
		if ctx.DocServer != nil {
			ctx.DocServer.Stop()
		}
		if ctx.APIServer != nil {
			ctx.APIServer.Stop()
		}
		if ctx.MetadataDB != nil {
			ctx.MetadataDB.Close()
		}
		if ctx.StockDB != nil {
			ctx.StockDB.Close()
		}

		// å¤åˆ¶æ•°æ®åº“åˆ° test/e2e/data ç›®å½•
		copyDatabasesForInspection(t, cfg)
	}

	return ctx
}

// copyDatabasesForInspection å¤åˆ¶æ•°æ®åº“æ–‡ä»¶åˆ°æŒ‡å®šç›®å½•ä¾›æ£€æŸ¥
func copyDatabasesForInspection(t *testing.T, cfg *E2EConfig) {
	// è·å–é¡¹ç›®æ ¹ç›®å½•
	wd, _ := os.Getwd()
	dataDir := filepath.Join(wd, "data")
	os.MkdirAll(dataDir, 0755)

	// å¤åˆ¶å…ƒæ•°æ®æ•°æ®åº“
	if _, err := os.Stat(cfg.MetadataDBPath); err == nil {
		destPath := filepath.Join(dataDir, "metadata.db")
		copyFile(cfg.MetadataDBPath, destPath)
		t.Logf("å…ƒæ•°æ®æ•°æ®åº“å·²ä¿å­˜åˆ°: %s", destPath)
	}

	// å¤åˆ¶è‚¡ç¥¨æ•°æ®æ•°æ®åº“
	if _, err := os.Stat(cfg.StockDBPath); err == nil {
		destPath := filepath.Join(dataDir, "stock_data.db")
		copyFile(cfg.StockDBPath, destPath)
		t.Logf("è‚¡ç¥¨æ•°æ®æ•°æ®åº“å·²ä¿å­˜åˆ°: %s", destPath)
	}
}

// copyFile å¤åˆ¶æ–‡ä»¶
func copyFile(src, dst string) error {
	sourceFile, err := os.Open(src)
	if err != nil {
		return err
	}
	defer sourceFile.Close()

	destFile, err := os.Create(dst)
	if err != nil {
		return err
	}
	defer destFile.Close()

	_, err = io.Copy(destFile, sourceFile)
	return err
}

// registerE2EFunctions æ³¨å†ŒE2Eæµ‹è¯•æ‰€éœ€çš„å‡½æ•°
func registerE2EFunctions(t *testing.T, ctx *E2EContext) {
	bgCtx := context.Background()
	registry := ctx.Registry

	// æ³¨å†Œä¾èµ–
	registry.RegisterDependencyWithKey("E2EContext", ctx)
	registry.RegisterDependencyWithKey("Engine", ctx.Engine)

	// æ³¨å†Œçˆ¬å–æ–‡æ¡£ç›®å½•å‡½æ•°
	registry.Register(bgCtx, "CrawlDocCatalog", CrawlDocCatalog, "çˆ¬å–Tushareæ–‡æ¡£ç›®å½•")

	// æ³¨å†Œçˆ¬å–APIè¯¦æƒ…å‡½æ•°ï¼ˆæ¨¡æ¿ä»»åŠ¡ç‰ˆæœ¬ï¼‰
	registry.Register(bgCtx, "CrawlAPIDetail", CrawlAPIDetail, "çˆ¬å–APIè¯¦æƒ…ï¼ˆæ¨¡æ¿ä»»åŠ¡ï¼‰")

	// æ³¨å†Œçˆ¬å–å•ä¸ªAPIè¯¦æƒ…å‡½æ•°ï¼ˆå­ä»»åŠ¡ä½¿ç”¨ï¼‰
	registry.Register(bgCtx, "CrawlSingleAPIDetail", CrawlSingleAPIDetail, "çˆ¬å–å•ä¸ªAPIè¯¦æƒ…ï¼ˆå­ä»»åŠ¡ï¼‰")

	// æ³¨å†Œä¿å­˜å…ƒæ•°æ®å‡½æ•°
	registry.Register(bgCtx, "SaveMetadata", SaveMetadata, "ä¿å­˜å…ƒæ•°æ®åˆ°SQLite")

	// æ³¨å†Œå»ºè¡¨å‡½æ•°
	registry.Register(bgCtx, "CreateTables", CreateTables, "åŸºäºå…ƒæ•°æ®åˆ›å»ºæ•°æ®è¡¨")

	// æ³¨å†Œæ•°æ®è·å–å‡½æ•°ï¼ˆç”¨äºæ™®é€šä»»åŠ¡ï¼‰
	registry.Register(bgCtx, "FetchTradeCal", FetchTradeCal, "è·å–äº¤æ˜“æ—¥å†")
	registry.Register(bgCtx, "FetchStockBasic", FetchStockBasic, "è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯")
	registry.Register(bgCtx, "FetchTopList", FetchTopList, "è·å–é¾™è™æ¦œ")

	// æ³¨å†Œæ¨¡æ¿ä»»åŠ¡å ä½å‡½æ•°ï¼ˆæ¨¡æ¿ä»»åŠ¡éœ€è¦ JobFunctionï¼Œä½†å®é™…é€»è¾‘åœ¨ Success Handler ä¸­ï¼‰
	registry.Register(bgCtx, "TemplateNoOp", func(tc *task.TaskContext) (interface{}, error) {
		log.Printf("ğŸ“‹ [æ¨¡æ¿ä»»åŠ¡] %s - å‡†å¤‡ç”Ÿæˆå­ä»»åŠ¡", tc.TaskName)
		return map[string]string{"status": "template_ready"}, nil
	}, "æ¨¡æ¿ä»»åŠ¡å ä½å‡½æ•°")

	// æ³¨å†Œå­ä»»åŠ¡çš„ Job Functionsï¼ˆç”±æ¨¡æ¿ä»»åŠ¡çš„ Handler ç”Ÿæˆçš„å­ä»»åŠ¡ä½¿ç”¨ï¼‰
	// è¿™äº›å‡½æ•°ä»å‚æ•°ä¸­è·å– ts_code å¹¶æ‰§è¡Œå®é™…çš„æ•°æ®è·å–
	registry.Register(bgCtx, "FetchDailySub", FetchDaily, "è·å–æ—¥çº¿è¡Œæƒ…(å­ä»»åŠ¡)")
	registry.Register(bgCtx, "FetchAdjFactorSub", FetchAdjFactor, "è·å–å¤æƒå› å­(å­ä»»åŠ¡)")
	registry.Register(bgCtx, "FetchIncomeSub", FetchIncome, "è·å–åˆ©æ¶¦è¡¨(å­ä»»åŠ¡)")
	registry.Register(bgCtx, "FetchBalanceSheetSub", FetchBalanceSheet, "è·å–èµ„äº§è´Ÿå€ºè¡¨(å­ä»»åŠ¡)")
	registry.Register(bgCtx, "FetchCashFlowSub", FetchCashFlow, "è·å–ç°é‡‘æµé‡è¡¨(å­ä»»åŠ¡)")

	// æ³¨å†Œé€šç”¨Handler
	registry.RegisterTaskHandler(bgCtx, "LogSuccess", func(tc *task.TaskContext) {
		log.Printf("âœ… [ä»»åŠ¡æˆåŠŸ] %s", tc.TaskName)
	}, "è®°å½•æˆåŠŸ")

	registry.RegisterTaskHandler(bgCtx, "LogError", func(tc *task.TaskContext) {
		errMsg := tc.GetParamString("_error_message")
		log.Printf("âŒ [ä»»åŠ¡å¤±è´¥] %s: %s", tc.TaskName, errMsg)
	}, "è®°å½•é”™è¯¯")

	// æ³¨å†Œç”Ÿæˆå­ä»»åŠ¡çš„ Handlersï¼ˆç”¨äºæ¨¡æ¿ä»»åŠ¡æ¨¡å¼ï¼‰
	registry.RegisterTaskHandler(bgCtx, "GenerateDailySubTasks", GenerateDailySubTasks, "ç”Ÿæˆæ—¥çº¿æ•°æ®å­ä»»åŠ¡")
	registry.RegisterTaskHandler(bgCtx, "GenerateAdjFactorSubTasks", GenerateAdjFactorSubTasks, "ç”Ÿæˆå¤æƒå› å­å­ä»»åŠ¡")
	registry.RegisterTaskHandler(bgCtx, "GenerateIncomeSubTasks", GenerateIncomeSubTasks, "ç”Ÿæˆåˆ©æ¶¦è¡¨å­ä»»åŠ¡")
	registry.RegisterTaskHandler(bgCtx, "GenerateBalanceSheetSubTasks", GenerateBalanceSheetSubTasks, "ç”Ÿæˆèµ„äº§è´Ÿå€ºè¡¨å­ä»»åŠ¡")
	registry.RegisterTaskHandler(bgCtx, "GenerateCashFlowSubTasks", GenerateCashFlowSubTasks, "ç”Ÿæˆç°é‡‘æµé‡è¡¨å­ä»»åŠ¡")
	registry.RegisterTaskHandler(bgCtx, "GenerateAPIDetailSubTasks", GenerateAPIDetailSubTasks, "ç”ŸæˆAPIè¯¦æƒ…å­ä»»åŠ¡")
	registry.RegisterTaskHandler(bgCtx, "AggregateAPIDetailResults", AggregateAPIDetailResults, "èšåˆAPIè¯¦æƒ…å­ä»»åŠ¡ç»“æœ")
}

// ==================== Workflow 1: æ–‡æ¡£çˆ¬å–å’Œå…ƒæ•°æ®ä¿å­˜ ====================

// CrawlDocCatalog çˆ¬å–æ–‡æ¡£ç›®å½•
func CrawlDocCatalog(tc *task.TaskContext) (interface{}, error) {
	e2eCtx, ok := tc.GetDependency("E2EContext")
	if !ok {
		return nil, fmt.Errorf("æœªæ‰¾åˆ°E2EContextä¾èµ–")
	}
	ctx := e2eCtx.(*E2EContext)

	url := ctx.Config.DocServerURL + "/document/2"
	log.Printf("ğŸ“¡ [CrawlDocCatalog] å¼€å§‹çˆ¬å–: %s", url)

	resp, err := httpClient.Get(url)
	if err != nil {
		return nil, fmt.Errorf("è¯·æ±‚å¤±è´¥: %w", err)
	}
	defer resp.Body.Close()

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return nil, fmt.Errorf("è¯»å–å“åº”å¤±è´¥: %w", err)
	}

	// è§£æç›®å½•ç»“æ„
	catalogs := parseDocCatalog(string(body), ctx.Config.DocServerURL)
	log.Printf("âœ… [CrawlDocCatalog] è§£æåˆ° %d ä¸ªç›®å½•é¡¹", len(catalogs))

	return catalogs, nil
}

// parseDocCatalog è§£ææ–‡æ¡£ç›®å½•HTMLï¼ˆä½¿ç”¨goqueryï¼‰
// æ”¯æŒä¸¤ç§URLæ ¼å¼ï¼š
// - Mockæ ¼å¼: /document/2/æ•°å­—
// - çœŸå®æ ¼å¼: /document/2?doc_id=æ•°å­—
// åŒºåˆ†å¶å­èŠ‚ç‚¹å’Œç›®å½•èŠ‚ç‚¹ï¼š
// - çœŸå®ç½‘ç«™ï¼šçˆ¶ç›®å½•çš„ <li> æœ‰ class="in"ï¼Œå¶å­èŠ‚ç‚¹æ²¡æœ‰
// - MockæœåŠ¡å™¨ï¼šæ‰€æœ‰èŠ‚ç‚¹éƒ½æ˜¯å¶å­èŠ‚ç‚¹
func parseDocCatalog(html, baseURL string) []APICatalog {
	var catalogs []APICatalog

	doc, err := goquery.NewDocumentFromReader(strings.NewReader(html))
	if err != nil {
		log.Printf("è§£æHTMLå¤±è´¥: %v", err)
		return catalogs
	}

	// éœ€è¦å±è”½çš„ç›®å½•é¡¹ï¼ˆé API æ•°æ®ï¼‰
	excludedNames := map[string]bool{
		"æ•°æ®ç´¢å¼•": true,
		"ç¤¾åŒºæåŠ©": true,
	}

	i := 0
	// æŸ¥æ‰¾æ‰€æœ‰æŒ‡å‘ /document/2 çš„é“¾æ¥ï¼ˆæ”¯æŒä¸¤ç§æ ¼å¼ï¼‰
	doc.Find("a[href^='/document/2']").Each(func(_ int, s *goquery.Selection) {
		href, exists := s.Attr("href")
		if !exists {
			return
		}

		name := strings.TrimSpace(s.Text())

		// è·³è¿‡éœ€è¦å±è”½çš„ç›®å½•é¡¹
		if excludedNames[name] {
			return
		}

		var docID string
		var fullLink string

		// æ ¼å¼1: /document/2?doc_id=æ•°å­— (çœŸå®ç½‘ç«™)
		if strings.Contains(href, "?doc_id=") {
			parts := strings.Split(href, "?doc_id=")
			if len(parts) == 2 && parts[1] != "" {
				docID = parts[1]
				fullLink = baseURL + href
			}
		} else if strings.HasPrefix(href, "/document/2/") {
			// æ ¼å¼2: /document/2/æ•°å­— (mockæœåŠ¡å™¨)
			parts := strings.Split(href, "/")
			if len(parts) >= 4 {
				lastPart := parts[len(parts)-1]
				if lastPart != "" && lastPart != "2" {
					docID = lastPart
					fullLink = baseURL + href
				}
			}
		}

		// è·³è¿‡æ— æ•ˆé“¾æ¥
		if docID == "" || fullLink == "" {
			return
		}

		// åˆ¤æ–­æ˜¯å¦ä¸ºå¶å­èŠ‚ç‚¹ï¼šæ£€æŸ¥çˆ¶å…ƒç´  <li> çš„ class æ˜¯å¦åŒ…å« "in"
		// çœŸå®ç½‘ç«™ï¼šçˆ¶ç›®å½•çš„ <li class="  in"> è¡¨ç¤ºå±•å¼€çš„ç›®å½•ï¼Œä¸æ˜¯å¶å­èŠ‚ç‚¹
		// MockæœåŠ¡å™¨ï¼šæ‰€æœ‰èŠ‚ç‚¹éƒ½æ˜¯å¶å­èŠ‚ç‚¹
		isLeaf := true
		parentLi := s.Parent()
		if parentLi.Is("li") {
			class, _ := parentLi.Attr("class")
			// å¦‚æœ class åŒ…å« "in"ï¼Œè¯´æ˜æ˜¯å±•å¼€çš„ç›®å½•ï¼ˆéå¶å­èŠ‚ç‚¹ï¼‰
			if strings.Contains(class, "in") {
				isLeaf = false
			}
		}

		i++
		catalogs = append(catalogs, APICatalog{
			ID:        i,
			Name:      name,
			Link:      fullLink,
			IsLeaf:    isLeaf,
			Level:     3,
			SortOrder: i,
			CreatedAt: time.Now(),
		})
	})

	return catalogs
}

// CrawlAPIDetail çˆ¬å–APIè¯¦æƒ…ï¼ˆæ¨¡æ¿ä»»åŠ¡ç‰ˆæœ¬ï¼Œç”¨äºç”Ÿæˆå­ä»»åŠ¡ï¼‰
// è¿™ä¸ªå‡½æ•°ç°åœ¨ä½œä¸ºæ¨¡æ¿ä»»åŠ¡çš„å ä½å‡½æ•°ï¼Œå®é™…çˆ¬å–é€»è¾‘åœ¨å­ä»»åŠ¡ä¸­
func CrawlAPIDetail(tc *task.TaskContext) (interface{}, error) {
	log.Printf("ğŸ“‹ [CrawlAPIDetail] æ¨¡æ¿ä»»åŠ¡å‡†å¤‡ç”Ÿæˆå­ä»»åŠ¡")
	return map[string]string{"status": "template_ready"}, nil
}

// CrawlSingleAPIDetail çˆ¬å–å•ä¸ªAPIè¯¦æƒ…ï¼ˆå­ä»»åŠ¡ä½¿ç”¨ï¼‰
func CrawlSingleAPIDetail(tc *task.TaskContext) (interface{}, error) {
	e2eCtx, ok := tc.GetDependency("E2EContext")
	if !ok {
		return nil, fmt.Errorf("æœªæ‰¾åˆ°E2EContextä¾èµ–")
	}
	ctx := e2eCtx.(*E2EContext)

	// ä»å‚æ•°ä¸­è·å– catalog ä¿¡æ¯
	catalogID, err := tc.GetParamInt("catalog_id")
	if err != nil || catalogID == 0 {
		return nil, fmt.Errorf("æœªæ‰¾åˆ° catalog_id å‚æ•°")
	}

	catalogName := tc.GetParamString("catalog_name")
	catalogLink := tc.GetParamString("catalog_link")

	if catalogLink == "" {
		return nil, fmt.Errorf("catalog_link ä¸ºç©º")
	}

	log.Printf("ğŸ“¡ [CrawlSingleAPIDetail] çˆ¬å–: %s (ID=%d)", catalogName, catalogID)

	// çˆ¬å–APIè¯¦æƒ…ï¼ˆä½¿ç”¨é«˜å¹¶å‘ HTTP å®¢æˆ·ç«¯ï¼‰
	resp, err := httpClient.Get(catalogLink)
	if err != nil {
		return nil, fmt.Errorf("è¯·æ±‚å¤±è´¥: %w", err)
	}
	defer resp.Body.Close()

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return nil, fmt.Errorf("è¯»å–å“åº”å¤±è´¥: %w", err)
	}

	// è§£æAPIè¯¦æƒ…
	detail := parseAPIDetail(string(body), catalogID)

	// æ›´æ–°catalogä¿¡æ¯
	catalog := APICatalog{
		ID:          catalogID,
		Name:        catalogName,
		Link:        catalogLink,
		APIName:     detail.apiName,
		Description: detail.description,
		Permission:  detail.permission,
		IsLeaf:      true,
		Level:       3,
		CreatedAt:   time.Now(),
	}

	// çº¿ç¨‹å®‰å…¨åœ°æ”¶é›†ç»“æœ
	ctx.crawlResultMu.Lock()
	if ctx.crawlCollector == nil {
		ctx.crawlCollector = &CrawlResultCollector{
			Provider: DataProvider{
				ID:          1,
				Name:        "Tushare",
				BaseURL:     ctx.Config.APIServerURL,
				Description: "Tushareé‡‘èå¤§æ•°æ®å¹³å°",
				CreatedAt:   time.Now(),
			},
			Catalogs:   []APICatalog{},
			Params:     []APIParam{},
			DataFields: []APIDataField{},
		}
	}
	ctx.crawlCollector.mu.Lock()
	ctx.crawlCollector.Catalogs = append(ctx.crawlCollector.Catalogs, catalog)
	ctx.crawlCollector.Params = append(ctx.crawlCollector.Params, detail.params...)
	ctx.crawlCollector.DataFields = append(ctx.crawlCollector.DataFields, detail.fields...)
	ctx.crawlCollector.mu.Unlock()
	ctx.crawlResultMu.Unlock()

	log.Printf("âœ… [CrawlSingleAPIDetail] å®Œæˆ: %s, å‚æ•°=%d, å­—æ®µ=%d", catalogName, len(detail.params), len(detail.fields))

	return map[string]interface{}{
		"catalog_id":   catalogID,
		"catalog_name": catalogName,
		"params_count": len(detail.params),
		"fields_count": len(detail.fields),
	}, nil
}

// apiDetailResult APIè¯¦æƒ…è§£æç»“æœ
type apiDetailResult struct {
	apiName     string
	description string
	permission  string
	params      []APIParam
	fields      []APIDataField
}

// parseAPIDetail è§£æAPIè¯¦æƒ…HTMLï¼ˆä½¿ç”¨goqueryï¼‰
// æ”¯æŒä¸¤ç§æ ¼å¼ï¼šmockæœåŠ¡å™¨æ ¼å¼å’ŒçœŸå®Tushareç½‘ç«™æ ¼å¼
func parseAPIDetail(html string, catalogID int) *apiDetailResult {
	result := &apiDetailResult{}

	doc, err := goquery.NewDocumentFromReader(strings.NewReader(html))
	if err != nil {
		log.Printf("è§£æAPIè¯¦æƒ…HTMLå¤±è´¥: %v", err)
		return result
	}

	// æ ¼å¼1: MockæœåŠ¡å™¨ - åœ¨ .api-info åŒºåŸŸå†…çš„ p æ ‡ç­¾
	doc.Find(".api-info p").Each(func(_ int, s *goquery.Selection) {
		text := s.Text()
		if strings.Contains(text, "æ¥å£ï¼š") {
			result.apiName = strings.TrimSpace(strings.TrimPrefix(text, "æ¥å£ï¼š"))
		} else if strings.Contains(text, "æè¿°ï¼š") {
			result.description = strings.TrimSpace(strings.TrimPrefix(text, "æè¿°ï¼š"))
		} else if strings.Contains(text, "æƒé™ï¼š") {
			result.permission = strings.TrimSpace(strings.TrimPrefix(text, "æƒé™ï¼š"))
		}
	})

	// æ ¼å¼2: çœŸå®ç½‘ç«™ - åœ¨ .content åŒºåŸŸå†…çš„ p æ ‡ç­¾
	// HTMLç»“æ„: <p>æ¥å£ï¼šstk_premarket<br>æè¿°ï¼š...<br>é™é‡ï¼š...<br>æƒé™ï¼š...</p>
	// æˆ–è€…: <p>æ¥å£ï¼šstock_basicï¼Œå¯ä»¥é€šè¿‡<a>æ•°æ®å·¥å…·</a>è°ƒè¯•<br>æè¿°ï¼š...</p>
	// goqueryçš„Text()ä¼šå¿½ç•¥<br>ï¼Œéœ€è¦ç”¨Html()è·å–åŸå§‹å†…å®¹å†è§£æ
	if result.apiName == "" {
		doc.Find(".content p").Each(func(_ int, s *goquery.Selection) {
			// è·å–HTMLå†…å®¹ï¼Œä¿ç•™<br>æ ‡ç­¾
			html, _ := s.Html()
			text := s.Text()

			// æ£€æŸ¥æ˜¯å¦åŒ…å«æ¥å£ä¿¡æ¯
			if strings.Contains(text, "æ¥å£ï¼š") && result.apiName == "" {
				// æŒ‰<br>åˆ†å‰²HTMLå†…å®¹
				parts := strings.Split(html, "<br")
				for _, part := range parts {
					// æ¸…ç†HTMLæ ‡ç­¾æ®‹ç•™ï¼ˆå¦‚ ">æè¿°ï¼š..."ï¼‰
					part = strings.TrimPrefix(part, ">")
					part = strings.TrimPrefix(part, "/>")
					part = strings.TrimSpace(part)

					if strings.HasPrefix(part, "æ¥å£ï¼š") {
						apiName := strings.TrimPrefix(part, "æ¥å£ï¼š")
						// ç§»é™¤HTMLæ ‡ç­¾
						apiName = regexp.MustCompile(`<[^>]*>`).ReplaceAllString(apiName, "")
						// æˆªå–åˆ°ç¬¬ä¸€ä¸ªä¸­æ–‡é€—å·æˆ–ä¸­æ–‡å¥å·æˆ–ç©ºæ ¼
						if idx := strings.IndexAny(apiName, "ï¼Œã€‚, "); idx > 0 {
							apiName = apiName[:idx]
						}
						result.apiName = strings.TrimSpace(apiName)
					} else if strings.HasPrefix(part, "æè¿°ï¼š") {
						desc := strings.TrimPrefix(part, "æè¿°ï¼š")
						// ç§»é™¤HTMLæ ‡ç­¾
						desc = regexp.MustCompile(`<[^>]*>`).ReplaceAllString(desc, "")
						result.description = strings.TrimSpace(desc)
					} else if strings.HasPrefix(part, "æƒé™ï¼š") {
						permPart := strings.TrimPrefix(part, "æƒé™ï¼š")
						// ç§»é™¤HTMLæ ‡ç­¾
						permPart = regexp.MustCompile(`<[^>]*>`).ReplaceAllString(permPart, "")
						result.permission = strings.TrimSpace(permPart)
					}
				}
			}
		})
	}

	// æå–è¾“å…¥å‚æ•°è¡¨æ ¼
	result.params = parseParamsTableWithGoquery(doc, catalogID)

	// æå–è¾“å‡ºå­—æ®µè¡¨æ ¼
	result.fields = parseFieldsTableWithGoquery(doc, catalogID)

	return result
}

// parseParamsTableWithGoquery ä½¿ç”¨goqueryè§£æå‚æ•°è¡¨æ ¼
// æ”¯æŒä¸¤ç§æ ¼å¼ï¼šmockæœåŠ¡å™¨ï¼ˆtable.params-tableï¼‰å’ŒçœŸå®ç½‘ç«™ï¼ˆè¾“å…¥å‚æ•°åçš„tableï¼‰
func parseParamsTableWithGoquery(doc *goquery.Document, catalogID int) []APIParam {
	var params []APIParam

	// æ ¼å¼1: MockæœåŠ¡å™¨ - table.params-table
	doc.Find("table.params-table tbody tr").Each(func(i int, s *goquery.Selection) {
		tds := s.Find("td")
		if tds.Length() >= 4 {
			name := strings.TrimSpace(tds.Eq(0).Text())
			paramType := strings.TrimSpace(tds.Eq(1).Text())
			required := strings.TrimSpace(tds.Eq(2).Text()) == "Y"
			desc := strings.TrimSpace(tds.Eq(3).Text())

			if name != "" {
				params = append(params, APIParam{
					ID:          catalogID*100 + i + 1,
					CatalogID:   catalogID,
					Name:        name,
					Type:        paramType,
					Required:    required,
					Description: desc,
					SortOrder:   i + 1,
					CreatedAt:   time.Now(),
				})
			}
		}
	})

	// æ ¼å¼2: çœŸå®ç½‘ç«™ - "è¾“å…¥å‚æ•°"åçš„ç¬¬ä¸€ä¸ªtable
	if len(params) == 0 {
		foundInputParams := false
		doc.Find("p, table").Each(func(_ int, s *goquery.Selection) {
			if foundInputParams && s.Is("table") {
				// æ‰¾åˆ°è¾“å…¥å‚æ•°åçš„ç¬¬ä¸€ä¸ªè¡¨æ ¼
				s.Find("tbody tr").Each(func(i int, row *goquery.Selection) {
					tds := row.Find("td")
					if tds.Length() >= 4 {
						name := strings.TrimSpace(tds.Eq(0).Text())
						paramType := strings.TrimSpace(tds.Eq(1).Text())
						requiredText := strings.TrimSpace(tds.Eq(2).Text())
						required := requiredText == "Y" || requiredText == "æ˜¯"
						desc := strings.TrimSpace(tds.Eq(3).Text())

						if name != "" {
							params = append(params, APIParam{
								ID:          catalogID*100 + i + 1,
								CatalogID:   catalogID,
								Name:        name,
								Type:        paramType,
								Required:    required,
								Description: desc,
								SortOrder:   i + 1,
								CreatedAt:   time.Now(),
							})
						}
					}
				})
				foundInputParams = false // åªå¤„ç†ç¬¬ä¸€ä¸ªè¡¨æ ¼
				return
			}
			if s.Is("p") && strings.Contains(s.Text(), "è¾“å…¥å‚æ•°") {
				foundInputParams = true
			}
		})
	}

	return params
}

// parseFieldsTableWithGoquery ä½¿ç”¨goqueryè§£æå­—æ®µè¡¨æ ¼
// æ”¯æŒä¸¤ç§æ ¼å¼ï¼šmockæœåŠ¡å™¨ï¼ˆtable.fields-tableï¼‰å’ŒçœŸå®ç½‘ç«™ï¼ˆè¾“å‡ºå‚æ•°åçš„tableï¼‰
func parseFieldsTableWithGoquery(doc *goquery.Document, catalogID int) []APIDataField {
	var fields []APIDataField

	// æ ¼å¼1: MockæœåŠ¡å™¨ - table.fields-table
	doc.Find("table.fields-table tbody tr").Each(func(i int, s *goquery.Selection) {
		tds := s.Find("td")
		if tds.Length() >= 4 {
			name := strings.TrimSpace(tds.Eq(0).Text())
			fieldType := strings.TrimSpace(tds.Eq(1).Text())
			isDefault := strings.TrimSpace(tds.Eq(2).Text()) == "Y"
			desc := strings.TrimSpace(tds.Eq(3).Text())

			if name != "" {
				fields = append(fields, APIDataField{
					ID:          catalogID*100 + i + 1,
					CatalogID:   catalogID,
					Name:        name,
					Type:        fieldType,
					Default:     isDefault,
					Description: desc,
					SortOrder:   i + 1,
					CreatedAt:   time.Now(),
				})
			}
		}
	})

	// æ ¼å¼2: çœŸå®ç½‘ç«™ - "è¾“å‡ºå‚æ•°"åçš„ç¬¬ä¸€ä¸ªtable
	// æ”¯æŒä¸¤ç§åˆ—æ ¼å¼ï¼š
	// - 4åˆ—: åç§°ã€ç±»å‹ã€é»˜è®¤å€¼ã€æè¿°
	// - 3åˆ—: åç§°ã€ç±»å‹ã€æè¿°ï¼ˆæ— é»˜è®¤å€¼åˆ—ï¼‰
	if len(fields) == 0 {
		foundOutputParams := false
		doc.Find("p, table").Each(func(_ int, s *goquery.Selection) {
			if foundOutputParams && s.Is("table") {
				// æ‰¾åˆ°è¾“å‡ºå‚æ•°åçš„ç¬¬ä¸€ä¸ªè¡¨æ ¼
				s.Find("tbody tr").Each(func(i int, row *goquery.Selection) {
					tds := row.Find("td")
					colCount := tds.Length()

					var name, fieldType, desc string
					var isDefault bool

					if colCount >= 4 {
						// 4åˆ—æ ¼å¼: åç§°ã€ç±»å‹ã€é»˜è®¤å€¼ã€æè¿°
						name = strings.TrimSpace(tds.Eq(0).Text())
						fieldType = strings.TrimSpace(tds.Eq(1).Text())
						defaultText := strings.TrimSpace(tds.Eq(2).Text())
						isDefault = defaultText == "Y" || defaultText == "æ˜¯"
						desc = strings.TrimSpace(tds.Eq(3).Text())
					} else if colCount >= 3 {
						// 3åˆ—æ ¼å¼: åç§°ã€ç±»å‹ã€æè¿°ï¼ˆæ— é»˜è®¤å€¼åˆ—ï¼‰
						name = strings.TrimSpace(tds.Eq(0).Text())
						fieldType = strings.TrimSpace(tds.Eq(1).Text())
						desc = strings.TrimSpace(tds.Eq(2).Text())
						isDefault = false
					} else {
						return // åˆ—æ•°ä¸è¶³ï¼Œè·³è¿‡
					}

					if name != "" {
						fields = append(fields, APIDataField{
							ID:          catalogID*100 + i + 1,
							CatalogID:   catalogID,
							Name:        name,
							Type:        fieldType,
							Default:     isDefault,
							Description: desc,
							SortOrder:   i + 1,
							CreatedAt:   time.Now(),
						})
					}
				})
				foundOutputParams = false // åªå¤„ç†ç¬¬ä¸€ä¸ªè¡¨æ ¼
				return
			}
			if s.Is("p") && strings.Contains(s.Text(), "è¾“å‡ºå‚æ•°") {
				foundOutputParams = true
			}
		})
	}

	return fields
}

// SaveMetadata ä¿å­˜å…ƒæ•°æ®åˆ°SQLite
func SaveMetadata(tc *task.TaskContext) (interface{}, error) {
	e2eCtx, ok := tc.GetDependency("E2EContext")
	if !ok {
		return nil, fmt.Errorf("æœªæ‰¾åˆ°E2EContextä¾èµ–")
	}
	ctx := e2eCtx.(*E2EContext)

	// ä» crawlCollector èšåˆç»“æœï¼ˆå¦‚æœå­˜åœ¨ï¼‰
	ctx.crawlResultMu.Lock()
	if ctx.crawlCollector != nil && ctx.CrawlResult == nil {
		ctx.CrawlResult = &CrawlResult{
			Provider:   ctx.crawlCollector.Provider,
			Catalogs:   ctx.crawlCollector.Catalogs,
			Params:     ctx.crawlCollector.Params,
			DataFields: ctx.crawlCollector.DataFields,
		}
		log.Printf("ğŸ“Š [SaveMetadata] ä»å­ä»»åŠ¡èšåˆç»“æœ: Catalogs=%d, Params=%d, Fields=%d",
			len(ctx.CrawlResult.Catalogs), len(ctx.CrawlResult.Params), len(ctx.CrawlResult.DataFields))
	}
	ctx.crawlResultMu.Unlock()

	if ctx.CrawlResult == nil {
		return nil, fmt.Errorf("æœªæ‰¾åˆ°çˆ¬å–ç»“æœ")
	}

	log.Printf("ğŸ’¾ [SaveMetadata] å¼€å§‹ä¿å­˜å…ƒæ•°æ®åˆ°: %s", ctx.Config.MetadataDBPath)

	// åˆ›å»ºæ•°æ®åº“è¿æ¥
	db, err := sql.Open("sqlite3", ctx.Config.MetadataDBPath)
	if err != nil {
		return nil, fmt.Errorf("æ‰“å¼€æ•°æ®åº“å¤±è´¥: %w", err)
	}
	ctx.MetadataDB = db

	// åˆ›å»ºè¡¨
	if err := createMetadataTables(db); err != nil {
		return nil, fmt.Errorf("åˆ›å»ºè¡¨å¤±è´¥: %w", err)
	}

	// å¼€å¯äº‹åŠ¡
	tx, err := db.Begin()
	if err != nil {
		return nil, fmt.Errorf("å¼€å¯äº‹åŠ¡å¤±è´¥: %w", err)
	}
	defer tx.Rollback()

	// ä¿å­˜Provider
	_, err = tx.Exec(`INSERT INTO data_provider (id, name, base_url, description, created_at) VALUES (?, ?, ?, ?, ?)`,
		ctx.CrawlResult.Provider.ID,
		ctx.CrawlResult.Provider.Name,
		ctx.CrawlResult.Provider.BaseURL,
		ctx.CrawlResult.Provider.Description,
		ctx.CrawlResult.Provider.CreatedAt,
	)
	if err != nil {
		return nil, fmt.Errorf("ä¿å­˜Providerå¤±è´¥: %w", err)
	}

	// ä¿å­˜Catalogs
	for _, c := range ctx.CrawlResult.Catalogs {
		_, err = tx.Exec(`INSERT INTO api_catalog (id, provider_id, name, level, is_leaf, link, api_name, description, permission, sort_order, created_at) 
			VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)`,
			c.ID, 1, c.Name, c.Level, c.IsLeaf, c.Link, c.APIName, c.Description, c.Permission, c.SortOrder, c.CreatedAt,
		)
		if err != nil {
			log.Printf("  âš ï¸ ä¿å­˜Catalogå¤±è´¥: %v", err)
		}
	}

	// ä¿å­˜Params
	for _, p := range ctx.CrawlResult.Params {
		_, err = tx.Exec(`INSERT INTO api_param (id, catalog_id, name, type, required, description, sort_order, created_at) 
			VALUES (?, ?, ?, ?, ?, ?, ?, ?)`,
			p.ID, p.CatalogID, p.Name, p.Type, p.Required, p.Description, p.SortOrder, p.CreatedAt,
		)
		if err != nil {
			log.Printf("  âš ï¸ ä¿å­˜Paramå¤±è´¥: %v", err)
		}
	}

	// ä¿å­˜Fields
	for _, f := range ctx.CrawlResult.DataFields {
		_, err = tx.Exec(`INSERT INTO api_data_field (id, catalog_id, name, type, is_default, description, sort_order, created_at) 
			VALUES (?, ?, ?, ?, ?, ?, ?, ?)`,
			f.ID, f.CatalogID, f.Name, f.Type, f.Default, f.Description, f.SortOrder, f.CreatedAt,
		)
		if err != nil {
			log.Printf("  âš ï¸ ä¿å­˜Fieldå¤±è´¥: %v", err)
		}
	}

	// æäº¤äº‹åŠ¡
	if err := tx.Commit(); err != nil {
		return nil, fmt.Errorf("æäº¤äº‹åŠ¡å¤±è´¥: %w", err)
	}

	log.Printf("âœ… [SaveMetadata] ä¿å­˜å®Œæˆ: Provider=1, Catalogs=%d, Params=%d, Fields=%d",
		len(ctx.CrawlResult.Catalogs), len(ctx.CrawlResult.Params), len(ctx.CrawlResult.DataFields))

	return map[string]int{
		"providers": 1,
		"catalogs":  len(ctx.CrawlResult.Catalogs),
		"params":    len(ctx.CrawlResult.Params),
		"fields":    len(ctx.CrawlResult.DataFields),
	}, nil
}

// createMetadataTables åˆ›å»ºå…ƒæ•°æ®è¡¨
func createMetadataTables(db *sql.DB) error {
	sqls := []string{
		`CREATE TABLE IF NOT EXISTS data_provider (
			id INTEGER PRIMARY KEY,
			name TEXT NOT NULL,
			base_url TEXT,
			description TEXT,
			created_at DATETIME DEFAULT CURRENT_TIMESTAMP
		)`,
		`CREATE TABLE IF NOT EXISTS api_catalog (
			id INTEGER PRIMARY KEY,
			provider_id INTEGER,
			parent_id INTEGER,
			name TEXT NOT NULL,
			level INTEGER DEFAULT 1,
			is_leaf INTEGER DEFAULT 0,
			link TEXT,
			api_name TEXT,
			description TEXT,
			permission TEXT,
			sort_order INTEGER DEFAULT 0,
			created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
			FOREIGN KEY (provider_id) REFERENCES data_provider(id)
		)`,
		`CREATE TABLE IF NOT EXISTS api_param (
			id INTEGER PRIMARY KEY,
			catalog_id INTEGER,
			name TEXT NOT NULL,
			type TEXT,
			required INTEGER DEFAULT 0,
			description TEXT,
			sort_order INTEGER DEFAULT 0,
			created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
			FOREIGN KEY (catalog_id) REFERENCES api_catalog(id)
		)`,
		`CREATE TABLE IF NOT EXISTS api_data_field (
			id INTEGER PRIMARY KEY,
			catalog_id INTEGER,
			name TEXT NOT NULL,
			type TEXT,
			is_default INTEGER DEFAULT 0,
			description TEXT,
			sort_order INTEGER DEFAULT 0,
			created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
			FOREIGN KEY (catalog_id) REFERENCES api_catalog(id)
		)`,
	}

	for _, s := range sqls {
		if _, err := db.Exec(s); err != nil {
			return err
		}
	}

	return nil
}

// ==================== Workflow 2: åŸºäºå…ƒæ•°æ®å»ºè¡¨ ====================

// CreateTables åŸºäºçˆ¬å–çš„APIå…ƒæ•°æ®åŠ¨æ€åˆ›å»ºæ•°æ®è¡¨
func CreateTables(tc *task.TaskContext) (interface{}, error) {
	e2eCtx, ok := tc.GetDependency("E2EContext")
	if !ok {
		return nil, fmt.Errorf("æœªæ‰¾åˆ°E2EContextä¾èµ–")
	}
	ctx := e2eCtx.(*E2EContext)

	log.Printf("ğŸ”¨ [CreateTables] å¼€å§‹åœ¨ %s åˆ›å»ºæ•°æ®è¡¨", ctx.Config.StockDBPath)

	// æ£€æŸ¥æ˜¯å¦æœ‰çˆ¬å–ç»“æœ
	if ctx.CrawlResult == nil || len(ctx.CrawlResult.Catalogs) == 0 {
		return nil, fmt.Errorf("æœªæ‰¾åˆ°çˆ¬å–ç»“æœï¼Œæ— æ³•åˆ›å»ºè¡¨")
	}

	// åˆ›å»ºè‚¡ç¥¨æ•°æ®æ•°æ®åº“
	db, err := sql.Open("sqlite3", ctx.Config.StockDBPath)
	if err != nil {
		return nil, fmt.Errorf("æ‰“å¼€æ•°æ®åº“å¤±è´¥: %w", err)
	}
	ctx.StockDB = db

	// å¼€å¯äº‹åŠ¡åˆ›å»ºæ‰€æœ‰è¡¨
	tx, err := db.Begin()
	if err != nil {
		return nil, fmt.Errorf("å¼€å¯äº‹åŠ¡å¤±è´¥: %w", err)
	}
	defer tx.Rollback()

	// æ ¹æ®çˆ¬å–çš„APIå…ƒæ•°æ®åŠ¨æ€ç”Ÿæˆå»ºè¡¨è¯­å¥
	createdTables := 0
	for _, catalog := range ctx.CrawlResult.Catalogs {
		if catalog.APIName == "" {
			continue
		}

		// è·å–è¯¥APIçš„æ‰€æœ‰å­—æ®µ
		fields := getFieldsForCatalog(ctx.CrawlResult.DataFields, catalog.ID)
		if len(fields) == 0 {
			log.Printf("  âš ï¸ API %s (%s) æ²¡æœ‰å­—æ®µå®šä¹‰ï¼Œè·³è¿‡", catalog.Name, catalog.APIName)
			continue
		}

		// ç”ŸæˆDDL
		ddl := generateTableDDL(catalog.APIName, fields)
		log.Printf("  - åˆ›å»ºè¡¨: %s (%dä¸ªå­—æ®µ)", catalog.APIName, len(fields))

		if _, err := tx.Exec(ddl); err != nil {
			log.Printf("  âš ï¸ åˆ›å»ºè¡¨ %s å¤±è´¥: %v", catalog.APIName, err)
			continue
		}
		createdTables++
	}

	if err := tx.Commit(); err != nil {
		return nil, fmt.Errorf("æäº¤äº‹åŠ¡å¤±è´¥: %w", err)
	}

	log.Printf("âœ… [CreateTables] åˆ›å»ºå®Œæˆï¼Œå…± %d ä¸ªè¡¨", createdTables)
	return map[string]int{"tables_created": createdTables}, nil
}

// getFieldsForCatalog è·å–æŒ‡å®šCatalogçš„æ‰€æœ‰å­—æ®µ
func getFieldsForCatalog(allFields []APIDataField, catalogID int) []APIDataField {
	var fields []APIDataField
	for _, f := range allFields {
		if f.CatalogID == catalogID {
			fields = append(fields, f)
		}
	}
	return fields
}

// generateTableDDL æ ¹æ®APIå­—æ®µåŠ¨æ€ç”Ÿæˆå»ºè¡¨DDL
// ä½¿ç”¨åŒå¼•å·è½¬ä¹‰è¡¨åå’Œå­—æ®µåï¼ˆé¿å… SQLite ä¿ç•™å­—å†²çªï¼Œå¦‚ on, limit, order ç­‰ï¼‰
func generateTableDDL(tableName string, fields []APIDataField) string {
	var sb strings.Builder
	// è¡¨åç”¨åŒå¼•å·åŒ…è£¹
	sb.WriteString(fmt.Sprintf("CREATE TABLE IF NOT EXISTS \"%s\" (\n", tableName))
	sb.WriteString("    \"id\" INTEGER PRIMARY KEY AUTOINCREMENT,\n")

	// å»é‡å­—æ®µåï¼ˆæŸäº› API å¯èƒ½æœ‰é‡å¤å­—æ®µå®šä¹‰ï¼‰
	seenFields := make(map[string]bool)
	uniqueFields := []APIDataField{}
	for _, f := range fields {
		fieldName := strings.TrimSpace(f.Name)
		if fieldName == "" || fieldName == "id" || seenFields[fieldName] {
			continue
		}
		seenFields[fieldName] = true
		uniqueFields = append(uniqueFields, f)
	}

	for i, f := range uniqueFields {
		sqlType := mapTushareTypeToSQLite(f.Type)
		// å­—æ®µåç”¨åŒå¼•å·åŒ…è£¹
		sb.WriteString(fmt.Sprintf("    \"%s\" %s", f.Name, sqlType))
		if i < len(uniqueFields)-1 {
			sb.WriteString(",\n")
		} else {
			sb.WriteString(",\n")
		}
	}

	sb.WriteString("    \"created_at\" DATETIME DEFAULT CURRENT_TIMESTAMP\n")
	sb.WriteString(")")

	return sb.String()
}

// mapTushareTypeToSQLite å°†Tushareå­—æ®µç±»å‹æ˜ å°„ä¸ºSQLiteç±»å‹
func mapTushareTypeToSQLite(tushareType string) string {
	tushareType = strings.ToLower(strings.TrimSpace(tushareType))
	switch tushareType {
	case "int", "integer":
		return "INTEGER"
	case "float", "number", "double":
		return "REAL"
	case "str", "string", "text", "date", "datetime":
		return "TEXT"
	default:
		return "TEXT" // é»˜è®¤ä½¿ç”¨TEXT
	}
}

// ==================== Workflow 3: æ•°æ®è·å– ====================

// callTushareAPI è°ƒç”¨Tushare API
func callTushareAPI(ctx *E2EContext, apiName string, params map[string]interface{}) (*TushareDataFrame, error) {
	reqBody := TushareRequest{
		APIName: apiName,
		Token:   ctx.Config.TushareToken,
		Params:  params,
	}

	jsonData, _ := json.Marshal(reqBody)
	resp, err := httpClient.Post(ctx.Config.APIServerURL, "application/json", strings.NewReader(string(jsonData)))
	if err != nil {
		return nil, err
	}
	defer resp.Body.Close()

	var result TushareResponse
	if err := json.NewDecoder(resp.Body).Decode(&result); err != nil {
		return nil, err
	}

	if result.Code != 0 {
		return nil, fmt.Errorf("APIé”™è¯¯: %s", result.Msg)
	}

	// è½¬æ¢Dataä¸ºDataFrame
	dataBytes, _ := json.Marshal(result.Data)
	var df TushareDataFrame
	if err := json.Unmarshal(dataBytes, &df); err != nil {
		return nil, err
	}

	return &df, nil
}

// FetchTradeCal è·å–äº¤æ˜“æ—¥å†
// è¿”å›å€¼åŒ…å«äº¤æ˜“æ—¥æœŸåˆ—è¡¨ï¼Œç”¨äºä¸‹æ¸¸ä»»åŠ¡ç”Ÿæˆå­ä»»åŠ¡
func FetchTradeCal(tc *task.TaskContext) (interface{}, error) {
	e2eCtx, ok := tc.GetDependency("E2EContext")
	if !ok {
		return nil, fmt.Errorf("æœªæ‰¾åˆ°E2EContextä¾èµ–")
	}
	ctx := e2eCtx.(*E2EContext)

	log.Printf("ğŸ“¡ [FetchTradeCal] è·å–äº¤æ˜“æ—¥å†: %s - %s", ctx.Config.StartDate, ctx.Config.EndDate)

	df, err := callTushareAPI(ctx, "trade_cal", map[string]interface{}{
		"exchange":   "SSE",
		"start_date": ctx.Config.StartDate,
		"end_date":   ctx.Config.EndDate,
	})
	if err != nil {
		return nil, err
	}

	// ä¿å­˜åˆ°æ•°æ®åº“
	count, err := saveDataFrame(ctx.StockDB, "trade_cal", df)
	if err != nil {
		return nil, err
	}

	// æå–äº¤æ˜“æ—¥æœŸåˆ—è¡¨ï¼ˆç”¨äºç”Ÿæˆå­ä»»åŠ¡ï¼‰
	var tradeDates []string
	calDateIdx := -1
	isOpenIdx := -1
	for i, field := range df.Fields {
		if field == "cal_date" {
			calDateIdx = i
		} else if field == "is_open" {
			isOpenIdx = i
		}
	}
	if calDateIdx >= 0 {
		for _, item := range df.Items {
			if len(item) > calDateIdx {
				// åªå–å¼€ç›˜æ—¥ï¼ˆis_open=1ï¼‰
				if isOpenIdx >= 0 && len(item) > isOpenIdx {
					if isOpen, ok := item[isOpenIdx].(float64); ok && isOpen == 1 {
						if date, ok := item[calDateIdx].(string); ok {
							tradeDates = append(tradeDates, date)
						}
					}
				} else {
					if date, ok := item[calDateIdx].(string); ok {
						tradeDates = append(tradeDates, date)
					}
				}
			}
		}
	}

	log.Printf("âœ… [FetchTradeCal] ä¿å­˜ %d æ¡è®°å½•ï¼Œæå– %d ä¸ªäº¤æ˜“æ—¥", count, len(tradeDates))
	return map[string]interface{}{
		"count":       count,
		"trade_dates": tradeDates,
	}, nil
}

// FetchStockBasic è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
// è¿”å›å€¼åŒ…å«è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œç”¨äºä¸‹æ¸¸ä»»åŠ¡ç”Ÿæˆå­ä»»åŠ¡
func FetchStockBasic(tc *task.TaskContext) (interface{}, error) {
	e2eCtx, ok := tc.GetDependency("E2EContext")
	if !ok {
		return nil, fmt.Errorf("æœªæ‰¾åˆ°E2EContextä¾èµ–")
	}
	ctx := e2eCtx.(*E2EContext)

	log.Printf("ğŸ“¡ [FetchStockBasic] è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯")

	df, err := callTushareAPI(ctx, "stock_basic", map[string]interface{}{
		"list_status": "L",
	})
	if err != nil {
		return nil, err
	}

	count, err := saveDataFrame(ctx.StockDB, "stock_basic", df)
	if err != nil {
		return nil, err
	}

	// æå–è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆç”¨äºç”Ÿæˆå­ä»»åŠ¡ï¼Œé™åˆ¶æ•°é‡é¿å…ç”Ÿæˆå¤ªå¤šå­ä»»åŠ¡ï¼‰
	var tsCodes []string
	tsCodeIdx := -1
	for i, field := range df.Fields {
		if field == "ts_code" {
			tsCodeIdx = i
			break
		}
	}
	maxStocks := 3 // é™åˆ¶å­ä»»åŠ¡æ•°é‡ï¼Œç”¨äºæµ‹è¯•
	if tsCodeIdx >= 0 {
		for _, item := range df.Items {
			if len(item) > tsCodeIdx {
				if code, ok := item[tsCodeIdx].(string); ok {
					tsCodes = append(tsCodes, code)
					if len(tsCodes) >= maxStocks {
						break
					}
				}
			}
		}
	}

	log.Printf("âœ… [FetchStockBasic] ä¿å­˜ %d æ¡è®°å½•ï¼Œæå– %d ä¸ªè‚¡ç¥¨ä»£ç ç”¨äºå­ä»»åŠ¡", count, len(tsCodes))
	return map[string]interface{}{
		"count":    count,
		"ts_codes": tsCodes,
	}, nil
}

// FetchDaily è·å–æ—¥çº¿è¡Œæƒ…
// ä»ä»»åŠ¡å‚æ•°ä¸­è·å– ts_codeï¼ˆç”± GenerateSubTasks åŠ¨æ€æ³¨å…¥ï¼‰
func FetchDaily(tc *task.TaskContext) (interface{}, error) {
	e2eCtx, ok := tc.GetDependency("E2EContext")
	if !ok {
		return nil, fmt.Errorf("æœªæ‰¾åˆ°E2EContextä¾èµ–")
	}
	ctx := e2eCtx.(*E2EContext)

	// ä»å‚æ•°ä¸­è·å– ts_codeï¼ˆç”±çˆ¶ä»»åŠ¡é€šè¿‡ GenerateSubTasks æ³¨å…¥ï¼‰
	tsCode := tc.GetParamString("ts_code")
	if tsCode == "" {
		tsCode = "000001.SZ" // é»˜è®¤å€¼ï¼ˆç”¨äºæ¨¡æ‹Ÿæ¨¡å¼æˆ–æœªæ³¨å…¥å‚æ•°æ—¶ï¼‰
	}

	log.Printf("ğŸ“¡ [FetchDaily] è·å–æ—¥çº¿è¡Œæƒ…: ts_code=%s, %s - %s", tsCode, ctx.Config.StartDate, ctx.Config.EndDate)

	df, err := callTushareAPI(ctx, "daily", map[string]interface{}{
		"ts_code":    tsCode,
		"start_date": ctx.Config.StartDate,
		"end_date":   ctx.Config.EndDate,
	})
	if err != nil {
		return nil, err
	}

	count, err := saveDataFrame(ctx.StockDB, "daily", df)
	if err != nil {
		return nil, err
	}

	log.Printf("âœ… [FetchDaily] ä¿å­˜ %d æ¡è®°å½• (ts_code=%s)", count, tsCode)
	return map[string]int{"count": count}, nil
}

// FetchAdjFactor è·å–å¤æƒå› å­
// ä»ä»»åŠ¡å‚æ•°ä¸­è·å– ts_codeï¼ˆç”± GenerateSubTasks åŠ¨æ€æ³¨å…¥ï¼‰
func FetchAdjFactor(tc *task.TaskContext) (interface{}, error) {
	e2eCtx, ok := tc.GetDependency("E2EContext")
	if !ok {
		return nil, fmt.Errorf("æœªæ‰¾åˆ°E2EContextä¾èµ–")
	}
	ctx := e2eCtx.(*E2EContext)

	// ä»å‚æ•°ä¸­è·å– ts_codeï¼ˆç”±çˆ¶ä»»åŠ¡é€šè¿‡ GenerateSubTasks æ³¨å…¥ï¼‰
	tsCode := tc.GetParamString("ts_code")
	if tsCode == "" {
		tsCode = "000001.SZ" // é»˜è®¤å€¼
	}

	log.Printf("ğŸ“¡ [FetchAdjFactor] è·å–å¤æƒå› å­: ts_code=%s", tsCode)

	df, err := callTushareAPI(ctx, "adj_factor", map[string]interface{}{
		"ts_code":    tsCode,
		"start_date": ctx.Config.StartDate,
		"end_date":   ctx.Config.EndDate,
	})
	if err != nil {
		return nil, err
	}

	count, err := saveDataFrame(ctx.StockDB, "adj_factor", df)
	if err != nil {
		return nil, err
	}

	log.Printf("âœ… [FetchAdjFactor] ä¿å­˜ %d æ¡è®°å½• (ts_code=%s)", count, tsCode)
	return map[string]int{"count": count}, nil
}

// FetchIncome è·å–åˆ©æ¶¦è¡¨
// ä»ä»»åŠ¡å‚æ•°ä¸­è·å– ts_codeï¼ˆç”± GenerateSubTasks åŠ¨æ€æ³¨å…¥ï¼‰
func FetchIncome(tc *task.TaskContext) (interface{}, error) {
	e2eCtx, ok := tc.GetDependency("E2EContext")
	if !ok {
		return nil, fmt.Errorf("æœªæ‰¾åˆ°E2EContextä¾èµ–")
	}
	ctx := e2eCtx.(*E2EContext)

	// ä»å‚æ•°ä¸­è·å– ts_codeï¼ˆç”±çˆ¶ä»»åŠ¡é€šè¿‡ GenerateSubTasks æ³¨å…¥ï¼‰
	tsCode := tc.GetParamString("ts_code")
	if tsCode == "" {
		tsCode = "000001.SZ" // é»˜è®¤å€¼
	}

	log.Printf("ğŸ“¡ [FetchIncome] è·å–åˆ©æ¶¦è¡¨: ts_code=%s", tsCode)

	df, err := callTushareAPI(ctx, "income", map[string]interface{}{
		"ts_code": tsCode,
		"period":  "20240930",
	})
	if err != nil {
		return nil, err
	}

	count, err := saveDataFrame(ctx.StockDB, "income", df)
	if err != nil {
		return nil, err
	}

	log.Printf("âœ… [FetchIncome] ä¿å­˜ %d æ¡è®°å½• (ts_code=%s)", count, tsCode)
	return map[string]int{"count": count}, nil
}

// FetchBalanceSheet è·å–èµ„äº§è´Ÿå€ºè¡¨
// ä»ä»»åŠ¡å‚æ•°ä¸­è·å– ts_codeï¼ˆç”± GenerateSubTasks åŠ¨æ€æ³¨å…¥ï¼‰
func FetchBalanceSheet(tc *task.TaskContext) (interface{}, error) {
	e2eCtx, ok := tc.GetDependency("E2EContext")
	if !ok {
		return nil, fmt.Errorf("æœªæ‰¾åˆ°E2EContextä¾èµ–")
	}
	ctx := e2eCtx.(*E2EContext)

	// ä»å‚æ•°ä¸­è·å– ts_codeï¼ˆç”±çˆ¶ä»»åŠ¡é€šè¿‡ GenerateSubTasks æ³¨å…¥ï¼‰
	tsCode := tc.GetParamString("ts_code")
	if tsCode == "" {
		tsCode = "000001.SZ" // é»˜è®¤å€¼
	}

	log.Printf("ğŸ“¡ [FetchBalanceSheet] è·å–èµ„äº§è´Ÿå€ºè¡¨: ts_code=%s", tsCode)

	df, err := callTushareAPI(ctx, "balancesheet", map[string]interface{}{
		"ts_code": tsCode,
		"period":  "20240930",
	})
	if err != nil {
		return nil, err
	}

	count, err := saveDataFrame(ctx.StockDB, "balancesheet", df)
	if err != nil {
		return nil, err
	}

	log.Printf("âœ… [FetchBalanceSheet] ä¿å­˜ %d æ¡è®°å½• (ts_code=%s)", count, tsCode)
	return map[string]int{"count": count}, nil
}

// FetchCashFlow è·å–ç°é‡‘æµé‡è¡¨
// ä»ä»»åŠ¡å‚æ•°ä¸­è·å– ts_codeï¼ˆç”± GenerateSubTasks åŠ¨æ€æ³¨å…¥ï¼‰
func FetchCashFlow(tc *task.TaskContext) (interface{}, error) {
	e2eCtx, ok := tc.GetDependency("E2EContext")
	if !ok {
		return nil, fmt.Errorf("æœªæ‰¾åˆ°E2EContextä¾èµ–")
	}
	ctx := e2eCtx.(*E2EContext)

	// ä»å‚æ•°ä¸­è·å– ts_codeï¼ˆç”±çˆ¶ä»»åŠ¡é€šè¿‡ GenerateSubTasks æ³¨å…¥ï¼‰
	tsCode := tc.GetParamString("ts_code")
	if tsCode == "" {
		tsCode = "000001.SZ" // é»˜è®¤å€¼
	}

	log.Printf("ğŸ“¡ [FetchCashFlow] è·å–ç°é‡‘æµé‡è¡¨: ts_code=%s", tsCode)

	df, err := callTushareAPI(ctx, "cashflow", map[string]interface{}{
		"ts_code": tsCode,
		"period":  "20240930",
	})
	if err != nil {
		return nil, err
	}

	count, err := saveDataFrame(ctx.StockDB, "cashflow", df)
	if err != nil {
		return nil, err
	}

	log.Printf("âœ… [FetchCashFlow] ä¿å­˜ %d æ¡è®°å½• (ts_code=%s)", count, tsCode)
	return map[string]int{"count": count}, nil
}

// getParamKeys è·å–å‚æ•°çš„æ‰€æœ‰ keyï¼ˆè°ƒè¯•ç”¨ï¼‰
func getParamKeys(params map[string]interface{}) []string {
	keys := make([]string, 0, len(params))
	for k := range params {
		keys = append(keys, k)
	}
	return keys
}

// extractTsCodesFromUpstream ä»ä¸Šæ¸¸ä»»åŠ¡ç»“æœä¸­æå– ts_codes
func extractTsCodesFromUpstream(tc *task.TaskContext) []string {
	var tsCodes []string

	// ä» _cached_ å‚æ•°ä¸­æŸ¥æ‰¾ä¸Šæ¸¸ä»»åŠ¡ç»“æœ
	for key, val := range tc.Params {
		if strings.HasPrefix(key, "_cached_") {
			if resultMap, ok := val.(map[string]interface{}); ok {
				if tsCodesRaw, ok := resultMap["ts_codes"]; ok {
					switch v := tsCodesRaw.(type) {
					case []string:
						return v
					case []interface{}:
						for _, item := range v {
							if s, ok := item.(string); ok {
								tsCodes = append(tsCodes, s)
							}
						}
						return tsCodes
					}
				}
			}
		}
	}
	return tsCodes
}

// extractCatalogsFromUpstream ä»ä¸Šæ¸¸ä»»åŠ¡ç»“æœä¸­æå– catalogs
func extractCatalogsFromUpstream(tc *task.TaskContext) []APICatalog {
	var catalogs []APICatalog

	// ä» _cached_ å‚æ•°ä¸­æŸ¥æ‰¾ä¸Šæ¸¸ä»»åŠ¡ç»“æœ
	for key, val := range tc.Params {
		if strings.HasPrefix(key, "_cached_") {
			catalogsRaw := val
			// ç±»å‹æ–­è¨€
			switch v := catalogsRaw.(type) {
			case []APICatalog:
				return v
			case []interface{}:
				data, _ := json.Marshal(v)
				json.Unmarshal(data, &catalogs)
				return catalogs
			default:
				data, _ := json.Marshal(catalogsRaw)
				json.Unmarshal(data, &catalogs)
				return catalogs
			}
		}
	}

	// ä¹Ÿå°è¯• _result_data
	catalogsRaw := tc.GetParam("_result_data")
	if catalogsRaw != nil {
		switch v := catalogsRaw.(type) {
		case []APICatalog:
			return v
		case []interface{}:
			data, _ := json.Marshal(v)
			json.Unmarshal(data, &catalogs)
			return catalogs
		default:
			data, _ := json.Marshal(catalogsRaw)
			json.Unmarshal(data, &catalogs)
			return catalogs
		}
	}

	return catalogs
}

// generateSubTasksForType é€šç”¨çš„å­ä»»åŠ¡ç”Ÿæˆå‡½æ•°
func generateSubTasksForType(tc *task.TaskContext, taskTypeName, jobFuncName string) {
	// è°ƒè¯•ï¼šæ‰“å°æ‰€æœ‰å‚æ•°
	log.Printf("ğŸ” [%s] Params å†…å®¹: %+v", taskTypeName, tc.Params)

	// è·å–Engine
	engineInterface, ok := tc.GetDependency("Engine")
	if !ok {
		log.Printf("âš ï¸ [%s] æœªæ‰¾åˆ°Engineä¾èµ–", taskTypeName)
		return
	}
	eng, ok := engineInterface.(*engine.Engine)
	if !ok {
		log.Printf("âš ï¸ [%s] Engineç±»å‹è½¬æ¢å¤±è´¥", taskTypeName)
		return
	}

	registry := eng.GetRegistry()
	if registry == nil {
		log.Printf("âš ï¸ [%s] æ— æ³•è·å–Registry", taskTypeName)
		return
	}

	// ä»ä¸Šæ¸¸ä»»åŠ¡ç»“æœä¸­æå– ts_codes
	tsCodes := extractTsCodesFromUpstream(tc)
	if len(tsCodes) == 0 {
		log.Printf("âš ï¸ [%s] æœªæ‰¾åˆ° ts_codesï¼ŒParams keys: %v", taskTypeName, getParamKeys(tc.Params))
		return
	}

	log.Printf("ğŸ“¡ [%s] ä»ä¸Šæ¸¸ä»»åŠ¡è·å–åˆ° %d ä¸ªè‚¡ç¥¨ä»£ç : %v", taskTypeName, len(tsCodes), tsCodes)

	parentTaskID := tc.TaskID
	workflowInstanceID := tc.WorkflowInstanceID
	generatedCount := 0

	for _, tsCode := range tsCodes {
		subTaskName := fmt.Sprintf("%s_%s", taskTypeName, tsCode)
		subTask, err := builder.NewTaskBuilder(subTaskName, fmt.Sprintf("è·å–%sçš„%s", tsCode, taskTypeName), registry).
			WithJobFunction(jobFuncName, map[string]interface{}{
				"ts_code": tsCode,
			}).
			WithTaskHandler(task.TaskStatusSuccess, "LogSuccess").
			WithTaskHandler(task.TaskStatusFailed, "LogError").
			Build()
		if err != nil {
			log.Printf("âŒ [%s] åˆ›å»ºå­ä»»åŠ¡å¤±è´¥: %s, error=%v", taskTypeName, subTaskName, err)
			continue
		}

		bgCtx := context.Background()
		if err := eng.AddSubTaskToInstance(bgCtx, workflowInstanceID, subTask, parentTaskID); err != nil {
			log.Printf("âŒ [%s] æ·»åŠ å­ä»»åŠ¡å¤±è´¥: %s, error=%v", taskTypeName, subTaskName, err)
			continue
		}

		generatedCount++
		log.Printf("âœ… [%s] å­ä»»åŠ¡å·²æ·»åŠ : %s (ts_code=%s)", taskTypeName, subTaskName, tsCode)
	}

	log.Printf("âœ… [%s] å…±ç”Ÿæˆ %d ä¸ªå­ä»»åŠ¡", taskTypeName, generatedCount)
}

// GenerateDailySubTasks æ—¥çº¿æ•°æ®æ¨¡æ¿ä»»åŠ¡çš„ Success Handler
func GenerateDailySubTasks(tc *task.TaskContext) {
	generateSubTasksForType(tc, "è·å–æ—¥çº¿æ•°æ®", "FetchDailySub")
}

// GenerateAdjFactorSubTasks å¤æƒå› å­æ¨¡æ¿ä»»åŠ¡çš„ Success Handler
func GenerateAdjFactorSubTasks(tc *task.TaskContext) {
	generateSubTasksForType(tc, "è·å–å¤æƒå› å­", "FetchAdjFactorSub")
}

// GenerateIncomeSubTasks åˆ©æ¶¦è¡¨æ¨¡æ¿ä»»åŠ¡çš„ Success Handler
func GenerateIncomeSubTasks(tc *task.TaskContext) {
	generateSubTasksForType(tc, "è·å–åˆ©æ¶¦è¡¨", "FetchIncomeSub")
}

// GenerateBalanceSheetSubTasks èµ„äº§è´Ÿå€ºè¡¨æ¨¡æ¿ä»»åŠ¡çš„ Success Handler
func GenerateBalanceSheetSubTasks(tc *task.TaskContext) {
	generateSubTasksForType(tc, "è·å–èµ„äº§è´Ÿå€ºè¡¨", "FetchBalanceSheetSub")
}

// GenerateCashFlowSubTasks ç°é‡‘æµé‡è¡¨æ¨¡æ¿ä»»åŠ¡çš„ Success Handler
func GenerateCashFlowSubTasks(tc *task.TaskContext) {
	generateSubTasksForType(tc, "è·å–ç°é‡‘æµé‡è¡¨", "FetchCashFlowSub")
}

// GenerateAPIDetailSubTasks çˆ¬å–APIè¯¦æƒ…æ¨¡æ¿ä»»åŠ¡çš„ Success Handler
func GenerateAPIDetailSubTasks(tc *task.TaskContext) {
	e2eCtx, ok := tc.GetDependency("E2EContext")
	if !ok {
		log.Printf("âš ï¸ [GenerateAPIDetailSubTasks] æœªæ‰¾åˆ°E2EContextä¾èµ–")
		return
	}
	ctx := e2eCtx.(*E2EContext)

	// ä»ä¸Šæ¸¸ä»»åŠ¡è·å–ç›®å½•åˆ—è¡¨
	catalogs := extractCatalogsFromUpstream(tc)
	if len(catalogs) == 0 {
		log.Printf("âš ï¸ [GenerateAPIDetailSubTasks] æœªæ‰¾åˆ°ç›®å½•æ•°æ®ï¼ŒParams keys: %v", getParamKeys(tc.Params))
		return
	}

	// çœŸå®æ¨¡å¼ä¸‹é™åˆ¶çˆ¬å–æ•°é‡
	if ctx.Config.MaxAPICrawl > 0 && len(catalogs) > ctx.Config.MaxAPICrawl {
		log.Printf("ğŸ“¡ [GenerateAPIDetailSubTasks] çœŸå®æ¨¡å¼ï¼šé™åˆ¶çˆ¬å–æ•°é‡ä» %d åˆ° %d", len(catalogs), ctx.Config.MaxAPICrawl)
		catalogs = catalogs[:ctx.Config.MaxAPICrawl]
	}

	log.Printf("ğŸ“¡ [GenerateAPIDetailSubTasks] ä»ä¸Šæ¸¸ä»»åŠ¡è·å–åˆ° %d ä¸ªç›®å½•ï¼Œå¼€å§‹ç”Ÿæˆå­ä»»åŠ¡", len(catalogs))

	// è·å–Engine
	engineInterface, ok := tc.GetDependency("Engine")
	if !ok {
		log.Printf("âš ï¸ [GenerateAPIDetailSubTasks] æœªæ‰¾åˆ°Engineä¾èµ–")
		return
	}
	eng, ok := engineInterface.(*engine.Engine)
	if !ok {
		log.Printf("âš ï¸ [GenerateAPIDetailSubTasks] Engineç±»å‹è½¬æ¢å¤±è´¥")
		return
	}

	registry := eng.GetRegistry()
	if registry == nil {
		log.Printf("âš ï¸ [GenerateAPIDetailSubTasks] æ— æ³•è·å–Registry")
		return
	}

	parentTaskID := tc.TaskID
	workflowInstanceID := tc.WorkflowInstanceID
	generatedCount := 0

	// åˆå§‹åŒ–ç»“æœæ”¶é›†å™¨
	ctx.crawlResultMu.Lock()
	if ctx.crawlCollector == nil {
		ctx.crawlCollector = &CrawlResultCollector{
			Provider: DataProvider{
				ID:          1,
				Name:        "Tushare",
				BaseURL:     ctx.Config.APIServerURL,
				Description: "Tushareé‡‘èå¤§æ•°æ®å¹³å°",
				CreatedAt:   time.Now(),
			},
			Catalogs:   []APICatalog{},
			Params:     []APIParam{},
			DataFields: []APIDataField{},
		}
	}
	ctx.crawlResultMu.Unlock()

	// ç»Ÿè®¡å¶å­èŠ‚ç‚¹å’Œç›®å½•èŠ‚ç‚¹æ•°é‡
	leafCount := 0
	dirCount := 0
	for _, c := range catalogs {
		if c.IsLeaf {
			leafCount++
		} else {
			dirCount++
		}
	}
	log.Printf("ğŸ“Š [GenerateAPIDetailSubTasks] ç›®å½•ç»“æ„: å¶å­èŠ‚ç‚¹=%d, ç›®å½•èŠ‚ç‚¹=%d", leafCount, dirCount)

	for _, catalog := range catalogs {
		// åªä¸ºå¶å­èŠ‚ç‚¹ç”Ÿæˆå­ä»»åŠ¡ï¼ˆè·³è¿‡ç›®å½•èŠ‚ç‚¹ï¼‰
		if !catalog.IsLeaf {
			log.Printf("ğŸ“ [GenerateAPIDetailSubTasks] è·³è¿‡ç›®å½•èŠ‚ç‚¹: %s", catalog.Name)
			continue
		}

		if catalog.Link == "" {
			continue
		}

		subTaskName := fmt.Sprintf("çˆ¬å–APIè¯¦æƒ…_%s", catalog.Name)
		subTask, err := builder.NewTaskBuilder(subTaskName, fmt.Sprintf("çˆ¬å–%sçš„APIè¯¦æƒ…", catalog.Name), registry).
			WithJobFunction("CrawlSingleAPIDetail", map[string]interface{}{
				"catalog_id":   catalog.ID,
				"catalog_name": catalog.Name,
				"catalog_link": catalog.Link,
			}).
			WithTaskHandler(task.TaskStatusSuccess, "LogSuccess").
			WithTaskHandler(task.TaskStatusFailed, "LogError").
			Build()
		if err != nil {
			log.Printf("âŒ [GenerateAPIDetailSubTasks] åˆ›å»ºå­ä»»åŠ¡å¤±è´¥: %s, error=%v", subTaskName, err)
			continue
		}

		bgCtx := context.Background()
		if err := eng.AddSubTaskToInstance(bgCtx, workflowInstanceID, subTask, parentTaskID); err != nil {
			log.Printf("âŒ [GenerateAPIDetailSubTasks] æ·»åŠ å­ä»»åŠ¡å¤±è´¥: %s, error=%v", subTaskName, err)
			continue
		}

		generatedCount++
		log.Printf("âœ… [GenerateAPIDetailSubTasks] å­ä»»åŠ¡å·²æ·»åŠ : %s (catalog=%s)", subTaskName, catalog.Name)
	}

	log.Printf("âœ… [GenerateAPIDetailSubTasks] å…±ç”Ÿæˆ %d ä¸ªå­ä»»åŠ¡", generatedCount)
}

// AggregateAPIDetailResults èšåˆæ‰€æœ‰APIè¯¦æƒ…å­ä»»åŠ¡çš„ç»“æœ
func AggregateAPIDetailResults(tc *task.TaskContext) {
	e2eCtx, ok := tc.GetDependency("E2EContext")
	if !ok {
		log.Printf("âš ï¸ [AggregateAPIDetailResults] æœªæ‰¾åˆ°E2EContextä¾èµ–")
		return
	}
	ctx := e2eCtx.(*E2EContext)

	ctx.crawlResultMu.Lock()
	defer ctx.crawlResultMu.Unlock()

	if ctx.crawlCollector == nil {
		log.Printf("âš ï¸ [AggregateAPIDetailResults] ç»“æœæ”¶é›†å™¨ä¸ºç©º")
		return
	}

	// æ„å»ºå®Œæ•´ç»“æœ
	result := &CrawlResult{
		Provider:   ctx.crawlCollector.Provider,
		Catalogs:   ctx.crawlCollector.Catalogs,
		Params:     ctx.crawlCollector.Params,
		DataFields: ctx.crawlCollector.DataFields,
	}

	ctx.CrawlResult = result

	log.Printf("âœ… [AggregateAPIDetailResults] èšåˆå®Œæˆ: Catalogs=%d, Params=%d, Fields=%d",
		len(result.Catalogs), len(result.Params), len(result.DataFields))
}

// FetchTopList è·å–é¾™è™æ¦œ
func FetchTopList(tc *task.TaskContext) (interface{}, error) {
	e2eCtx, ok := tc.GetDependency("E2EContext")
	if !ok {
		return nil, fmt.Errorf("æœªæ‰¾åˆ°E2EContextä¾èµ–")
	}
	ctx := e2eCtx.(*E2EContext)

	log.Printf("ğŸ“¡ [FetchTopList] è·å–é¾™è™æ¦œ")

	df, err := callTushareAPI(ctx, "top_list", map[string]interface{}{
		"trade_date": ctx.Config.StartDate,
	})
	if err != nil {
		return nil, err
	}

	count, err := saveDataFrame(ctx.StockDB, "top_list", df)
	if err != nil {
		return nil, err
	}

	log.Printf("âœ… [FetchTopList] ä¿å­˜ %d æ¡è®°å½•", count)
	return map[string]int{"count": count}, nil
}

// saveDataFrame ä¿å­˜DataFrameåˆ°æ•°æ®åº“
func saveDataFrame(db *sql.DB, tableName string, df *TushareDataFrame) (int, error) {
	if len(df.Items) == 0 {
		return 0, nil
	}

	// æ„å»ºINSERTè¯­å¥
	placeholders := make([]string, len(df.Fields))
	for i := range placeholders {
		placeholders[i] = "?"
	}

	query := fmt.Sprintf("INSERT OR REPLACE INTO %s (%s) VALUES (%s)",
		tableName,
		strings.Join(df.Fields, ", "),
		strings.Join(placeholders, ", "))

	// æ‰¹é‡æ’å…¥
	tx, err := db.Begin()
	if err != nil {
		return 0, err
	}
	defer tx.Rollback()

	stmt, err := tx.Prepare(query)
	if err != nil {
		return 0, err
	}
	defer stmt.Close()

	count := 0
	for _, item := range df.Items {
		if _, err := stmt.Exec(item...); err != nil {
			log.Printf("  âš ï¸ æ’å…¥å¤±è´¥: %v", err)
			continue
		}
		count++
	}

	if err := tx.Commit(); err != nil {
		return 0, err
	}

	return count, nil
}

// ==================== æµ‹è¯•å‡½æ•° ====================

// TestE2E_Workflow1_MetadataCrawl æµ‹è¯•Workflow 1: å…ƒæ•°æ®çˆ¬å–
func TestE2E_Workflow1_MetadataCrawl(t *testing.T) {
	ctx := setupE2E(t)
	defer ctx.cleanup()

	bgCtx := context.Background()

	// æ„å»ºWorkflow 1: å…ƒæ•°æ®çˆ¬å–
	task1, _ := builder.NewTaskBuilder("çˆ¬å–æ–‡æ¡£ç›®å½•", "çˆ¬å–Tushareæ–‡æ¡£ç›®å½•ç»“æ„", ctx.Registry).
		WithJobFunction("CrawlDocCatalog", nil).
		WithTaskHandler(task.TaskStatusSuccess, "LogSuccess").
		WithTaskHandler(task.TaskStatusFailed, "LogError").
		Build()

	task2, err := builder.NewTaskBuilder("çˆ¬å–APIè¯¦æƒ…", "çˆ¬å–æ¯ä¸ªAPIçš„è¯¦ç»†ä¿¡æ¯", ctx.Registry).
		WithJobFunction("TemplateNoOp", nil).
		WithDependency("çˆ¬å–æ–‡æ¡£ç›®å½•").
		WithTaskHandler(task.TaskStatusSuccess, "GenerateAPIDetailSubTasks").
		WithTaskHandler(task.TaskStatusSuccess, "LogSuccess").
		WithTaskHandler(task.TaskStatusFailed, "LogError").
		WithTemplate(true).
		Build()
	if err != nil {
		t.Fatalf("åˆ›å»ºçˆ¬å–APIè¯¦æƒ…æ¨¡æ¿ä»»åŠ¡å¤±è´¥: %v", err)
	}

	task3, _ := builder.NewTaskBuilder("ä¿å­˜å…ƒæ•°æ®", "ä¿å­˜å…ƒæ•°æ®åˆ°SQLite", ctx.Registry).
		WithJobFunction("SaveMetadata", nil).
		WithDependency("çˆ¬å–APIè¯¦æƒ…").
		WithTaskHandler(task.TaskStatusSuccess, "LogSuccess").
		WithTaskHandler(task.TaskStatusFailed, "LogError").
		Build()

	wf, err := builder.NewWorkflowBuilder("Tushareå…ƒæ•°æ®çˆ¬å–", "çˆ¬å–Tushare APIæ–‡æ¡£å¹¶ä¿å­˜å…ƒæ•°æ®").
		WithTask(task1).
		WithTask(task2).
		WithTask(task3).
		Build()
	if err != nil {
		t.Fatalf("æ„å»ºWorkflowå¤±è´¥: %v", err)
	}

	// æ‰§è¡Œ
	controller, err := ctx.Engine.SubmitWorkflow(bgCtx, wf)
	if err != nil {
		t.Fatalf("æäº¤Workflowå¤±è´¥: %v", err)
	}

	// ç­‰å¾…å®Œæˆ
	waitForWorkflow(t, controller, 60*time.Second)

	// éªŒè¯ç»“æœ
	status, _ := controller.GetStatus()
	if status != "Success" {
		t.Errorf("WorkflowçŠ¶æ€ä¸æ­£ç¡®: æœŸæœ›=Success, å®é™…=%s", status)
	}

	// éªŒè¯å…ƒæ•°æ®å·²ä¿å­˜
	if ctx.CrawlResult == nil {
		t.Error("çˆ¬å–ç»“æœä¸ºç©º")
	} else {
		t.Logf("âœ… çˆ¬å–ç»“æœ: Provider=%s, Catalogs=%d, Params=%d, Fields=%d",
			ctx.CrawlResult.Provider.Name,
			len(ctx.CrawlResult.Catalogs),
			len(ctx.CrawlResult.Params),
			len(ctx.CrawlResult.DataFields))
	}
}

// TestE2E_Workflow2_CreateTables æµ‹è¯•Workflow 2: å»ºè¡¨
func TestE2E_Workflow2_CreateTables(t *testing.T) {
	ctx := setupE2E(t)
	defer ctx.cleanup()

	bgCtx := context.Background()

	// å…ˆæ‰§è¡ŒWorkflow 1è·å–å…ƒæ•°æ®
	runMetadataCrawlWorkflow(t, ctx)

	// æ„å»ºWorkflow 2: å»ºè¡¨
	task1, _ := builder.NewTaskBuilder("åˆ›å»ºæ•°æ®è¡¨", "åŸºäºå…ƒæ•°æ®åˆ›å»ºè‚¡ç¥¨æ•°æ®è¡¨", ctx.Registry).
		WithJobFunction("CreateTables", nil).
		WithTaskHandler(task.TaskStatusSuccess, "LogSuccess").
		WithTaskHandler(task.TaskStatusFailed, "LogError").
		Build()

	wf, err := builder.NewWorkflowBuilder("åˆ›å»ºæ•°æ®è¡¨", "åŸºäºå…ƒæ•°æ®åœ¨SQLiteä¸­åˆ›å»ºæ•°æ®è¡¨").
		WithTask(task1).
		Build()
	if err != nil {
		t.Fatalf("æ„å»ºWorkflowå¤±è´¥: %v", err)
	}

	// æ‰§è¡Œ
	controller, err := ctx.Engine.SubmitWorkflow(bgCtx, wf)
	if err != nil {
		t.Fatalf("æäº¤Workflowå¤±è´¥: %v", err)
	}

	waitForWorkflow(t, controller, 30*time.Second)

	status, _ := controller.GetStatus()
	if status != "Success" {
		t.Errorf("WorkflowçŠ¶æ€ä¸æ­£ç¡®: æœŸæœ›=Success, å®é™…=%s", status)
	}

	// éªŒè¯è¡¨å·²åˆ›å»º
	if ctx.StockDB != nil {
		tables := []string{"trade_cal", "stock_basic", "daily", "adj_factor", "income", "balancesheet", "cashflow", "top_list"}
		for _, table := range tables {
			var count int
			err := ctx.StockDB.QueryRow(fmt.Sprintf("SELECT COUNT(*) FROM sqlite_master WHERE type='table' AND name='%s'", table)).Scan(&count)
			if err != nil || count == 0 {
				t.Errorf("è¡¨ %s æœªåˆ›å»º", table)
			}
		}
		t.Logf("âœ… æ‰€æœ‰æ•°æ®è¡¨å·²åˆ›å»º")
	}
}

// TestE2E_Workflow3_DataAcquisition æµ‹è¯•Workflow 3: æ•°æ®è·å–
func TestE2E_Workflow3_DataAcquisition(t *testing.T) {
	ctx := setupE2E(t)
	defer ctx.cleanup()

	bgCtx := context.Background()

	// å…ˆæ‰§è¡ŒWorkflow 1å’Œ2
	runMetadataCrawlWorkflow(t, ctx)
	runCreateTablesWorkflow(t, ctx)

	// æ„å»ºWorkflow 3: æ•°æ®è·å–ï¼ˆä½¿ç”¨æ¨¡æ¿ä»»åŠ¡æ¨¡å¼ï¼‰
	//
	// ä»»åŠ¡ç»“æ„ï¼š
	// Level 0: è·å–äº¤æ˜“æ—¥å†, è·å–è‚¡ç¥¨ä¿¡æ¯ï¼ˆå¹¶è¡Œæ‰§è¡Œï¼‰
	// Level 1: 5ä¸ªæ¨¡æ¿ä»»åŠ¡ï¼ˆæ—¥çº¿ã€å¤æƒå› å­ã€åˆ©æ¶¦è¡¨ã€èµ„äº§è´Ÿå€ºè¡¨ã€ç°é‡‘æµé‡è¡¨ï¼‰ï¼Œè·å–é¾™è™æ¦œ
	//          æ¯ä¸ªæ¨¡æ¿ä»»åŠ¡ä¾èµ–è·å–è‚¡ç¥¨ä¿¡æ¯ï¼Œåœ¨ Success Handler ä¸­ç”Ÿæˆå­ä»»åŠ¡
	// Level 2: åŠ¨æ€ç”Ÿæˆçš„å­ä»»åŠ¡ï¼ˆè·å–æ—¥çº¿æ•°æ®_000001.SZ, è·å–å¤æƒå› å­_000001.SZ, ...ï¼‰
	//
	tasks := []*task.Task{}

	// äº¤æ˜“æ—¥å†ï¼ˆæ™®é€šä»»åŠ¡ï¼Œæ— ä¾èµ–ï¼‰
	t1, _ := builder.NewTaskBuilder("è·å–äº¤æ˜“æ—¥å†", "è·å–2025å¹´12æœˆäº¤æ˜“æ—¥å†", ctx.Registry).
		WithJobFunction("FetchTradeCal", nil).
		WithTaskHandler(task.TaskStatusSuccess, "LogSuccess").
		WithTaskHandler(task.TaskStatusFailed, "LogError").
		Build()
	tasks = append(tasks, t1)

	// è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ï¼ˆæ™®é€šä»»åŠ¡ï¼Œè¿”å› ts_codes ä¾›ä¸‹æ¸¸æ¨¡æ¿ä»»åŠ¡ä½¿ç”¨ï¼‰
	t2, _ := builder.NewTaskBuilder("è·å–è‚¡ç¥¨ä¿¡æ¯", "è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯", ctx.Registry).
		WithJobFunction("FetchStockBasic", nil).
		WithTaskHandler(task.TaskStatusSuccess, "LogSuccess").
		WithTaskHandler(task.TaskStatusFailed, "LogError").
		Build()
	tasks = append(tasks, t2)

	// æ—¥çº¿æ•°æ®æ¨¡æ¿ä»»åŠ¡ï¼ˆä¾èµ–è·å–è‚¡ç¥¨ä¿¡æ¯ï¼ŒSuccess Handler ç”Ÿæˆå­ä»»åŠ¡ï¼‰
	t3, err := builder.NewTaskBuilder("è·å–æ—¥çº¿æ•°æ®", "è·å–æ—¥çº¿è¡Œæƒ…æ•°æ®", ctx.Registry).
		WithJobFunction("TemplateNoOp", nil).
		WithDependency("è·å–è‚¡ç¥¨ä¿¡æ¯").
		WithTaskHandler(task.TaskStatusSuccess, "GenerateDailySubTasks").
		WithTaskHandler(task.TaskStatusFailed, "LogError").
		WithTemplate(true).
		Build()
	if err != nil {
		t.Fatalf("åˆ›å»ºæ—¥çº¿æ•°æ®æ¨¡æ¿ä»»åŠ¡å¤±è´¥: %v", err)
	}
	tasks = append(tasks, t3)

	// å¤æƒå› å­æ¨¡æ¿ä»»åŠ¡
	t4, err := builder.NewTaskBuilder("è·å–å¤æƒå› å­", "è·å–å¤æƒå› å­æ•°æ®", ctx.Registry).
		WithJobFunction("TemplateNoOp", nil).
		WithDependency("è·å–è‚¡ç¥¨ä¿¡æ¯").
		WithTaskHandler(task.TaskStatusSuccess, "GenerateAdjFactorSubTasks").
		WithTaskHandler(task.TaskStatusFailed, "LogError").
		WithTemplate(true).
		Build()
	if err != nil {
		t.Fatalf("åˆ›å»ºå¤æƒå› å­æ¨¡æ¿ä»»åŠ¡å¤±è´¥: %v", err)
	}
	tasks = append(tasks, t4)

	// åˆ©æ¶¦è¡¨æ¨¡æ¿ä»»åŠ¡
	t5, err := builder.NewTaskBuilder("è·å–åˆ©æ¶¦è¡¨", "è·å–åˆ©æ¶¦è¡¨æ•°æ®", ctx.Registry).
		WithJobFunction("TemplateNoOp", nil).
		WithDependency("è·å–è‚¡ç¥¨ä¿¡æ¯").
		WithTaskHandler(task.TaskStatusSuccess, "GenerateIncomeSubTasks").
		WithTaskHandler(task.TaskStatusFailed, "LogError").
		WithTemplate(true).
		Build()
	if err != nil {
		t.Fatalf("åˆ›å»ºåˆ©æ¶¦è¡¨æ¨¡æ¿ä»»åŠ¡å¤±è´¥: %v", err)
	}
	tasks = append(tasks, t5)

	// èµ„äº§è´Ÿå€ºè¡¨æ¨¡æ¿ä»»åŠ¡
	t6, err := builder.NewTaskBuilder("è·å–èµ„äº§è´Ÿå€ºè¡¨", "è·å–èµ„äº§è´Ÿå€ºè¡¨æ•°æ®", ctx.Registry).
		WithJobFunction("TemplateNoOp", nil).
		WithDependency("è·å–è‚¡ç¥¨ä¿¡æ¯").
		WithTaskHandler(task.TaskStatusSuccess, "GenerateBalanceSheetSubTasks").
		WithTaskHandler(task.TaskStatusFailed, "LogError").
		WithTemplate(true).
		Build()
	if err != nil {
		t.Fatalf("åˆ›å»ºèµ„äº§è´Ÿå€ºè¡¨æ¨¡æ¿ä»»åŠ¡å¤±è´¥: %v", err)
	}
	tasks = append(tasks, t6)

	// ç°é‡‘æµé‡è¡¨æ¨¡æ¿ä»»åŠ¡
	t7, err := builder.NewTaskBuilder("è·å–ç°é‡‘æµé‡è¡¨", "è·å–ç°é‡‘æµé‡è¡¨æ•°æ®", ctx.Registry).
		WithJobFunction("TemplateNoOp", nil).
		WithDependency("è·å–è‚¡ç¥¨ä¿¡æ¯").
		WithTaskHandler(task.TaskStatusSuccess, "GenerateCashFlowSubTasks").
		WithTaskHandler(task.TaskStatusFailed, "LogError").
		WithTemplate(true).
		Build()
	if err != nil {
		t.Fatalf("åˆ›å»ºç°é‡‘æµé‡è¡¨æ¨¡æ¿ä»»åŠ¡å¤±è´¥: %v", err)
	}
	tasks = append(tasks, t7)

	// é¾™è™æ¦œï¼ˆæ™®é€šä»»åŠ¡ï¼Œä¾èµ–äº¤æ˜“æ—¥å†ï¼‰
	t8, _ := builder.NewTaskBuilder("è·å–é¾™è™æ¦œ", "è·å–é¾™è™æ¦œæ•°æ®", ctx.Registry).
		WithJobFunction("FetchTopList", nil).
		WithDependency("è·å–äº¤æ˜“æ—¥å†").
		WithTaskHandler(task.TaskStatusSuccess, "LogSuccess").
		WithTaskHandler(task.TaskStatusFailed, "LogError").
		Build()
	tasks = append(tasks, t8)

	// æ„å»ºWorkflow
	wfBuilder := builder.NewWorkflowBuilder("æ•°æ®è·å–", "è·å–2025å¹´12æœˆè‚¡ç¥¨æ•°æ®")
	for _, tk := range tasks {
		wfBuilder.WithTask(tk)
	}

	wf, err := wfBuilder.Build()
	if err != nil {
		t.Fatalf("æ„å»ºWorkflowå¤±è´¥: %v", err)
	}

	// æ‰§è¡Œ
	controller, err := ctx.Engine.SubmitWorkflow(bgCtx, wf)
	if err != nil {
		t.Fatalf("æäº¤Workflowå¤±è´¥: %v", err)
	}

	waitForWorkflow(t, controller, 120*time.Second)

	status, _ := controller.GetStatus()
	if status != "Success" {
		t.Errorf("WorkflowçŠ¶æ€ä¸æ­£ç¡®: æœŸæœ›=Success, å®é™…=%s", status)
	}

	// éªŒè¯æ•°æ®å·²ä¿å­˜
	printDataSummary(t, ctx.StockDB)

	// æ ¡éªŒæ ¸å¿ƒæ•°æ®è¡¨æœ‰æ•°æ®ï¼ˆæ¨¡æ¿ä»»åŠ¡ç”Ÿæˆçš„å­ä»»åŠ¡åº”è¯¥æˆåŠŸæ‰§è¡Œï¼‰
	validateDataCounts(t, ctx.StockDB, ctx.Config.Mode)
}

// TestE2E_FullPipeline å®Œæ•´æµç¨‹æµ‹è¯•
func TestE2E_FullPipeline(t *testing.T) {
	ctx := setupE2E(t)
	defer ctx.cleanup()

	t.Log("========== E2Eå®Œæ•´æµç¨‹æµ‹è¯•å¼€å§‹ ==========")
	t.Logf("æ¨¡å¼: %s", ctx.Config.Mode)
	t.Logf("å…ƒæ•°æ®åº“: %s", ctx.Config.MetadataDBPath)
	t.Logf("è‚¡ç¥¨æ•°æ®åº“: %s", ctx.Config.StockDBPath)

	// Workflow 1: å…ƒæ•°æ®çˆ¬å–
	t.Log("\n----- Workflow 1: å…ƒæ•°æ®çˆ¬å– -----")
	runMetadataCrawlWorkflow(t, ctx)

	// Workflow 2: å»ºè¡¨
	t.Log("\n----- Workflow 2: åˆ›å»ºæ•°æ®è¡¨ -----")
	runCreateTablesWorkflow(t, ctx)

	// Workflow 3: æ•°æ®è·å–
	t.Log("\n----- Workflow 3: æ•°æ®è·å– -----")
	runDataAcquisitionWorkflow(t, ctx)

	// è¾“å‡ºæœ€ç»ˆç»“æœ
	t.Log("\n========== æµ‹è¯•ç»“æœæ±‡æ€» ==========")
	printMetadataSummary(t, ctx.MetadataDB)
	printDataSummary(t, ctx.StockDB)

	// æ ¡éªŒæ ¸å¿ƒæ•°æ®è¡¨æœ‰æ•°æ®
	validateDataCounts(t, ctx.StockDB, ctx.Config.Mode)

	t.Log("========== E2Eå®Œæ•´æµç¨‹æµ‹è¯•å®Œæˆ ==========")
}

// ==================== è¾…åŠ©å‡½æ•° ====================

func waitForWorkflow(t *testing.T, controller workflow.WorkflowController, timeout time.Duration) {
	startTime := time.Now()
	for {
		status, err := controller.GetStatus()
		if err != nil {
			t.Fatalf("è·å–çŠ¶æ€å¤±è´¥: %v", err)
		}

		if status == "Success" || status == "Failed" || status == "Terminated" {
			t.Logf("Workflowå®Œæˆï¼ŒçŠ¶æ€=%sï¼Œè€—æ—¶=%v", status, time.Since(startTime))
			return
		}

		if time.Since(startTime) > timeout {
			t.Fatalf("Workflowæ‰§è¡Œè¶…æ—¶ï¼Œå½“å‰çŠ¶æ€=%s", status)
		}

		time.Sleep(100 * time.Millisecond)
	}
}

func runMetadataCrawlWorkflow(t *testing.T, ctx *E2EContext) {
	bgCtx := context.Background()

	task1, _ := builder.NewTaskBuilder("çˆ¬å–æ–‡æ¡£ç›®å½•", "çˆ¬å–Tushareæ–‡æ¡£ç›®å½•ç»“æ„", ctx.Registry).
		WithJobFunction("CrawlDocCatalog", nil).
		Build()

	task2, err := builder.NewTaskBuilder("çˆ¬å–APIè¯¦æƒ…", "çˆ¬å–æ¯ä¸ªAPIçš„è¯¦ç»†ä¿¡æ¯", ctx.Registry).
		WithJobFunction("TemplateNoOp", nil).
		WithDependency("çˆ¬å–æ–‡æ¡£ç›®å½•").
		WithTaskHandler(task.TaskStatusSuccess, "GenerateAPIDetailSubTasks").
		WithTemplate(true).
		Build()
	if err != nil {
		t.Fatalf("åˆ›å»ºçˆ¬å–APIè¯¦æƒ…æ¨¡æ¿ä»»åŠ¡å¤±è´¥: %v", err)
	}

	task3, _ := builder.NewTaskBuilder("ä¿å­˜å…ƒæ•°æ®", "ä¿å­˜å…ƒæ•°æ®åˆ°SQLite", ctx.Registry).
		WithJobFunction("SaveMetadata", nil).
		WithDependency("çˆ¬å–APIè¯¦æƒ…").
		Build()

	wf, _ := builder.NewWorkflowBuilder("Tushareå…ƒæ•°æ®çˆ¬å–", "").
		WithTask(task1).WithTask(task2).WithTask(task3).Build()

	controller, _ := ctx.Engine.SubmitWorkflow(bgCtx, wf)
	waitForWorkflow(t, controller, 60*time.Second)
}

func runCreateTablesWorkflow(t *testing.T, ctx *E2EContext) {
	bgCtx := context.Background()

	task1, _ := builder.NewTaskBuilder("åˆ›å»ºæ•°æ®è¡¨", "", ctx.Registry).
		WithJobFunction("CreateTables", nil).Build()

	wf, _ := builder.NewWorkflowBuilder("åˆ›å»ºæ•°æ®è¡¨", "").WithTask(task1).Build()

	controller, _ := ctx.Engine.SubmitWorkflow(bgCtx, wf)
	waitForWorkflow(t, controller, 30*time.Second)
}

func runDataAcquisitionWorkflow(t *testing.T, ctx *E2EContext) {
	bgCtx := context.Background()

	// ä½¿ç”¨æ¨¡æ¿ä»»åŠ¡æ¨¡å¼ï¼šæ¨¡æ¿ä»»åŠ¡çš„ Success Handler ä¼šæ ¹æ®ä¸Šæ¸¸ç»“æœåŠ¨æ€ç”Ÿæˆå­ä»»åŠ¡
	// Level 0: è·å–äº¤æ˜“æ—¥å†, è·å–è‚¡ç¥¨ä¿¡æ¯
	// Level 1: 5ä¸ªæ¨¡æ¿ä»»åŠ¡ï¼ˆæ—¥çº¿ã€å¤æƒå› å­ã€åˆ©æ¶¦è¡¨ã€èµ„äº§è´Ÿå€ºè¡¨ã€ç°é‡‘æµé‡è¡¨ï¼‰ï¼Œè·å–é¾™è™æ¦œ
	// Level 2: åŠ¨æ€ç”Ÿæˆçš„å­ä»»åŠ¡

	t1, _ := builder.NewTaskBuilder("è·å–äº¤æ˜“æ—¥å†", "è·å–äº¤æ˜“æ—¥å†", ctx.Registry).
		WithJobFunction("FetchTradeCal", nil).
		WithTaskHandler(task.TaskStatusSuccess, "LogSuccess").
		Build()

	t2, _ := builder.NewTaskBuilder("è·å–è‚¡ç¥¨ä¿¡æ¯", "è·å–è‚¡ç¥¨ä¿¡æ¯", ctx.Registry).
		WithJobFunction("FetchStockBasic", nil).
		WithTaskHandler(task.TaskStatusSuccess, "LogSuccess").
		Build()

	// 5ä¸ªæ¨¡æ¿ä»»åŠ¡ï¼Œä½¿ç”¨ TemplateNoOp å ä½å‡½æ•°ï¼ŒSuccess Handler ç”Ÿæˆå­ä»»åŠ¡
	t3, _ := builder.NewTaskBuilder("è·å–æ—¥çº¿æ•°æ®", "è·å–æ—¥çº¿æ•°æ®", ctx.Registry).
		WithJobFunction("TemplateNoOp", nil).
		WithDependency("è·å–è‚¡ç¥¨ä¿¡æ¯").
		WithTaskHandler(task.TaskStatusSuccess, "GenerateDailySubTasks").
		WithTemplate(true).
		Build()

	t4, _ := builder.NewTaskBuilder("è·å–å¤æƒå› å­", "è·å–å¤æƒå› å­", ctx.Registry).
		WithJobFunction("TemplateNoOp", nil).
		WithDependency("è·å–è‚¡ç¥¨ä¿¡æ¯").
		WithTaskHandler(task.TaskStatusSuccess, "GenerateAdjFactorSubTasks").
		WithTemplate(true).
		Build()

	t5, _ := builder.NewTaskBuilder("è·å–åˆ©æ¶¦è¡¨", "è·å–åˆ©æ¶¦è¡¨", ctx.Registry).
		WithJobFunction("TemplateNoOp", nil).
		WithDependency("è·å–è‚¡ç¥¨ä¿¡æ¯").
		WithTaskHandler(task.TaskStatusSuccess, "GenerateIncomeSubTasks").
		WithTemplate(true).
		Build()

	t6, _ := builder.NewTaskBuilder("è·å–èµ„äº§è´Ÿå€ºè¡¨", "è·å–èµ„äº§è´Ÿå€ºè¡¨", ctx.Registry).
		WithJobFunction("TemplateNoOp", nil).
		WithDependency("è·å–è‚¡ç¥¨ä¿¡æ¯").
		WithTaskHandler(task.TaskStatusSuccess, "GenerateBalanceSheetSubTasks").
		WithTemplate(true).
		Build()

	t7, _ := builder.NewTaskBuilder("è·å–ç°é‡‘æµé‡è¡¨", "è·å–ç°é‡‘æµé‡è¡¨", ctx.Registry).
		WithJobFunction("TemplateNoOp", nil).
		WithDependency("è·å–è‚¡ç¥¨ä¿¡æ¯").
		WithTaskHandler(task.TaskStatusSuccess, "GenerateCashFlowSubTasks").
		WithTemplate(true).
		Build()

	t8, _ := builder.NewTaskBuilder("è·å–é¾™è™æ¦œ", "è·å–é¾™è™æ¦œ", ctx.Registry).
		WithJobFunction("FetchTopList", nil).
		WithDependency("è·å–äº¤æ˜“æ—¥å†").
		WithTaskHandler(task.TaskStatusSuccess, "LogSuccess").
		Build()

	wf, _ := builder.NewWorkflowBuilder("æ•°æ®è·å–", "è·å–è‚¡ç¥¨æ•°æ®").
		WithTask(t1).WithTask(t2).WithTask(t3).WithTask(t4).
		WithTask(t5).WithTask(t6).WithTask(t7).WithTask(t8).Build()

	controller, _ := ctx.Engine.SubmitWorkflow(bgCtx, wf)
	waitForWorkflow(t, controller, 120*time.Second)
}

func printMetadataSummary(t *testing.T, db *sql.DB) {
	if db == nil {
		return
	}

	t.Log("\nğŸ“Š å…ƒæ•°æ®ç»Ÿè®¡:")
	tables := []string{"data_provider", "api_catalog", "api_param", "api_data_field"}
	for _, table := range tables {
		var count int
		db.QueryRow(fmt.Sprintf("SELECT COUNT(*) FROM %s", table)).Scan(&count)
		t.Logf("  - %s: %d æ¡", table, count)
	}
}

func printDataSummary(t *testing.T, db *sql.DB) {
	if db == nil {
		return
	}

	// è·å–æ‰€æœ‰è¡¨åï¼ˆæ’é™¤sqliteå†…éƒ¨è¡¨å’Œcreated_atæ—¶é—´æˆ³ï¼‰
	tables := getTableNames(db)
	if len(tables) == 0 {
		t.Log("\nğŸ“Š è‚¡ç¥¨æ•°æ®åº“ä¸­æ²¡æœ‰è¡¨")
		return
	}

	t.Log("\nğŸ“Š è‚¡ç¥¨æ•°æ®ç»Ÿè®¡:")
	for _, table := range tables {
		var count int
		db.QueryRow(fmt.Sprintf("SELECT COUNT(*) FROM %s", table)).Scan(&count)
		t.Logf("  - %s: %d æ¡", table, count)
	}

	// æ‰“å°å„è¡¨çš„æ•°æ®æ ·æœ¬ï¼ˆè¡¨æ ¼å½¢å¼ï¼‰
	t.Log("\nğŸ“‹ æ•°æ®æ ·æœ¬ï¼ˆæ¯è¡¨æœ€å¤š5æ¡ï¼‰:")
	for _, table := range tables {
		printTableSample(t, db, table, 5)
	}
}

// getTableNames è·å–æ•°æ®åº“ä¸­æ‰€æœ‰ç”¨æˆ·è¡¨å
func getTableNames(db *sql.DB) []string {
	var tables []string
	rows, err := db.Query("SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%' ORDER BY name")
	if err != nil {
		return tables
	}
	defer rows.Close()

	for rows.Next() {
		var name string
		if err := rows.Scan(&name); err == nil {
			tables = append(tables, name)
		}
	}
	return tables
}

// printTableSample ä»¥è¡¨æ ¼å½¢å¼æ‰“å°è¡¨çš„æ•°æ®æ ·æœ¬
func printTableSample(t *testing.T, db *sql.DB, tableName string, limit int) {
	// è·å–åˆ—åï¼ˆä¸åŒ…æ‹¬idå’Œcreated_atï¼‰
	columns, err := getTableColumns(db, tableName)
	if err != nil || len(columns) == 0 {
		return
	}

	// åªæŸ¥è¯¢éœ€è¦çš„åˆ—
	columnList := strings.Join(columns, ", ")
	query := fmt.Sprintf("SELECT %s FROM %s LIMIT %d", columnList, tableName, limit)
	rows, err := db.Query(query)
	if err != nil {
		return
	}
	defer rows.Close()

	// è¯»å–æ‰€æœ‰è¡Œ
	var dataRows [][]string
	for rows.Next() {
		// åˆ›å»ºåŠ¨æ€æ‰«æç›®æ ‡
		values := make([]interface{}, len(columns))
		valuePtrs := make([]interface{}, len(columns))
		for i := range values {
			valuePtrs[i] = &values[i]
		}

		if err := rows.Scan(valuePtrs...); err != nil {
			continue
		}

		row := make([]string, len(columns))
		for i, val := range values {
			row[i] = formatValue(val)
		}
		dataRows = append(dataRows, row)
	}

	if len(dataRows) == 0 {
		t.Logf("\n  ğŸ“„ %s: (ç©ºè¡¨)", tableName)
		return
	}

	// è®¡ç®—æ¯åˆ—å®½åº¦ï¼ˆåŸºäºè¡¨å¤´å’Œæ•°æ®ï¼‰
	colWidths := make([]int, len(columns))
	for i, col := range columns {
		colWidths[i] = len(col)
	}
	for _, row := range dataRows {
		for i, cell := range row {
			if len(cell) > colWidths[i] {
				colWidths[i] = len(cell)
			}
		}
	}

	// é™åˆ¶åˆ—å®½é¿å…è¿‡é•¿
	maxColWidth := 20
	for i := range colWidths {
		if colWidths[i] > maxColWidth {
			colWidths[i] = maxColWidth
		}
	}

	// æ‰“å°è¡¨å
	t.Logf("\n  ğŸ“„ %s (%dæ¡):", tableName, len(dataRows))

	// æ‰“å°è¡¨å¤´
	header := "    â”‚"
	separator := "    â”œ"
	for i, col := range columns {
		header += fmt.Sprintf(" %-*s â”‚", colWidths[i], truncateString(col, colWidths[i]))
		separator += strings.Repeat("â”€", colWidths[i]+2) + "â”¼"
	}
	separator = separator[:len(separator)-3] + "â”¤"
	t.Log(header)
	t.Log(separator)

	// æ‰“å°æ•°æ®è¡Œ
	for _, row := range dataRows {
		line := "    â”‚"
		for i, cell := range row {
			line += fmt.Sprintf(" %-*s â”‚", colWidths[i], truncateString(cell, colWidths[i]))
		}
		t.Log(line)
	}
}

// getTableColumns è·å–è¡¨çš„åˆ—å
func getTableColumns(db *sql.DB, tableName string) ([]string, error) {
	query := fmt.Sprintf("PRAGMA table_info(%s)", tableName)
	rows, err := db.Query(query)
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	var columns []string
	for rows.Next() {
		var cid int
		var name, ctype string
		var notnull, pk int
		var dfltValue interface{}
		if err := rows.Scan(&cid, &name, &ctype, &notnull, &dfltValue, &pk); err != nil {
			continue
		}
		// è·³è¿‡ id å’Œ created_at å­—æ®µ
		if name != "id" && name != "created_at" {
			columns = append(columns, name)
		}
	}
	return columns, nil
}

// formatValue æ ¼å¼åŒ–æ•°æ®åº“å€¼ä¸ºå­—ç¬¦ä¸²
func formatValue(val interface{}) string {
	if val == nil {
		return "NULL"
	}
	switch v := val.(type) {
	case []byte:
		return string(v)
	case float64:
		if v == float64(int64(v)) {
			return fmt.Sprintf("%.0f", v)
		}
		return fmt.Sprintf("%.4f", v)
	case int64:
		return fmt.Sprintf("%d", v)
	default:
		return fmt.Sprintf("%v", v)
	}
}

// truncateString æˆªæ–­å­—ç¬¦ä¸²å¹¶æ·»åŠ çœç•¥å·
func truncateString(s string, maxLen int) string {
	if len(s) <= maxLen {
		return s
	}
	if maxLen <= 3 {
		return s[:maxLen]
	}
	return s[:maxLen-2] + ".."
}

// validateDataCounts æ ¡éªŒæ•°æ®è¡¨æœ‰æ•°æ®
func validateDataCounts(t *testing.T, db *sql.DB, mode string) {
	if db == nil {
		return
	}

	// è·å–æ‰€æœ‰åŠ¨æ€åˆ›å»ºçš„è¡¨
	tables := getTableNames(db)
	if len(tables) == 0 {
		t.Errorf("âŒ æ•°æ®æ ¡éªŒå¤±è´¥: æ²¡æœ‰åˆ›å»ºä»»ä½•æ•°æ®è¡¨")
		return
	}

	// æ ¸å¿ƒè¡¨å¿…é¡»æœ‰æ•°æ®ï¼ˆè¿™äº›è¡¨åä¸Tushare APIåç§°å¯¹åº”ï¼‰
	requiredTables := map[string]int{
		"trade_cal":   1, // äº¤æ˜“æ—¥å†
		"stock_basic": 1, // è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
		"daily":       1, // æ—¥çº¿æ•°æ®
		"adj_factor":  1, // å¤æƒå› å­
		"top_list":    1, // é¾™è™æ¦œ
	}

	// æ ¡éªŒæ ¸å¿ƒè¡¨
	for table, minCount := range requiredTables {
		var count int
		err := db.QueryRow(fmt.Sprintf("SELECT COUNT(*) FROM %s", table)).Scan(&count)
		if err != nil {
			// è¡¨å¯èƒ½ä¸å­˜åœ¨ï¼ˆåŠ¨æ€å»ºè¡¨æ—¶è¯¥APIæœªçˆ¬å–åˆ°ï¼‰
			t.Logf("âš ï¸ è¡¨ %s ä¸å­˜åœ¨æˆ–æŸ¥è¯¢å¤±è´¥: %v", table, err)
			continue
		}

		if count < minCount {
			t.Errorf("âŒ æ•°æ®æ ¡éªŒå¤±è´¥: %s è¡¨åº”è‡³å°‘æœ‰ %d æ¡æ•°æ®ï¼Œå®é™…åªæœ‰ %d æ¡", table, minCount, count)
		} else {
			t.Logf("âœ… æ•°æ®æ ¡éªŒé€šè¿‡: %s è¡¨æœ‰ %d æ¡æ•°æ®", table, count)
		}
	}

	// ç»Ÿè®¡æ‰€æœ‰è¡¨çš„æ•°æ®æƒ…å†µ
	t.Log("\nğŸ“ˆ æ‰€æœ‰è¡¨æ•°æ®ç»Ÿè®¡:")
	totalRows := 0
	for _, table := range tables {
		var count int
		if err := db.QueryRow(fmt.Sprintf("SELECT COUNT(*) FROM %s", table)).Scan(&count); err == nil {
			totalRows += count
			status := "âœ…"
			if count == 0 {
				status = "âšª"
			}
			t.Logf("  %s %s: %d æ¡", status, table, count)
		}
	}
	t.Logf("  ğŸ“Š æ€»è®¡: %d ä¸ªè¡¨, %d æ¡æ•°æ®", len(tables), totalRows)
}
