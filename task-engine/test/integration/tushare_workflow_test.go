package integration

import (
	"context"
	"encoding/json"
	"fmt"
	"log"
	"os"
	"path/filepath"
	"strings"
	"testing"
	"time"

	_ "github.com/mattn/go-sqlite3"
	"github.com/stevelan1995/task-engine/internal/storage/sqlite"
	"github.com/stevelan1995/task-engine/pkg/core/builder"
	"github.com/stevelan1995/task-engine/pkg/core/engine"
	"github.com/stevelan1995/task-engine/pkg/core/task"
	"github.com/stevelan1995/task-engine/pkg/storage"
)

// ==================== æ•°æ®ç»“æ„å®šä¹‰ ====================

// é¢„è®¾æ¨¡æ‹Ÿæ•°æ®æ•°é‡å¸¸é‡
const (
	// äº¤æ˜“æ—¥å†æ•°æ®ï¼š5ä¸ªäº¤æ˜“æ—¥
	ExpectedTradeCalDates = 5

	// è‚¡ç¥¨åˆ—è¡¨æ•°æ®ï¼š5åªè‚¡ç¥¨
	ExpectedStockCount = 5

	// é¢„æœŸå­ä»»åŠ¡ç”Ÿæˆæ•°é‡
	ExpectedDailySubTaskCount     = 5 // dailyåº”è¯¥ä¸º5ä¸ªäº¤æ˜“æ—¥å„ç”Ÿæˆ1ä¸ªå­ä»»åŠ¡
	ExpectedAdjFactorSubTaskCount = 5 // adj_factoråº”è¯¥ä¸º5åªè‚¡ç¥¨å„ç”Ÿæˆ1ä¸ªå­ä»»åŠ¡

	// é¢„æœŸæ•°æ®æ€»æ•°ï¼ˆå¦‚æœåŠ¨æ€å­ä»»åŠ¡å®Œå…¨å®ç°ï¼‰
	// 5ä¸ªtrade_calï¼ˆæ¯ä¸ªäº¤æ˜“æ—¥1æ¡ï¼‰+ 5ä¸ªstock_basicï¼ˆæ¯åªè‚¡ç¥¨1æ¡ï¼‰+ 5ä¸ªdailyï¼ˆæ¯ä¸ªå­ä»»åŠ¡1æ¡ï¼‰+ 5ä¸ªadj_factorï¼ˆæ¯ä¸ªå­ä»»åŠ¡1æ¡ï¼‰= 20æ¡
	ExpectedTotalDataCountWithDynamicTasks = 20

	// é¢„æœŸæ•°æ®æ€»æ•°ï¼ˆåªæ‰§è¡Œç¬¬ä¸€ç»„ä»»åŠ¡ï¼‰
	// TestTushareWorkflow_Basic: 5ä¸ªtrade_calï¼ˆæ¯ä¸ªäº¤æ˜“æ—¥1æ¡ï¼‰+ 5ä¸ªstock_basicï¼ˆæ¯åªè‚¡ç¥¨1æ¡ï¼‰= 10æ¡
	ExpectedTotalDataCountBasic = 10

	// TestTushareWorkflow_WithDependencies: 5ä¸ªtrade_cal + 5ä¸ªstock_basic + 1ä¸ªdaily + 1ä¸ªadj_factor = 12æ¡
	ExpectedTotalDataCountWithDependencies = 12
)

// TradeCalResult äº¤æ˜“æ—¥å†æ•°æ®ç»“æœ
type TradeCalResult struct {
	Exchange string   `json:"exchange"`
	CalDates []string `json:"cal_dates"` // yyyymmddæ ¼å¼
	IsOpen   []string `json:"is_open"`
	PreDates []string `json:"pre_dates"`
}

// StockBasicResult è‚¡ç¥¨åˆ—è¡¨æ•°æ®ç»“æœ
type StockBasicResult struct {
	TSCodes    []string `json:"ts_codes"` // è‚¡ç¥¨ä»£ç åˆ—è¡¨
	Symbols    []string `json:"symbols"`
	Names      []string `json:"names"`
	Areas      []string `json:"areas"`
	Industries []string `json:"industries"`
	ListDates  []string `json:"list_dates"`
}

// DailyResult æ—¥çº¿æ•°æ®ç»“æœ
// æ ¹æ®éœ€æ±‚æ–‡æ¡£ï¼šts_code(str), trade_date(str), open(str), high(float), low(float), close(str), pre_close(float), change(float), pct_chg(float), vol(int), amount(float)
type DailyResult struct {
	TSCode    string  `json:"ts_code"`
	TradeDate string  `json:"trade_date"`
	Open      string  `json:"open"`
	High      float64 `json:"high"`
	Low       float64 `json:"low"`
	Close     string  `json:"close"`
	PreClose  float64 `json:"pre_close"` // éœ€æ±‚æ–‡æ¡£è¦æ±‚æ˜¯ float
	Change    float64 `json:"change"`
	PctChg    float64 `json:"pct_chg"`
	Vol       int     `json:"vol"`
	Amount    float64 `json:"amount"`
}

// AdjFactorResult å¤æƒå› å­ç»“æœ
type AdjFactorResult struct {
	TSCode    string  `json:"ts_code"`
	TradeDate string  `json:"trade_date"`
	AdjFactor float64 `json:"adj_factor"`
}

// QuantDataRepository æ¨¡æ‹Ÿçš„æ•°æ®ä»“åº“ï¼ˆä¾èµ–æ³¨å…¥ï¼‰
type QuantDataRepository struct {
	savedData []map[string]interface{}
}

func NewQuantDataRepository() *QuantDataRepository {
	return &QuantDataRepository{
		savedData: make([]map[string]interface{}, 0),
	}
}

func (r *QuantDataRepository) Save(data map[string]interface{}) error {
	r.savedData = append(r.savedData, data)
	log.Printf("ğŸ’¾ [ä¿å­˜æ•°æ®] ç±»å‹=%v, æ•°æ®=%v", data["type"], data)
	return nil
}

func (r *QuantDataRepository) GetSavedData() []map[string]interface{} {
	return r.savedData
}

// ==================== ä»»åŠ¡å‡½æ•°å®ç° ====================

// QueryTushare æ¨¡æ‹ŸTushare APIæŸ¥è¯¢
func QueryTushare(ctx *task.TaskContext) (interface{}, error) {
	apiName := ctx.GetParamString("api_name")
	log.Printf("ğŸ“¡ [QueryTushare] API=%s, å¼€å§‹æŸ¥è¯¢...", apiName)

	// æ¨¡æ‹ŸAPIè°ƒç”¨å»¶è¿Ÿ
	time.Sleep(50 * time.Millisecond)

	switch apiName {
	case "trade_cal":
		// æ¨¡æ‹Ÿè¿”å›äº¤æ˜“æ—¥å†æ•°æ®
		result := TradeCalResult{
			Exchange: "SSE",
			CalDates: []string{"20251201", "20251202", "20251203", "20251204", "20251205"},
			IsOpen:   []string{"1", "1", "1", "0", "1"},
			PreDates: []string{"20251130", "20251201", "20251202", "20251203", "20251204"},
		}
		log.Printf("âœ… [QueryTushare] trade_cal æŸ¥è¯¢æˆåŠŸï¼Œè¿”å› %d æ¡è®°å½•", len(result.CalDates))
		return result, nil

	case "stock_basic":
		// æ¨¡æ‹Ÿè¿”å›è‚¡ç¥¨åˆ—è¡¨æ•°æ®
		result := StockBasicResult{
			TSCodes:    []string{"000001.SZ", "000002.SZ", "000003.SZ", "000004.SZ", "000005.SZ"},
			Symbols:    []string{"000001", "000002", "000003", "000004", "000005"},
			Names:      []string{"å¹³å®‰é“¶è¡Œ", "ä¸‡ç§‘A", "å›½å†œç§‘æŠ€", "åè”æ§è‚¡", "ä¸–çºªæ˜Ÿæº"},
			Areas:      []string{"æ·±åœ³", "æ·±åœ³", "æ·±åœ³", "æ·±åœ³", "æ·±åœ³"},
			Industries: []string{"é“¶è¡Œ", "æˆ¿åœ°äº§", "ç»¼åˆ", "æˆ¿åœ°äº§", "ç»¼åˆ"},
			ListDates:  []string{"19910403", "19910129", "19910412", "19920106", "19900303"},
		}
		log.Printf("âœ… [QueryTushare] stock_basic æŸ¥è¯¢æˆåŠŸï¼Œè¿”å› %d æ¡è®°å½•", len(result.TSCodes))
		return result, nil

	case "daily":
		// æ¨¡æ‹Ÿè¿”å›æ—¥çº¿æ•°æ®
		// æ ¹æ®éœ€æ±‚æ–‡æ¡£ï¼Œè¿”å›å‚æ•°ï¼šts_code(str), trade_date(str), open(str), high(float), low(float), close(str), pre_close(float), change(float), pct_chg(float), vol(int), amount(float)
		tradeDate := ctx.GetParamString("trade_date")
		result := DailyResult{
			TSCode:    ctx.GetParamString("ts_code"),
			TradeDate: tradeDate,
			Open:      "10.50",
			High:      10.80,
			Low:       10.30,
			Close:     "10.60",
			PreClose:  10.40, // éœ€æ±‚æ–‡æ¡£è¦æ±‚æ˜¯ float
			Change:    0.20,
			PctChg:    1.92,
			Vol:       1000000,
			Amount:    10600000.0,
		}
		log.Printf("âœ… [QueryTushare] daily æŸ¥è¯¢æˆåŠŸï¼Œts_code=%s, trade_date=%s", result.TSCode, result.TradeDate)
		return result, nil

	case "adj_factor":
		// æ¨¡æ‹Ÿè¿”å›å¤æƒå› å­æ•°æ®
		tsCode := ctx.GetParamString("ts_code")
		result := AdjFactorResult{
			TSCode:    tsCode,
			TradeDate: "20251201",
			AdjFactor: 1.0,
		}
		log.Printf("âœ… [QueryTushare] adj_factor æŸ¥è¯¢æˆåŠŸï¼Œts_code=%s", tsCode)
		return result, nil

	default:
		return nil, fmt.Errorf("æœªçŸ¥çš„APIåç§°: %s", apiName)
	}
}

// GenerateSubTasks æ ¹æ®ä¾èµ–ä»»åŠ¡çš„ç»“æœç”Ÿæˆå­ä»»åŠ¡
// è¿™ä¸ªå‡½æ•°ä½œä¸ºSuccess Handlerè¢«è°ƒç”¨ï¼Œä»ç»“æœæ•°æ®ä¸­æå–ä¿¡æ¯å¹¶ç”Ÿæˆå­ä»»åŠ¡
//
// ä½¿ç”¨åœºæ™¯ç¤ºä¾‹ï¼š
// - ä¸Šæ¸¸ä»»åŠ¡è¿”å› trade_date=['20260101', '20260102', '20260103', '20260104']
// - ä¸ºæ¯ä¸ª trade_date å€¼åˆ›å»ºä¸€ä¸ªå­ä»»åŠ¡ï¼Œå¹¶å°†è¯¥å€¼æ³¨å…¥åˆ°å­ä»»åŠ¡çš„å‚æ•°ä¸­
// - æ¯ä¸ªå­ä»»åŠ¡éƒ½ä¼šä½¿ç”¨ä¸åŒçš„å‚æ•°å€¼æ‰§è¡Œ
//
// âœ… å…³é”®ç‚¹ï¼šå¯ä»¥åœ¨ç”Ÿæˆå­ä»»åŠ¡æ—¶è®¾ç½®å‚æ•°ï¼
//  1. é€šè¿‡ WithJobFunction çš„ params å‚æ•°è®¾ç½®ï¼ˆæ¨èæ–¹å¼ï¼‰
//     ä¾‹å¦‚ï¼šWithJobFunction("QueryTushare", map[string]interface{}{"trade_date": calDate})
//  2. ä¹Ÿå¯ä»¥é€šè¿‡ SetParam æ–¹æ³•åœ¨åˆ›å»ºåè®¾ç½®æˆ–ä¿®æ”¹å‚æ•°
//     ä¾‹å¦‚ï¼šsubTask.SetParam("trade_date", calDate)
//  3. å­ä»»åŠ¡çš„å‚æ•°ä¼šåœ¨ä»»åŠ¡æ‰§è¡Œæ—¶è¢«ä½¿ç”¨ï¼Œæ¯ä¸ªå­ä»»åŠ¡éƒ½ä¼šè·å¾—ä¸åŒçš„å‚æ•°å€¼
//  4. å¯¹äºé¢„å®šä¹‰çš„ä»»åŠ¡ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ResultMappingä»ä¸Šæ¸¸ç»“æœä¸­è‡ªåŠ¨æ˜ å°„å‚æ•°
func GenerateSubTasks(ctx *task.TaskContext) {
	// è·å–ä»»åŠ¡ç»“æœæ•°æ®
	resultData := ctx.GetParam("_result_data")
	if resultData == nil {
		log.Printf("âš ï¸ [GenerateSubTasks] æœªæ‰¾åˆ°ç»“æœæ•°æ®")
		return
	}

	// è·å–çˆ¶ä»»åŠ¡åç§°å’ŒID
	parentTaskName := ctx.TaskName
	parentTaskID := ctx.TaskID
	workflowInstanceID := ctx.WorkflowInstanceID
	log.Printf("ğŸ”„ [GenerateSubTasks] çˆ¶ä»»åŠ¡=%s (ID=%s), å¼€å§‹ç”Ÿæˆå­ä»»åŠ¡...", parentTaskName, parentTaskID)

	// è·å–Engineä¾èµ–ï¼ˆé€šè¿‡ä¾èµ–æ³¨å…¥ï¼‰
	engineInterface, ok := ctx.GetDependency("Engine")
	if !ok {
		log.Printf("âš ï¸ [GenerateSubTasks] æœªæ‰¾åˆ°Engineä¾èµ–ï¼Œæ— æ³•æ·»åŠ å­ä»»åŠ¡")
		return
	}
	eng, ok := engineInterface.(*engine.Engine)
	if !ok {
		log.Printf("âš ï¸ [GenerateSubTasks] Engineç±»å‹è½¬æ¢å¤±è´¥")
		return
	}

	// è·å–Registryï¼ˆç”¨äºåˆ›å»ºå­ä»»åŠ¡ï¼‰
	registry := eng.GetRegistry()
	if registry == nil {
		log.Printf("âš ï¸ [GenerateSubTasks] æ— æ³•è·å–Registry")
		return
	}

	// æ ¹æ®çˆ¶ä»»åŠ¡ç±»å‹ç”Ÿæˆä¸åŒçš„å­ä»»åŠ¡
	// æ³¨æ„ï¼šå¦‚æœYAMLä¸­å®šä¹‰äº†"è·å–æ—¥çº¿æ•°æ®"å’Œ"è·å–å¤æƒå› å­"ä»»åŠ¡ï¼Œéœ€è¦ä¸ºå®ƒä»¬ç”Ÿæˆå­ä»»åŠ¡
	switch parentTaskName {
	case "è·å–äº¤æ˜“æ—¥å†":
		// æ£€æŸ¥æ˜¯å¦å­˜åœ¨"è·å–æ—¥çº¿æ•°æ®"ä»»åŠ¡å®šä¹‰ï¼ˆä»YAMLåŠ è½½çš„ï¼‰
		// å¦‚æœå­˜åœ¨ï¼Œä¸ºå®ƒç”Ÿæˆå­ä»»åŠ¡ï¼›å¦åˆ™ï¼Œä½¿ç”¨åŸæ¥çš„é€»è¾‘
		// è¿™é‡Œæˆ‘ä»¬ç›´æ¥ä¸º"è·å–æ—¥çº¿æ•°æ®"ä»»åŠ¡ç”Ÿæˆå­ä»»åŠ¡ï¼ˆå¦‚æœYAMLä¸­å®šä¹‰äº†è¯¥ä»»åŠ¡ï¼‰
		// æ³¨æ„ï¼šGenerateSubTasksä¼šåœ¨"è·å–äº¤æ˜“æ—¥å†"å®Œæˆåè¢«è°ƒç”¨ï¼Œæ­¤æ—¶éœ€è¦ä¸º"è·å–æ—¥çº¿æ•°æ®"ç”Ÿæˆå­ä»»åŠ¡
		// ä»äº¤æ˜“æ—¥å†ç»“æœä¸­æå–æ—¥æœŸï¼Œç”Ÿæˆæ—¥çº¿ä»»åŠ¡
		// æ³¨æ„ï¼šåº”è¯¥ä¸ºæ‰€æœ‰5ä¸ªäº¤æ˜“æ—¥ç”Ÿæˆå­ä»»åŠ¡ï¼Œä¸ç®¡æ˜¯å¦å¼€ç›˜
		var tradeCalResult TradeCalResult
		var ok bool

		// å°è¯•ç±»å‹æ–­è¨€ï¼ˆå¯èƒ½æ˜¯ç»“æ„ä½“æˆ–mapï¼‰
		if tradeCalResult, ok = resultData.(TradeCalResult); !ok {
			// å¦‚æœæ˜¯mapï¼Œå°è¯•è½¬æ¢
			if resultMap, ok2 := resultData.(map[string]interface{}); ok2 {
				// ä»mapè½¬æ¢ä¸ºç»“æ„ä½“
				if calDates, ok3 := resultMap["cal_dates"].([]interface{}); ok3 {
					tradeCalResult.CalDates = make([]string, len(calDates))
					for i, v := range calDates {
						if s, ok4 := v.(string); ok4 {
							tradeCalResult.CalDates[i] = s
						}
					}
				}
				if isOpen, ok3 := resultMap["is_open"].([]interface{}); ok3 {
					tradeCalResult.IsOpen = make([]string, len(isOpen))
					for i, v := range isOpen {
						if s, ok4 := v.(string); ok4 {
							tradeCalResult.IsOpen[i] = s
						}
					}
				}
				if preDates, ok3 := resultMap["pre_dates"].([]interface{}); ok3 {
					tradeCalResult.PreDates = make([]string, len(preDates))
					for i, v := range preDates {
						if s, ok4 := v.(string); ok4 {
							tradeCalResult.PreDates[i] = s
						}
					}
				}
				if exchange, ok3 := resultMap["exchange"].(string); ok3 {
					tradeCalResult.Exchange = exchange
				}
				ok = true
			}
		}

		if ok {
			log.Printf("ğŸ“ [GenerateSubTasks] äº¤æ˜“æ—¥å†ç»“æœ: %d ä¸ªäº¤æ˜“æ—¥", len(tradeCalResult.CalDates))
			generatedCount := 0
			// ä¸ºæ‰€æœ‰äº¤æ˜“æ—¥ç”Ÿæˆå­ä»»åŠ¡ï¼ˆä¸ç®¡æ˜¯å¦å¼€ç›˜ï¼‰
			// å…³é”®ï¼šåœ¨ç”Ÿæˆå­ä»»åŠ¡æ—¶ï¼Œå¯ä»¥ä¸ºæ¯ä¸ªå­ä»»åŠ¡è®¾ç½®ä¸åŒçš„å‚æ•°å€¼
			// ä¾‹å¦‚ï¼šä¸Šæ¸¸è¿”å› trade_date=['20260101', '20260102', '20260103', '20260104']
			// è¿™é‡Œä¼šä¸ºæ¯ä¸ª trade_date å€¼åˆ›å»ºä¸€ä¸ªå­ä»»åŠ¡ï¼Œå¹¶å°†è¯¥å€¼æ³¨å…¥åˆ°å­ä»»åŠ¡çš„å‚æ•°ä¸­
			for _, calDate := range tradeCalResult.CalDates {
				log.Printf("ğŸ“ [GenerateSubTasks] ç”Ÿæˆæ—¥çº¿ä»»åŠ¡: trade_date=%s", calDate)

				// åˆ›å»ºå­ä»»åŠ¡ï¼ˆä½¿ç”¨TaskBuilderï¼‰
				// âœ… å¯ä»¥åœ¨ç”Ÿæˆå­ä»»åŠ¡æ—¶è®¾ç½®å‚æ•°ï¼šé€šè¿‡ WithJobFunction çš„ params å‚æ•°
				// æ¯ä¸ªå­ä»»åŠ¡éƒ½ä¼šè·å¾—ä¸åŒçš„ trade_date å€¼ï¼Œè¿™äº›å€¼æ¥è‡ªä¸Šæ¸¸ä»»åŠ¡çš„ç»“æœæ•°ç»„
				subTaskName := fmt.Sprintf("è·å–æ—¥çº¿æ•°æ®_%s", calDate)
				subTask, err := builder.NewTaskBuilder(subTaskName, fmt.Sprintf("è·å–%sçš„æ—¥çº¿æ•°æ®", calDate), registry).
					WithJobFunction("QueryTushare", map[string]interface{}{
						"api_name":   "daily",
						"trade_date": calDate,     // âœ… ä¸ºæ¯ä¸ªå­ä»»åŠ¡æ³¨å…¥ä¸åŒçš„ trade_date å‚æ•°å€¼
						"ts_code":    "000001.SZ", // é»˜è®¤è‚¡ç¥¨ä»£ç ï¼Œå®é™…åº”è¯¥ä»stock_basicè·å–
					}).
					WithDependency(parentTaskName). // å­ä»»åŠ¡ä¾èµ–çˆ¶ä»»åŠ¡
					WithTaskHandler(task.TaskStatusSuccess, "SaveResult").
					WithTaskHandler(task.TaskStatusFailed, "LogError").
					Build()
				if err != nil {
					log.Printf("âŒ [GenerateSubTasks] åˆ›å»ºdailyå­ä»»åŠ¡å¤±è´¥: trade_date=%s, error=%v", calDate, err)
					continue
				}

				// âœ… ä¹Ÿå¯ä»¥é€šè¿‡ SetParam æ–¹æ³•åœ¨åˆ›å»ºåè®¾ç½®æˆ–ä¿®æ”¹å‚æ•°
				// ä¾‹å¦‚ï¼šsubTask.SetParam("trade_date", calDate)
				// ä½†åœ¨è¿™ä¸ªåœºæ™¯ä¸­ï¼Œå·²ç»åœ¨ WithJobFunction ä¸­è®¾ç½®äº†ï¼Œæ‰€ä»¥ä¸éœ€è¦

				// æ·»åŠ å­ä»»åŠ¡åˆ°WorkflowInstance
				// æ³¨æ„ï¼šå­ä»»åŠ¡çš„å‚æ•°å·²ç»é€šè¿‡ WithJobFunction è®¾ç½®å¥½äº†ï¼Œå¼•æ“ä¼šä½¿ç”¨è¿™äº›å‚æ•°æ‰§è¡Œä»»åŠ¡
				context := context.Background()
				if err := eng.AddSubTaskToInstance(context, workflowInstanceID, subTask, parentTaskID); err != nil {
					log.Printf("âŒ [GenerateSubTasks] æ·»åŠ dailyå­ä»»åŠ¡å¤±è´¥: trade_date=%s, error=%v", calDate, err)
					continue
				}

				generatedCount++
				log.Printf("âœ… [GenerateSubTasks] dailyå­ä»»åŠ¡å·²æ·»åŠ : %s (ID=%s), trade_date=%s", subTaskName, subTask.GetID(), calDate)
			}
			log.Printf("âœ… [GenerateSubTasks] å…±ç”Ÿæˆ %d ä¸ªdailyå­ä»»åŠ¡ï¼ˆé¢„æœŸ: %dï¼‰", generatedCount, ExpectedDailySubTaskCount)
			if generatedCount != ExpectedDailySubTaskCount {
				log.Printf("âš ï¸ [GenerateSubTasks] dailyå­ä»»åŠ¡æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=%d, å®é™…=%d", ExpectedDailySubTaskCount, generatedCount)
			}
		}

	case "è·å–è‚¡ç¥¨åˆ—è¡¨":
		// ä»è‚¡ç¥¨åˆ—è¡¨ç»“æœä¸­æå–è‚¡ç¥¨ä»£ç ï¼Œç”Ÿæˆå¤æƒå› å­ä»»åŠ¡
		var stockBasicResult StockBasicResult
		var ok bool

		// å°è¯•ç±»å‹æ–­è¨€ï¼ˆå¯èƒ½æ˜¯ç»“æ„ä½“æˆ–mapï¼‰
		if stockBasicResult, ok = resultData.(StockBasicResult); !ok {
			// å¦‚æœæ˜¯mapï¼Œå°è¯•è½¬æ¢
			if resultMap, ok2 := resultData.(map[string]interface{}); ok2 {
				// ä»mapè½¬æ¢ä¸ºç»“æ„ä½“
				if tsCodes, ok3 := resultMap["ts_codes"].([]interface{}); ok3 {
					stockBasicResult.TSCodes = make([]string, len(tsCodes))
					for i, v := range tsCodes {
						if s, ok4 := v.(string); ok4 {
							stockBasicResult.TSCodes[i] = s
						}
					}
				}
				if symbols, ok3 := resultMap["symbols"].([]interface{}); ok3 {
					stockBasicResult.Symbols = make([]string, len(symbols))
					for i, v := range symbols {
						if s, ok4 := v.(string); ok4 {
							stockBasicResult.Symbols[i] = s
						}
					}
				}
				if names, ok3 := resultMap["names"].([]interface{}); ok3 {
					stockBasicResult.Names = make([]string, len(names))
					for i, v := range names {
						if s, ok4 := v.(string); ok4 {
							stockBasicResult.Names[i] = s
						}
					}
				}
				if areas, ok3 := resultMap["areas"].([]interface{}); ok3 {
					stockBasicResult.Areas = make([]string, len(areas))
					for i, v := range areas {
						if s, ok4 := v.(string); ok4 {
							stockBasicResult.Areas[i] = s
						}
					}
				}
				if industries, ok3 := resultMap["industries"].([]interface{}); ok3 {
					stockBasicResult.Industries = make([]string, len(industries))
					for i, v := range industries {
						if s, ok4 := v.(string); ok4 {
							stockBasicResult.Industries[i] = s
						}
					}
				}
				if listDates, ok3 := resultMap["list_dates"].([]interface{}); ok3 {
					stockBasicResult.ListDates = make([]string, len(listDates))
					for i, v := range listDates {
						if s, ok4 := v.(string); ok4 {
							stockBasicResult.ListDates[i] = s
						}
					}
				}
				ok = true
			}
		}

		if ok {
			log.Printf("ğŸ“ [GenerateSubTasks] è‚¡ç¥¨åˆ—è¡¨ç»“æœ: %d åªè‚¡ç¥¨", len(stockBasicResult.TSCodes))
			generatedCount := 0
			// ä¸ºæ‰€æœ‰è‚¡ç¥¨ç”Ÿæˆå­ä»»åŠ¡
			// å…³é”®ï¼šåœ¨ç”Ÿæˆå­ä»»åŠ¡æ—¶ï¼Œå¯ä»¥ä¸ºæ¯ä¸ªå­ä»»åŠ¡è®¾ç½®ä¸åŒçš„å‚æ•°å€¼
			// ä¾‹å¦‚ï¼šä¸Šæ¸¸è¿”å› ts_codes=['000001.SZ', '000002.SZ', '000003.SZ', '000004.SZ', '000005.SZ']
			// è¿™é‡Œä¼šä¸ºæ¯ä¸ª ts_code å€¼åˆ›å»ºä¸€ä¸ªå­ä»»åŠ¡ï¼Œå¹¶å°†è¯¥å€¼æ³¨å…¥åˆ°å­ä»»åŠ¡çš„å‚æ•°ä¸­
			for _, tsCode := range stockBasicResult.TSCodes {
				log.Printf("ğŸ“ [GenerateSubTasks] ç”Ÿæˆå¤æƒå› å­ä»»åŠ¡: ts_code=%s", tsCode)

				// åˆ›å»ºå­ä»»åŠ¡ï¼ˆä½¿ç”¨TaskBuilderï¼‰
				// âœ… å¯ä»¥åœ¨ç”Ÿæˆå­ä»»åŠ¡æ—¶è®¾ç½®å‚æ•°ï¼šé€šè¿‡ WithJobFunction çš„ params å‚æ•°
				// æ¯ä¸ªå­ä»»åŠ¡éƒ½ä¼šè·å¾—ä¸åŒçš„ ts_code å€¼ï¼Œè¿™äº›å€¼æ¥è‡ªä¸Šæ¸¸ä»»åŠ¡çš„ç»“æœæ•°ç»„
				subTaskName := fmt.Sprintf("è·å–å¤æƒå› å­_%s", tsCode)
				subTask, err := builder.NewTaskBuilder(subTaskName, fmt.Sprintf("è·å–%sçš„å¤æƒå› å­", tsCode), registry).
					WithJobFunction("QueryTushare", map[string]interface{}{
						"api_name": "adj_factor",
						"ts_code":  tsCode, // âœ… ä¸ºæ¯ä¸ªå­ä»»åŠ¡æ³¨å…¥ä¸åŒçš„ ts_code å‚æ•°å€¼
					}).
					WithDependency(parentTaskName). // å­ä»»åŠ¡ä¾èµ–çˆ¶ä»»åŠ¡
					WithTaskHandler(task.TaskStatusSuccess, "SaveResult").
					WithTaskHandler(task.TaskStatusFailed, "LogError").
					Build()
				if err != nil {
					log.Printf("âŒ [GenerateSubTasks] åˆ›å»ºadj_factorå­ä»»åŠ¡å¤±è´¥: ts_code=%s, error=%v", tsCode, err)
					continue
				}

				// âœ… ä¹Ÿå¯ä»¥é€šè¿‡ SetParam æ–¹æ³•åœ¨åˆ›å»ºåè®¾ç½®æˆ–ä¿®æ”¹å‚æ•°ï¼ˆå¦‚æœéœ€è¦çš„è¯ï¼‰
				// ä¾‹å¦‚ï¼šsubTask.SetParam("ts_code", tsCode)
				// ä½†åœ¨è¿™ä¸ªåœºæ™¯ä¸­ï¼Œå·²ç»åœ¨ WithJobFunction ä¸­è®¾ç½®äº†ï¼Œæ‰€ä»¥ä¸éœ€è¦
				//
				// æ³¨æ„ï¼šå¦‚æœéœ€è¦åœ¨åˆ›å»ºåä¿®æ”¹å‚æ•°ï¼Œå¯ä»¥ä½¿ç”¨ï¼š
				// subTask.SetParam("ts_code", tsCode)

				// æ·»åŠ å­ä»»åŠ¡åˆ°WorkflowInstance
				// âœ… å­ä»»åŠ¡çš„å‚æ•°å·²ç»é€šè¿‡ WithJobFunction è®¾ç½®å¥½äº†ï¼Œå¼•æ“ä¼šä½¿ç”¨è¿™äº›å‚æ•°æ‰§è¡Œä»»åŠ¡
				// æ¯ä¸ªå­ä»»åŠ¡éƒ½ä¼šè·å¾—ä¸åŒçš„ ts_code å€¼ï¼Œä¾‹å¦‚ï¼š
				// - å­ä»»åŠ¡1: ts_code=000001.SZ
				// - å­ä»»åŠ¡2: ts_code=000002.SZ
				// - å­ä»»åŠ¡3: ts_code=000003.SZ
				// - ...
				context := context.Background()
				if err := eng.AddSubTaskToInstance(context, workflowInstanceID, subTask, parentTaskID); err != nil {
					log.Printf("âŒ [GenerateSubTasks] æ·»åŠ adj_factorå­ä»»åŠ¡å¤±è´¥: ts_code=%s, error=%v", tsCode, err)
					continue
				}

				generatedCount++
				log.Printf("âœ… [GenerateSubTasks] adj_factorå­ä»»åŠ¡å·²æ·»åŠ : %s (ID=%s), ts_code=%s", subTaskName, subTask.GetID(), tsCode)
			}
			log.Printf("âœ… [GenerateSubTasks] å…±ç”Ÿæˆ %d ä¸ªadj_factorå­ä»»åŠ¡ï¼ˆé¢„æœŸ: %dï¼‰", generatedCount, ExpectedAdjFactorSubTaskCount)
			if generatedCount != ExpectedAdjFactorSubTaskCount {
				log.Printf("âš ï¸ [GenerateSubTasks] adj_factorå­ä»»åŠ¡æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=%d, å®é™…=%d", ExpectedAdjFactorSubTaskCount, generatedCount)
			}
		}
	}
}

// SaveResult ä¿å­˜ç»“æœæ•°æ®ï¼ˆSuccess Handlerï¼‰
func SaveResult(ctx *task.TaskContext) {
	log.Printf("ğŸ’¾ [SaveResult] è¢«è°ƒç”¨ï¼ŒTaskName=%s, TaskID=%s", ctx.TaskName, ctx.TaskID)

	// è·å–ç»“æœæ•°æ®ï¼ˆå°è¯•å¤šä¸ªå¯èƒ½çš„å‚æ•°åï¼‰
	resultData := ctx.GetParam("_result_data")
	if resultData == nil {
		resultData = ctx.GetParam("result")
	}
	if resultData == nil {
		// å°è¯•ä»æ‰€æœ‰å‚æ•°ä¸­æŸ¥æ‰¾ç»“æœæ•°æ®
		for k, v := range ctx.Params {
			if k != "_status" && k != "_previous_status" && k != "_error_message" {
				resultData = v
				log.Printf("ğŸ“ [SaveResult] ä»å‚æ•° %s è·å–ç»“æœæ•°æ®", k)
				break
			}
		}
	}
	if resultData == nil {
		log.Printf("âš ï¸ [SaveResult] æœªæ‰¾åˆ°ç»“æœæ•°æ®ï¼Œæ‰€æœ‰å‚æ•°é”®: %v", func() []string {
			keys := make([]string, 0, len(ctx.Params))
			for k := range ctx.Params {
				keys = append(keys, k)
			}
			return keys
		}())
		return
	}

	// è·å–æ•°æ®ä»“åº“ï¼ˆé€šè¿‡ä¾èµ–æ³¨å…¥ï¼Œä½¿ç”¨å­—ç¬¦ä¸²keyï¼‰
	repoInterface, ok := ctx.GetDependency("QuantDataRepository")
	if !ok {
		log.Printf("âš ï¸ [SaveResult] æœªæ‰¾åˆ°QuantDataRepositoryä¾èµ–")
		return
	}
	repo, ok := repoInterface.(*QuantDataRepository)
	if !ok {
		log.Printf("âš ï¸ [SaveResult] QuantDataRepositoryç±»å‹è½¬æ¢å¤±è´¥")
		return
	}

	// æ ¹æ®ç»“æœç±»å‹ä¿å­˜æ•°æ®
	// æ³¨æ„ï¼štrade_cal å’Œ stock_basic åº”è¯¥ä¸ºæ¯ä¸ªäº¤æ˜“æ—¥/è‚¡ç¥¨ä¿å­˜ 1 æ¡æ•°æ®
	switch result := resultData.(type) {
	case TradeCalResult:
		// ä¸ºæ¯ä¸ªäº¤æ˜“æ—¥ä¿å­˜ 1 æ¡æ•°æ®
		for i, calDate := range result.CalDates {
			dataToSave := map[string]interface{}{
				"type":     "trade_cal",
				"exchange": result.Exchange,
				"cal_date": calDate,
				"is_open":  result.IsOpen[i],
				"pre_date": result.PreDates[i],
			}
			if err := repo.Save(dataToSave); err != nil {
				log.Printf("âŒ [SaveResult] ä¿å­˜trade_calæ•°æ®å¤±è´¥: %v", err)
			} else {
				log.Printf("âœ… [SaveResult] trade_calæ•°æ®ä¿å­˜æˆåŠŸ: cal_date=%s", calDate)
			}
		}
		// æ³¨æ„ï¼šä¸åœ¨è¿™é‡Œè°ƒç”¨ GenerateSubTasksï¼Œè€Œæ˜¯é€šè¿‡é…ç½® Handler æ¥æ§åˆ¶
		// å¦‚æœéœ€è¦åœ¨ä¿å­˜åç”Ÿæˆå­ä»»åŠ¡ï¼Œåº”è¯¥é…ç½® GenerateSubTasks ä½œä¸º Success Handler
		return
	case StockBasicResult:
		// ä¸ºæ¯åªè‚¡ç¥¨ä¿å­˜ 1 æ¡æ•°æ®
		for i, tsCode := range result.TSCodes {
			dataToSave := map[string]interface{}{
				"type":      "stock_basic",
				"ts_code":   tsCode,
				"symbol":    result.Symbols[i],
				"name":      result.Names[i],
				"area":      result.Areas[i],
				"industry":  result.Industries[i],
				"list_date": result.ListDates[i],
			}
			if err := repo.Save(dataToSave); err != nil {
				log.Printf("âŒ [SaveResult] ä¿å­˜stock_basicæ•°æ®å¤±è´¥: %v", err)
			} else {
				log.Printf("âœ… [SaveResult] stock_basicæ•°æ®ä¿å­˜æˆåŠŸ: ts_code=%s", tsCode)
			}
		}
		// æ³¨æ„ï¼šä¸åœ¨è¿™é‡Œè°ƒç”¨ GenerateSubTasksï¼Œè€Œæ˜¯é€šè¿‡é…ç½® Handler æ¥æ§åˆ¶
		// å¦‚æœéœ€è¦åœ¨ä¿å­˜åç”Ÿæˆå­ä»»åŠ¡ï¼Œåº”è¯¥é…ç½® GenerateSubTasks ä½œä¸º Success Handler
		return
	}

	// å¯¹äºå…¶ä»–ç±»å‹ï¼ˆdailyã€adj_factorï¼‰ï¼Œä¿å­˜å•æ¡æ•°æ®
	var dataType string
	var dataToSave map[string]interface{}

	switch result := resultData.(type) {
	case DailyResult:
		dataType = "daily"
		dataToSave = map[string]interface{}{
			"type":       dataType,
			"ts_code":    result.TSCode,
			"trade_date": result.TradeDate,
			"open":       result.Open,
			"high":       result.High,
			"low":        result.Low,
			"close":      result.Close,
			"pre_close":  result.PreClose,
			"change":     result.Change,
			"pct_chg":    result.PctChg,
			"vol":        result.Vol,
			"amount":     result.Amount,
		}
	case AdjFactorResult:
		dataType = "adj_factor"
		dataToSave = map[string]interface{}{
			"type":       dataType,
			"ts_code":    result.TSCode,
			"trade_date": result.TradeDate,
			"adj_factor": result.AdjFactor,
		}
	default:
		// å°è¯•JSONåºåˆ—åŒ–
		jsonData, err := json.Marshal(result)
		if err != nil {
			log.Printf("âŒ [SaveResult] æ— æ³•åºåˆ—åŒ–ç»“æœæ•°æ®: %v", err)
			return
		}
		dataType = "unknown"
		dataToSave = map[string]interface{}{
			"type": dataType,
			"data": string(jsonData),
		}
	}

	// ä¿å­˜æ•°æ®
	if err := repo.Save(dataToSave); err != nil {
		log.Printf("âŒ [SaveResult] ä¿å­˜æ•°æ®å¤±è´¥: %v", err)
	} else {
		log.Printf("âœ… [SaveResult] æ•°æ®ä¿å­˜æˆåŠŸï¼Œç±»å‹=%s", dataType)
	}
}

// SaveResultAndGenerateSubTasks ä¿å­˜ç»“æœæ•°æ®å¹¶ç”Ÿæˆå­ä»»åŠ¡ï¼ˆSuccess Handlerï¼‰
// è¿™ä¸ª Handler åŒæ—¶æ‰§è¡Œ SaveResult å’Œ GenerateSubTasks
func SaveResultAndGenerateSubTasks(ctx *task.TaskContext) {
	// å…ˆæ‰§è¡Œ SaveResult
	SaveResult(ctx)
	// ç„¶åæ‰§è¡Œ GenerateSubTasksï¼ˆåªæœ‰ trade_cal å’Œ stock_basic ä¼šç”Ÿæˆå­ä»»åŠ¡ï¼‰
	GenerateSubTasks(ctx)
}

// LogError è®°å½•é”™è¯¯ï¼ˆFailed Handlerï¼‰
func LogError(ctx *task.TaskContext) {
	errorMsg := ctx.GetParamString("_error_message")
	taskName := ctx.TaskName
	log.Printf("âŒ [LogError] ä»»åŠ¡=%s, é”™è¯¯=%s", taskName, errorMsg)
}

// ==================== å­—æ®µå®Œæ•´æ€§éªŒè¯å‡½æ•° ====================

// validateDailyDataFields éªŒè¯ daily æ•°æ®å­—æ®µå®Œæ•´æ€§
// æ ¹æ®éœ€æ±‚æ–‡æ¡£ï¼Œdaily åº”è¯¥åŒ…å«ï¼šts_code(str), trade_date(str), open(str), high(float), low(float), close(str), pre_close(float), change(float), pct_chg(float), vol(int), amount(float)
func validateDailyDataFields(t *testing.T, data map[string]interface{}, index int) {
	requiredFields := []string{
		"type",       // é¢å¤–å­—æ®µï¼Œç”¨äºæ ‡è¯†æ•°æ®ç±»å‹
		"ts_code",    // str
		"trade_date", // str
		"open",       // str
		"high",       // float
		"low",        // float
		"close",      // str
		"pre_close",  // float
		"change",     // float
		"pct_chg",    // float
		"vol",        // int
		"amount",     // float
	}

	missingFields := make([]string, 0)
	for _, field := range requiredFields {
		if _, exists := data[field]; !exists {
			missingFields = append(missingFields, field)
		}
	}

	if len(missingFields) > 0 {
		t.Errorf("dailyæ•°æ®[%d]ç¼ºå°‘å¿…éœ€å­—æ®µ: %v", index, missingFields)
	}

	// éªŒè¯å­—æ®µç±»å‹
	if tsCode, ok := data["ts_code"].(string); !ok || tsCode == "" {
		t.Errorf("dailyæ•°æ®[%d] ts_code å­—æ®µç±»å‹é”™è¯¯æˆ–ä¸ºç©º", index)
	}
	if tradeDate, ok := data["trade_date"].(string); !ok || tradeDate == "" {
		t.Errorf("dailyæ•°æ®[%d] trade_date å­—æ®µç±»å‹é”™è¯¯æˆ–ä¸ºç©º", index)
	}
	if open, ok := data["open"].(string); !ok || open == "" {
		t.Errorf("dailyæ•°æ®[%d] open å­—æ®µç±»å‹é”™è¯¯æˆ–ä¸ºç©º", index)
	}
	if _, ok := data["high"].(float64); !ok {
		t.Errorf("dailyæ•°æ®[%d] high å­—æ®µç±»å‹é”™è¯¯ï¼ŒæœŸæœ› float64", index)
	}
	if _, ok := data["low"].(float64); !ok {
		t.Errorf("dailyæ•°æ®[%d] low å­—æ®µç±»å‹é”™è¯¯ï¼ŒæœŸæœ› float64", index)
	}
	if close, ok := data["close"].(string); !ok || close == "" {
		t.Errorf("dailyæ•°æ®[%d] close å­—æ®µç±»å‹é”™è¯¯æˆ–ä¸ºç©º", index)
	}
	if _, ok := data["pre_close"].(float64); !ok {
		t.Errorf("dailyæ•°æ®[%d] pre_close å­—æ®µç±»å‹é”™è¯¯ï¼ŒæœŸæœ› float64", index)
	}
	if _, ok := data["change"].(float64); !ok {
		t.Errorf("dailyæ•°æ®[%d] change å­—æ®µç±»å‹é”™è¯¯ï¼ŒæœŸæœ› float64", index)
	}
	if _, ok := data["pct_chg"].(float64); !ok {
		t.Errorf("dailyæ•°æ®[%d] pct_chg å­—æ®µç±»å‹é”™è¯¯ï¼ŒæœŸæœ› float64", index)
	}
	if _, ok := data["vol"].(int); !ok {
		t.Errorf("dailyæ•°æ®[%d] vol å­—æ®µç±»å‹é”™è¯¯ï¼ŒæœŸæœ› int", index)
	}
	if _, ok := data["amount"].(float64); !ok {
		t.Errorf("dailyæ•°æ®[%d] amount å­—æ®µç±»å‹é”™è¯¯ï¼ŒæœŸæœ› float64", index)
	}
}

// validateAdjFactorDataFields éªŒè¯ adj_factor æ•°æ®å­—æ®µå®Œæ•´æ€§
// æ ¹æ®éœ€æ±‚æ–‡æ¡£ï¼Œadj_factor åº”è¯¥åŒ…å«ï¼šts_code(str), trade_date(str), adj_factor(float)
func validateAdjFactorDataFields(t *testing.T, data map[string]interface{}, index int) {
	requiredFields := []string{
		"type",       // é¢å¤–å­—æ®µï¼Œç”¨äºæ ‡è¯†æ•°æ®ç±»å‹
		"ts_code",    // str
		"trade_date", // str
		"adj_factor", // float
	}

	missingFields := make([]string, 0)
	for _, field := range requiredFields {
		if _, exists := data[field]; !exists {
			missingFields = append(missingFields, field)
		}
	}

	if len(missingFields) > 0 {
		t.Errorf("adj_factoræ•°æ®[%d]ç¼ºå°‘å¿…éœ€å­—æ®µ: %v", index, missingFields)
	}

	// éªŒè¯å­—æ®µç±»å‹
	if tsCode, ok := data["ts_code"].(string); !ok || tsCode == "" {
		t.Errorf("adj_factoræ•°æ®[%d] ts_code å­—æ®µç±»å‹é”™è¯¯æˆ–ä¸ºç©º", index)
	}
	if tradeDate, ok := data["trade_date"].(string); !ok || tradeDate == "" {
		t.Errorf("adj_factoræ•°æ®[%d] trade_date å­—æ®µç±»å‹é”™è¯¯æˆ–ä¸ºç©º", index)
	}
	if _, ok := data["adj_factor"].(float64); !ok {
		t.Errorf("adj_factoræ•°æ®[%d] adj_factor å­—æ®µç±»å‹é”™è¯¯ï¼ŒæœŸæœ› float64", index)
	}
}

// validateTradeCalDataFields éªŒè¯ trade_cal æ•°æ®å­—æ®µå®Œæ•´æ€§
// æ ¹æ®éœ€æ±‚æ–‡æ¡£ï¼Œtrade_cal åº”è¯¥åŒ…å«ï¼šexchange(str), cal_date(str, yyyymmdd), is_open(str), pre_date(str)
func validateTradeCalDataFields(t *testing.T, data map[string]interface{}, index int) {
	requiredFields := []string{
		"type",     // é¢å¤–å­—æ®µ
		"exchange", // str
		"cal_date", // str
		"is_open",  // str
		"pre_date", // str
	}

	missingFields := make([]string, 0)
	for _, field := range requiredFields {
		if _, exists := data[field]; !exists {
			missingFields = append(missingFields, field)
		}
	}

	if len(missingFields) > 0 {
		t.Errorf("trade_calæ•°æ®[%d]ç¼ºå°‘å¿…éœ€å­—æ®µ: %v", index, missingFields)
	}
}

// validateStockBasicDataFields éªŒè¯ stock_basic æ•°æ®å­—æ®µå®Œæ•´æ€§
// æ ¹æ®éœ€æ±‚æ–‡æ¡£ï¼Œstock_basic åº”è¯¥åŒ…å«ï¼šts_code(str), symbol(str), name(str), area(str), industry(str), list_date(str)
func validateStockBasicDataFields(t *testing.T, data map[string]interface{}, index int) {
	requiredFields := []string{
		"type",      // é¢å¤–å­—æ®µ
		"ts_code",   // str
		"symbol",    // str
		"name",      // str
		"area",      // str
		"industry",  // str
		"list_date", // str
	}

	missingFields := make([]string, 0)
	for _, field := range requiredFields {
		if _, exists := data[field]; !exists {
			missingFields = append(missingFields, field)
		}
	}

	if len(missingFields) > 0 {
		t.Errorf("stock_basicæ•°æ®[%d]ç¼ºå°‘å¿…éœ€å­—æ®µ: %v", index, missingFields)
	}
}

// ==================== æµ‹è¯•å‡½æ•° ====================

func setupTushareTest(t *testing.T) (*engine.Engine, task.FunctionRegistry, *QuantDataRepository, storage.TaskRepository, func()) {
	// åˆ›å»ºä¸´æ—¶æ•°æ®åº“
	tmpDir := t.TempDir()
	dbPath := filepath.Join(tmpDir, "tushare_test.db")

	// åˆ›å»ºRepository
	repos, err := sqlite.NewRepositories(dbPath)
	if err != nil {
		t.Fatalf("åˆ›å»ºRepositoryå¤±è´¥: %v", err)
	}

	// åˆ›å»ºEngine
	eng, err := engine.NewEngine(10, 30, repos.Workflow, repos.WorkflowInstance, repos.Task)
	if err != nil {
		t.Fatalf("åˆ›å»ºEngineå¤±è´¥: %v", err)
	}

	// è·å–Registry
	registry := eng.GetRegistry()
	if registry == nil {
		t.Fatalf("è·å–registryå¤±è´¥")
	}

	// åˆ›å»ºæ•°æ®ä»“åº“
	repo := NewQuantDataRepository()

	// æ³¨å†Œä¾èµ–
	ctx := context.Background()
	if err := registry.RegisterDependencyWithKey("QuantDataRepository", repo); err != nil {
		t.Fatalf("æ³¨å†ŒQuantDataRepositoryä¾èµ–å¤±è´¥: %v", err)
	}
	if err := registry.RegisterDependencyWithKey("Engine", eng); err != nil {
		t.Fatalf("æ³¨å†ŒEngineä¾èµ–å¤±è´¥: %v", err)
	}

	// å¯åŠ¨Engine
	if err := eng.Start(ctx); err != nil {
		t.Fatalf("å¯åŠ¨Engineå¤±è´¥: %v", err)
	}

	// æ³¨å†ŒJobå‡½æ•°
	_, err = registry.Register(ctx, "QueryTushare", QueryTushare, "æ¨¡æ‹ŸTushare APIæŸ¥è¯¢")
	if err != nil {
		t.Fatalf("æ³¨å†ŒQueryTushareå¤±è´¥: %v", err)
	}

	// æ³¨å†ŒTask Handler
	_, err = registry.RegisterTaskHandler(ctx, "SaveResult", SaveResult, "ä¿å­˜ç»“æœæ•°æ®")
	if err != nil {
		t.Fatalf("æ³¨å†ŒSaveResultå¤±è´¥: %v", err)
	}

	_, err = registry.RegisterTaskHandler(ctx, "LogError", LogError, "è®°å½•é”™è¯¯")
	if err != nil {
		t.Fatalf("æ³¨å†ŒLogErrorå¤±è´¥: %v", err)
	}

	_, err = registry.RegisterTaskHandler(ctx, "GenerateSubTasks", GenerateSubTasks, "ç”Ÿæˆå­ä»»åŠ¡")
	if err != nil {
		t.Fatalf("æ³¨å†ŒGenerateSubTaskså¤±è´¥: %v", err)
	}

	_, err = registry.RegisterTaskHandler(ctx, "SaveResultAndGenerateSubTasks", SaveResultAndGenerateSubTasks, "ä¿å­˜ç»“æœæ•°æ®å¹¶ç”Ÿæˆå­ä»»åŠ¡")
	if err != nil {
		t.Fatalf("æ³¨å†ŒSaveResultAndGenerateSubTaskså¤±è´¥: %v", err)
	}

	cleanup := func() {
		eng.Stop()
		repos.Close()
		os.Remove(dbPath)
	}

	return eng, registry, repo, repos.Task, cleanup
}

func TestTushareWorkflow_Basic(t *testing.T) {
	eng, registry, repo, taskRepo, cleanup := setupTushareTest(t)
	defer cleanup()

	ctx := context.Background()

	// åˆ›å»ºä»»åŠ¡ç»„1ï¼šæ— ä¾èµ–ä»»åŠ¡
	// æ³¨æ„ï¼šTestTushareWorkflow_Basic åªæ‰§è¡Œå‰ä¸¤ä¸ªä»»åŠ¡ï¼Œä¸ç”Ÿæˆå­ä»»åŠ¡ï¼Œæ‰€ä»¥åªä½¿ç”¨ SaveResult
	task1, err := builder.NewTaskBuilder("è·å–äº¤æ˜“æ—¥å†", "è·å–Tushareäº¤æ˜“æ—¥å†æ•°æ®", registry).
		WithJobFunction("QueryTushare", map[string]interface{}{
			"api_name": "trade_cal",
		}).
		WithTaskHandler(task.TaskStatusSuccess, "SaveResult"). // åªä¿å­˜æ•°æ®ï¼Œä¸ç”Ÿæˆå­ä»»åŠ¡
		WithTaskHandler(task.TaskStatusFailed, "LogError").
		Build()
	if err != nil {
		t.Fatalf("æ„å»ºTask1å¤±è´¥: %v", err)
	}

	// éªŒè¯StatusHandlersæ˜¯å¦æ­£ç¡®è®¾ç½®
	if len(task1.StatusHandlers) == 0 {
		t.Fatal("Task1çš„StatusHandlersä¸ºç©º")
	}
	log.Printf("âœ… [æµ‹è¯•] Task1 StatusHandlers: %v", task1.StatusHandlers)

	task2, err := builder.NewTaskBuilder("è·å–è‚¡ç¥¨åˆ—è¡¨", "è·å–Tushareè‚¡ç¥¨åˆ—è¡¨æ•°æ®", registry).
		WithJobFunction("QueryTushare", map[string]interface{}{
			"api_name": "stock_basic",
		}).
		WithTaskHandler(task.TaskStatusSuccess, "SaveResult"). // åªä¿å­˜æ•°æ®ï¼Œä¸ç”Ÿæˆå­ä»»åŠ¡
		WithTaskHandler(task.TaskStatusFailed, "LogError").
		Build()
	if err != nil {
		t.Fatalf("æ„å»ºTask2å¤±è´¥: %v", err)
	}

	// åˆ›å»ºWorkflow
	wf, err := builder.NewWorkflowBuilder("Tushareæ•°æ®ä¸‹è½½å·¥ä½œæµ", "æ¨¡æ‹Ÿä»Tushareæ‰¹é‡ä¸‹è½½æ•°æ®çš„æµç¨‹").
		WithTask(task1).
		WithTask(task2).
		Build()
	if err != nil {
		t.Fatalf("æ„å»ºWorkflowå¤±è´¥: %v", err)
	}

	// æäº¤Workflow
	controller, err := eng.SubmitWorkflow(ctx, wf)
	if err != nil {
		t.Fatalf("æäº¤Workflowå¤±è´¥: %v", err)
	}

	instanceID := controller.GetInstanceID()
	if instanceID == "" {
		t.Fatal("InstanceIDä¸ºç©º")
	}

	// ç­‰å¾…å·¥ä½œæµæ‰§è¡Œå®Œæˆï¼ˆæœ€å¤šç­‰å¾…30ç§’ï¼‰
	timeout := 30 * time.Second
	startTime := time.Now()
	for {
		status, err := controller.GetStatus()
		if err != nil {
			t.Fatalf("è·å–çŠ¶æ€å¤±è´¥: %v", err)
		}

		if status == "Success" || status == "Failed" || status == "Terminated" {
			log.Printf("âœ… [å·¥ä½œæµå®Œæˆ] çŠ¶æ€=%s, è€—æ—¶=%v", status, time.Since(startTime))
			break
		}

		if time.Since(startTime) > timeout {
			t.Fatalf("å·¥ä½œæµæ‰§è¡Œè¶…æ—¶ï¼Œå½“å‰çŠ¶æ€=%s", status)
		}

		time.Sleep(100 * time.Millisecond)
	}

	// éªŒè¯æœ€ç»ˆçŠ¶æ€
	finalStatus, err := controller.GetStatus()
	if err != nil {
		t.Fatalf("è·å–æœ€ç»ˆçŠ¶æ€å¤±è´¥: %v", err)
	}

	if finalStatus != "Success" {
		t.Errorf("æœŸæœ›å·¥ä½œæµçŠ¶æ€ä¸ºSuccessï¼Œå®é™…ä¸º%s", finalStatus)
	}

	// ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œç¡®ä¿Handleræ‰§è¡Œå®Œæˆ
	time.Sleep(500 * time.Millisecond)

	// éªŒè¯å¹¶æ‰“å°ä¿å­˜çš„æ•°æ®ï¼ˆéœ€æ±‚ç¬¬7æ¡ï¼šéœ€è¦æ‰“å°æœ€åä¿å­˜çš„æ•°æ®ï¼‰
	savedData := repo.GetSavedData()
	if len(savedData) == 0 {
		t.Logf("âš ï¸ æœªä¿å­˜ä»»ä½•æ•°æ®ï¼Œè¿™å¯èƒ½æ˜¯å› ä¸ºHandleræœªè¢«è°ƒç”¨æˆ–ä¾èµ–æ³¨å…¥å¤±è´¥")
		// æš‚æ—¶ä¸å¤±è´¥ï¼Œå› ä¸ºHandlerè°ƒç”¨å¯èƒ½æœ‰é—®é¢˜
		t.Error("æœªä¿å­˜ä»»ä½•æ•°æ®")
	} else {
		// ç»Ÿè®¡å„ç±»å‹æ•°æ®æ•°é‡
		dataCountByType := make(map[string]int)
		for _, data := range savedData {
			if dataType, ok := data["type"].(string); ok {
				dataCountByType[dataType]++
			}
		}

		log.Printf("âœ… [æ•°æ®éªŒè¯] å…±ä¿å­˜ %d æ¡æ•°æ®", len(savedData))
		log.Printf("ğŸ“Š [æ•°æ®ç»Ÿè®¡] trade_cal=%d, stock_basic=%d, daily=%d, adj_factor=%d",
			dataCountByType["trade_cal"],
			dataCountByType["stock_basic"],
			dataCountByType["daily"],
			dataCountByType["adj_factor"])

		// éªŒè¯æ•°æ®æ•°é‡æ˜¯å¦ç¬¦åˆé¢„æœŸï¼ˆéœ€æ±‚ç¬¬7æ¡ï¼šéœ€è¦ç¬¦åˆé¢„è®¾æ¨¡æ‹Ÿæ•°æ®çš„æ•°é‡ï¼‰
		// åªæ‰§è¡Œç¬¬ä¸€ç»„ä»»åŠ¡ï¼Œåº”è¯¥ä¿å­˜ 10 æ¡æ•°æ®ï¼ˆ5 trade_cal + 5 stock_basicï¼‰
		expectedCount := ExpectedTotalDataCountBasic

		log.Printf("ğŸ“Š [æ•°é‡éªŒè¯] å½“å‰æ•°æ®: %d æ¡, é¢„æœŸ: %d æ¡ï¼ˆ5 trade_cal + 5 stock_basicï¼‰",
			len(savedData), expectedCount)

		if len(savedData) != expectedCount {
			t.Errorf("æ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=%d, å®é™…=%d", expectedCount, len(savedData))
		} else {
			log.Printf("âœ… [æ•°é‡éªŒè¯] æ•°æ®æ•°é‡ç¬¦åˆé¢„æœŸ: %d æ¡", expectedCount)
		}

		// éªŒè¯å„ç±»å‹æ•°æ®æ•°é‡
		if dataCountByType["trade_cal"] != 5 {
			t.Errorf("trade_calæ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=5, å®é™…=%d", dataCountByType["trade_cal"])
		}
		if dataCountByType["stock_basic"] != 5 {
			t.Errorf("stock_basicæ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=5, å®é™…=%d", dataCountByType["stock_basic"])
		}

		// é‡è¦ï¼šéªŒè¯å­ä»»åŠ¡ç¡®å®æ²¡æœ‰ç”Ÿæˆå’Œæ‰§è¡Œ
		// TestTushareWorkflow_Basic åªä½¿ç”¨ SaveResultï¼Œä¸ç”Ÿæˆå­ä»»åŠ¡ï¼Œæ‰€ä»¥ daily å’Œ adj_factor åº”è¯¥ä¸º 0
		if dataCountByType["daily"] != 0 {
			t.Errorf("dailyæ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=0ï¼ˆä¸ç”Ÿæˆå­ä»»åŠ¡ï¼‰, å®é™…=%d", dataCountByType["daily"])
		}
		if dataCountByType["adj_factor"] != 0 {
			t.Errorf("adj_factoræ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=0ï¼ˆä¸ç”Ÿæˆå­ä»»åŠ¡ï¼‰, å®é™…=%d", dataCountByType["adj_factor"])
		}

		// éªŒè¯ä»»åŠ¡å®ä¾‹ï¼šåº”è¯¥åªæœ‰2ä¸ªä»»åŠ¡ï¼ˆtrade_cal å’Œ stock_basicï¼‰ï¼Œæ²¡æœ‰å­ä»»åŠ¡
		ctx := context.Background()
		taskInstances, err := taskRepo.GetByWorkflowInstanceID(ctx, instanceID)
		if err != nil {
			t.Logf("âš ï¸ æ— æ³•æŸ¥è¯¢ä»»åŠ¡å®ä¾‹: %v", err)
		} else {
			// ç»Ÿè®¡ä»»åŠ¡æ•°é‡
			taskCount := len(taskInstances)
			expectedTaskCount := 2 // åªæœ‰ trade_cal å’Œ stock_basic
			if taskCount != expectedTaskCount {
				t.Errorf("ä»»åŠ¡å®ä¾‹æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=%dï¼ˆä¸ç”Ÿæˆå­ä»»åŠ¡ï¼‰, å®é™…=%d", expectedTaskCount, taskCount)
			} else {
				log.Printf("âœ… [ä»»åŠ¡å®ä¾‹éªŒè¯] ä»»åŠ¡æ•°é‡ç¬¦åˆé¢„æœŸ: %d ä¸ªï¼ˆæ— å­ä»»åŠ¡ï¼‰", taskCount)
			}

			// éªŒè¯æ‰€æœ‰ä»»åŠ¡éƒ½æˆåŠŸå®Œæˆï¼ˆå…¼å®¹å¤§å°å†™ï¼‰
			for _, taskInstance := range taskInstances {
				if taskInstance.Status != "Success" && taskInstance.Status != "SUCCESS" {
					t.Errorf("ä»»åŠ¡ %s çŠ¶æ€ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=Successæˆ–SUCCESS, å®é™…=%s", taskInstance.Name, taskInstance.Status)
				}
			}
		}

		// æ‰“å°æ‰€æœ‰ä¿å­˜çš„æ•°æ®ï¼ˆéœ€æ±‚ç¬¬7æ¡ï¼‰
		separator := strings.Repeat("=", 80)
		log.Printf("\n%s", separator)
		log.Printf("ğŸ“Š [æœ€ç»ˆä¿å­˜çš„æ•°æ®] (é¢„æœŸ: %d æ¡, å®é™…: %d æ¡)", expectedCount, len(savedData))
		log.Printf("%s", separator)
		for i, data := range savedData {
			log.Printf("\n[æ•°æ® %d/%d]", i+1, len(savedData))
			if dataType, ok := data["type"].(string); ok {
				log.Printf("  ç±»å‹: %s", dataType)
			}
			// å®Œæ•´æ‰“å°æ‰€æœ‰å­—æ®µ
			for k, v := range data {
				if k != "type" {
					log.Printf("  %s: %v", k, v)
				}
			}
		}
		log.Printf("%s\n", separator)

		// éªŒè¯è‡³å°‘åŒ…å«äº¤æ˜“æ—¥å†å’Œè‚¡ç¥¨åˆ—è¡¨æ•°æ®
		hasTradeCal := false
		hasStockBasic := false
		for _, data := range savedData {
			if dataType, ok := data["type"].(string); ok {
				if dataType == "trade_cal" {
					hasTradeCal = true
				}
				if dataType == "stock_basic" {
					hasStockBasic = true
				}
			}
		}
		if !hasTradeCal {
			t.Error("æœªä¿å­˜äº¤æ˜“æ—¥å†æ•°æ®")
		}
		if !hasStockBasic {
			t.Error("æœªä¿å­˜è‚¡ç¥¨åˆ—è¡¨æ•°æ®")
		}
	}
}

func TestTushareWorkflow_WithDependencies(t *testing.T) {
	eng, registry, repo, _, cleanup := setupTushareTest(t)
	defer cleanup()

	ctx := context.Background()

	// åˆ›å»ºä»»åŠ¡ç»„1ï¼šæ— ä¾èµ–ä»»åŠ¡
	task1, _ := builder.NewTaskBuilder("è·å–äº¤æ˜“æ—¥å†", "è·å–Tushareäº¤æ˜“æ—¥å†æ•°æ®", registry).
		WithJobFunction("QueryTushare", map[string]interface{}{
			"api_name": "trade_cal",
		}).
		WithTaskHandler(task.TaskStatusSuccess, "SaveResult").
		WithTaskHandler(task.TaskStatusFailed, "LogError").
		Build()

	task2, _ := builder.NewTaskBuilder("è·å–è‚¡ç¥¨åˆ—è¡¨", "è·å–Tushareè‚¡ç¥¨åˆ—è¡¨æ•°æ®", registry).
		WithJobFunction("QueryTushare", map[string]interface{}{
			"api_name": "stock_basic",
		}).
		WithTaskHandler(task.TaskStatusSuccess, "SaveResult").
		WithTaskHandler(task.TaskStatusFailed, "LogError").
		Build()

	// åˆ›å»ºä»»åŠ¡ç»„2ï¼šä¾èµ–ä»»åŠ¡ç»„1ï¼ˆé™æ€ä»»åŠ¡ï¼Œç”¨äºæµ‹è¯•ä¾èµ–å…³ç³»ï¼‰
	// æ³¨æ„ï¼šè¿™äº›ä»»åŠ¡ä¹Ÿå¯ä»¥ä½¿ç”¨ResultMappingä»ä¸Šæ¸¸ä»»åŠ¡ç»“æœä¸­è‡ªåŠ¨è·å–å‚æ•°
	// ä½†ç”±äºå½“å‰QueryTushareè¿”å›çš„æ˜¯ç»“æ„ä½“è€Œémapï¼ŒResultMappingéœ€è¦mapæ ¼å¼çš„ç»“æœ
	// å®é™…åœºæ™¯ä¸­ï¼Œè¿™äº›ä»»åŠ¡åº”è¯¥ç”±GenerateSubTasksåŠ¨æ€ç”Ÿæˆ
	// å¦‚æœä¸Šæ¸¸ä»»åŠ¡è¿”å›mapæ ¼å¼ç»“æœï¼Œå¯ä»¥ä½¿ç”¨WithResultMappingè‡ªåŠ¨æ˜ å°„å‚æ•°ï¼Œä¾‹å¦‚ï¼š
	//   WithResultMapping(map[string]string{"ts_code": "default_code"})
	task3, _ := builder.NewTaskBuilder("è·å–æ—¥çº¿æ•°æ®_20251201", "è·å–20251201çš„æ—¥çº¿æ•°æ®", registry).
		WithJobFunction("QueryTushare", map[string]interface{}{
			"api_name":   "daily",
			"trade_date": "20251201",
			"ts_code":    "000001.SZ",
		}).
		WithDependency("è·å–äº¤æ˜“æ—¥å†").
		WithTaskHandler(task.TaskStatusSuccess, "SaveResult").
		WithTaskHandler(task.TaskStatusFailed, "LogError").
		Build()

	task4, _ := builder.NewTaskBuilder("è·å–å¤æƒå› å­_000001.SZ", "è·å–000001.SZçš„å¤æƒå› å­", registry).
		WithJobFunction("QueryTushare", map[string]interface{}{
			"api_name": "adj_factor",
			"ts_code":  "000001.SZ",
		}).
		WithDependency("è·å–è‚¡ç¥¨åˆ—è¡¨").
		WithTaskHandler(task.TaskStatusSuccess, "SaveResult").
		WithTaskHandler(task.TaskStatusFailed, "LogError").
		Build()

	// åˆ›å»ºWorkflow
	wf, err := builder.NewWorkflowBuilder("Tushareæ•°æ®ä¸‹è½½å·¥ä½œæµï¼ˆå«ä¾èµ–ï¼‰", "æµ‹è¯•ä¾èµ–å…³ç³»çš„æ­£ç¡®æ‰§è¡Œé¡ºåº").
		WithTask(task1).
		WithTask(task2).
		WithTask(task3).
		WithTask(task4).
		Build()
	if err != nil {
		t.Fatalf("æ„å»ºWorkflowå¤±è´¥: %v", err)
	}

	// æäº¤Workflow
	controller, err := eng.SubmitWorkflow(ctx, wf)
	if err != nil {
		t.Fatalf("æäº¤Workflowå¤±è´¥: %v", err)
	}

	// ç­‰å¾…å·¥ä½œæµæ‰§è¡Œå®Œæˆ
	timeout := 30 * time.Second
	startTime := time.Now()
	for {
		status, err := controller.GetStatus()
		if err != nil {
			t.Fatalf("è·å–çŠ¶æ€å¤±è´¥: %v", err)
		}

		if status == "Success" || status == "Failed" || status == "Terminated" {
			log.Printf("âœ… [å·¥ä½œæµå®Œæˆ] çŠ¶æ€=%s, è€—æ—¶=%v", status, time.Since(startTime))
			break
		}

		if time.Since(startTime) > timeout {
			t.Fatalf("å·¥ä½œæµæ‰§è¡Œè¶…æ—¶ï¼Œå½“å‰çŠ¶æ€=%s", status)
		}

		time.Sleep(100 * time.Millisecond)
	}

	// éªŒè¯æœ€ç»ˆçŠ¶æ€
	finalStatus, err := controller.GetStatus()
	if err != nil {
		t.Fatalf("è·å–æœ€ç»ˆçŠ¶æ€å¤±è´¥: %v", err)
	}

	if finalStatus != "Success" {
		t.Errorf("æœŸæœ›å·¥ä½œæµçŠ¶æ€ä¸ºSuccessï¼Œå®é™…ä¸º%s", finalStatus)
	}

	// ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œç¡®ä¿Handleræ‰§è¡Œå®Œæˆ
	time.Sleep(500 * time.Millisecond)

	// éªŒè¯å¹¶æ‰“å°ä¿å­˜çš„æ•°æ®ï¼ˆéœ€æ±‚ç¬¬7æ¡ï¼šéœ€è¦æ‰“å°æœ€åä¿å­˜çš„æ•°æ®ï¼‰
	savedData := repo.GetSavedData()

	// ç»Ÿè®¡å„ç±»å‹æ•°æ®æ•°é‡
	dataCountByType := make(map[string]int)
	for _, data := range savedData {
		if dataType, ok := data["type"].(string); ok {
			dataCountByType[dataType]++
		}
	}

	log.Printf("âœ… [æ•°æ®éªŒè¯] å…±ä¿å­˜ %d æ¡æ•°æ®", len(savedData))
	log.Printf("ğŸ“Š [æ•°æ®ç»Ÿè®¡] trade_cal=%d, stock_basic=%d, daily=%d, adj_factor=%d",
		dataCountByType["trade_cal"],
		dataCountByType["stock_basic"],
		dataCountByType["daily"],
		dataCountByType["adj_factor"])

	// éªŒè¯æ•°æ®æ•°é‡æ˜¯å¦ç¬¦åˆé¢„æœŸï¼ˆéœ€æ±‚ç¬¬7æ¡ï¼šéœ€è¦ç¬¦åˆé¢„è®¾æ¨¡æ‹Ÿæ•°æ®çš„æ•°é‡ï¼‰
	// é™æ€ä»»åŠ¡åœºæ™¯ï¼š5 trade_cal + 5 stock_basic + 1 daily + 1 adj_factor = 12æ¡
	expectedCount := ExpectedTotalDataCountWithDependencies

	log.Printf("ğŸ“Š [æ•°é‡éªŒè¯] å½“å‰æ•°æ®: %d æ¡, é¢„æœŸ: %d æ¡ï¼ˆ5 trade_cal + 5 stock_basic + 1 daily + 1 adj_factorï¼‰",
		len(savedData), expectedCount)

	if len(savedData) != expectedCount {
		t.Errorf("æ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=%d, å®é™…=%d", expectedCount, len(savedData))
	} else {
		log.Printf("âœ… [æ•°é‡éªŒè¯] æ•°æ®æ•°é‡ç¬¦åˆé¢„æœŸ: %d æ¡", expectedCount)
	}

	// éªŒè¯å„ç±»å‹æ•°æ®æ•°é‡
	if dataCountByType["trade_cal"] != 5 {
		t.Errorf("trade_calæ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=5, å®é™…=%d", dataCountByType["trade_cal"])
	}
	if dataCountByType["stock_basic"] != 5 {
		t.Errorf("stock_basicæ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=5, å®é™…=%d", dataCountByType["stock_basic"])
	}
	if dataCountByType["daily"] != 1 {
		t.Errorf("dailyæ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=1, å®é™…=%d", dataCountByType["daily"])
	}
	if dataCountByType["adj_factor"] != 1 {
		t.Errorf("adj_factoræ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=1, å®é™…=%d", dataCountByType["adj_factor"])
	}

	// éªŒè¯å­—æ®µå®Œæ•´æ€§ï¼šæ£€æŸ¥æ‰€æœ‰ä¿å­˜çš„æ•°æ®æ˜¯å¦åŒ…å«å¿…éœ€çš„å­—æ®µ
	log.Printf("ğŸ” [å­—æ®µå®Œæ•´æ€§éªŒè¯] å¼€å§‹éªŒè¯æ‰€æœ‰æ•°æ®çš„å­—æ®µå®Œæ•´æ€§...")
	dailyIndex := 0
	adjFactorIndex := 0
	tradeCalIndex := 0
	stockBasicIndex := 0
	for i, data := range savedData {
		if dataType, ok := data["type"].(string); ok {
			switch dataType {
			case "daily":
				validateDailyDataFields(t, data, dailyIndex)
				dailyIndex++
			case "adj_factor":
				validateAdjFactorDataFields(t, data, adjFactorIndex)
				adjFactorIndex++
			case "trade_cal":
				validateTradeCalDataFields(t, data, tradeCalIndex)
				tradeCalIndex++
			case "stock_basic":
				validateStockBasicDataFields(t, data, stockBasicIndex)
				stockBasicIndex++
			default:
				t.Logf("âš ï¸ æœªçŸ¥æ•°æ®ç±»å‹: %s (æ•°æ®ç´¢å¼•: %d)", dataType, i)
			}
		}
	}
	log.Printf("âœ… [å­—æ®µå®Œæ•´æ€§éªŒè¯] å®Œæˆï¼ŒéªŒè¯äº† %d æ¡ daily æ•°æ®ï¼Œ%d æ¡ adj_factor æ•°æ®ï¼Œ%d æ¡ trade_cal æ•°æ®ï¼Œ%d æ¡ stock_basic æ•°æ®",
		dailyIndex, adjFactorIndex, tradeCalIndex, stockBasicIndex)

	// æ‰“å°æ‰€æœ‰ä¿å­˜çš„æ•°æ®ï¼ˆéœ€æ±‚ç¬¬7æ¡ï¼‰
	if len(savedData) > 0 {
		separator := strings.Repeat("=", 80)
		log.Printf("\n%s", separator)
		log.Printf("ğŸ“Š [æœ€ç»ˆä¿å­˜çš„æ•°æ®] (é¢„æœŸ: %d æ¡, å®é™…: %d æ¡)", expectedCount, len(savedData))
		log.Printf("%s", separator)
		for i, data := range savedData {
			log.Printf("\n[æ•°æ® %d/%d]", i+1, len(savedData))
			if dataType, ok := data["type"].(string); ok {
				log.Printf("  ç±»å‹: %s", dataType)
			}
			// å®Œæ•´æ‰“å°æ‰€æœ‰å­—æ®µ
			for k, v := range data {
				if k != "type" {
					log.Printf("  %s: %v", k, v)
				}
			}
		}
		log.Printf("%s\n", separator)
	}

	// éªŒè¯æ•°æ®åŒ…å«æ‰€æœ‰ç±»å‹
	dataTypes := make(map[string]bool)
	for _, data := range savedData {
		if dataType, ok := data["type"].(string); ok {
			dataTypes[dataType] = true
		}
	}

	expectedTypes := []string{"trade_cal", "stock_basic", "daily", "adj_factor"}
	for _, expectedType := range expectedTypes {
		if !dataTypes[expectedType] {
			t.Errorf("ç¼ºå°‘æ•°æ®ç±»å‹: %s", expectedType)
		}
	}
}

// TestTushareWorkflow_Full å®Œæ•´æµ‹è¯•ï¼šæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡ï¼ŒåŒ…æ‹¬åŠ¨æ€ç”Ÿæˆçš„å­ä»»åŠ¡
// é¢„æœŸä¿å­˜ 20 æ¡æ•°æ®ï¼š5 trade_cal + 5 stock_basic + 5 daily + 5 adj_factor
func TestTushareWorkflow_Full(t *testing.T) {
	eng, registry, repo, taskRepo, cleanup := setupTushareTest(t)
	defer cleanup()

	ctx := context.Background()

	// åˆ›å»ºä»»åŠ¡ç»„1ï¼šæ— ä¾èµ–ä»»åŠ¡
	// æ³¨æ„ï¼šTestTushareWorkflow_Full éœ€è¦ç”Ÿæˆå­ä»»åŠ¡ï¼Œæ‰€ä»¥ä½¿ç”¨ SaveResultAndGenerateSubTasks
	task1, err := builder.NewTaskBuilder("è·å–äº¤æ˜“æ—¥å†", "è·å–Tushareäº¤æ˜“æ—¥å†æ•°æ®", registry).
		WithJobFunction("QueryTushare", map[string]interface{}{
			"api_name": "trade_cal",
		}).
		WithTaskHandler(task.TaskStatusSuccess, "SaveResultAndGenerateSubTasks"). // ä¿å­˜æ•°æ®å¹¶ç”Ÿæˆå­ä»»åŠ¡
		WithTaskHandler(task.TaskStatusFailed, "LogError").
		Build()
	if err != nil {
		t.Fatalf("æ„å»ºTask1å¤±è´¥: %v", err)
	}

	task2, err := builder.NewTaskBuilder("è·å–è‚¡ç¥¨åˆ—è¡¨", "è·å–Tushareè‚¡ç¥¨åˆ—è¡¨æ•°æ®", registry).
		WithJobFunction("QueryTushare", map[string]interface{}{
			"api_name": "stock_basic",
		}).
		WithTaskHandler(task.TaskStatusSuccess, "SaveResultAndGenerateSubTasks"). // ä¿å­˜æ•°æ®å¹¶ç”Ÿæˆå­ä»»åŠ¡
		WithTaskHandler(task.TaskStatusFailed, "LogError").
		Build()
	if err != nil {
		t.Fatalf("æ„å»ºTask2å¤±è´¥: %v", err)
	}

	// åˆ›å»ºWorkflow
	wf, err := builder.NewWorkflowBuilder("Tushareæ•°æ®ä¸‹è½½å·¥ä½œæµï¼ˆå®Œæ•´ï¼‰", "æµ‹è¯•å®Œæ•´æµç¨‹ï¼ŒåŒ…æ‹¬åŠ¨æ€å­ä»»åŠ¡").
		WithTask(task1).
		WithTask(task2).
		Build()
	if err != nil {
		t.Fatalf("æ„å»ºWorkflowå¤±è´¥: %v", err)
	}

	// æäº¤Workflow
	controller, err := eng.SubmitWorkflow(ctx, wf)
	if err != nil {
		t.Fatalf("æäº¤Workflowå¤±è´¥: %v", err)
	}

	instanceID := controller.GetInstanceID()
	if instanceID == "" {
		t.Fatal("InstanceIDä¸ºç©º")
	}

	// ç­‰å¾…å·¥ä½œæµæ‰§è¡Œå®Œæˆï¼ˆæœ€å¤šç­‰å¾…60ç§’ï¼Œå› ä¸ºéœ€è¦æ‰§è¡Œæ›´å¤šä»»åŠ¡ï¼‰
	timeout := 60 * time.Second
	startTime := time.Now()
	for {
		status, err := controller.GetStatus()
		if err != nil {
			t.Fatalf("è·å–çŠ¶æ€å¤±è´¥: %v", err)
		}

		if status == "Success" || status == "Failed" || status == "Terminated" {
			log.Printf("âœ… [å·¥ä½œæµå®Œæˆ] çŠ¶æ€=%s, è€—æ—¶=%v", status, time.Since(startTime))
			break
		}

		if time.Since(startTime) > timeout {
			t.Fatalf("å·¥ä½œæµæ‰§è¡Œè¶…æ—¶ï¼Œå½“å‰çŠ¶æ€=%s", status)
		}

		time.Sleep(100 * time.Millisecond)
	}

	// éªŒè¯æœ€ç»ˆçŠ¶æ€
	finalStatus, err := controller.GetStatus()
	if err != nil {
		t.Fatalf("è·å–æœ€ç»ˆçŠ¶æ€å¤±è´¥: %v", err)
	}

	if finalStatus != "Success" {
		t.Errorf("æœŸæœ›å·¥ä½œæµçŠ¶æ€ä¸ºSuccessï¼Œå®é™…ä¸º%s", finalStatus)
	}

	// ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œç¡®ä¿æ‰€æœ‰Handleræ‰§è¡Œå®Œæˆ
	time.Sleep(1 * time.Second)

	// éªŒè¯å¹¶æ‰“å°ä¿å­˜çš„æ•°æ®
	savedData := repo.GetSavedData()
	if len(savedData) == 0 {
		t.Fatal("æœªä¿å­˜ä»»ä½•æ•°æ®")
	}

	// ç»Ÿè®¡å„ç±»å‹æ•°æ®æ•°é‡
	dataCountByType := make(map[string]int)
	for _, data := range savedData {
		if dataType, ok := data["type"].(string); ok {
			dataCountByType[dataType]++
		}
	}

	log.Printf("âœ… [æ•°æ®éªŒè¯] å…±ä¿å­˜ %d æ¡æ•°æ®", len(savedData))
	log.Printf("ğŸ“Š [æ•°æ®ç»Ÿè®¡] trade_cal=%d, stock_basic=%d, daily=%d, adj_factor=%d",
		dataCountByType["trade_cal"],
		dataCountByType["stock_basic"],
		dataCountByType["daily"],
		dataCountByType["adj_factor"])

	// éªŒè¯æ•°æ®æ•°é‡æ˜¯å¦ç¬¦åˆé¢„æœŸï¼š20æ¡ï¼ˆ5 trade_cal + 5 stock_basic + 5 daily + 5 adj_factorï¼‰
	expectedCount := ExpectedTotalDataCountWithDynamicTasks

	log.Printf("ğŸ“Š [æ•°é‡éªŒè¯] å½“å‰æ•°æ®: %d æ¡, é¢„æœŸ: %d æ¡ï¼ˆ5 trade_cal + 5 stock_basic + 5 daily + 5 adj_factorï¼‰",
		len(savedData), expectedCount)

	if len(savedData) != expectedCount {
		t.Errorf("æ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=%d, å®é™…=%d", expectedCount, len(savedData))
	} else {
		log.Printf("âœ… [æ•°é‡éªŒè¯] æ•°æ®æ•°é‡ç¬¦åˆé¢„æœŸ: %d æ¡", expectedCount)
	}

	// éªŒè¯å„ç±»å‹æ•°æ®æ•°é‡
	if dataCountByType["trade_cal"] != 5 {
		t.Errorf("trade_calæ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=5, å®é™…=%d", dataCountByType["trade_cal"])
	}
	if dataCountByType["stock_basic"] != 5 {
		t.Errorf("stock_basicæ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=5, å®é™…=%d", dataCountByType["stock_basic"])
	}
	if dataCountByType["daily"] != 5 {
		t.Errorf("dailyæ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=5, å®é™…=%d", dataCountByType["daily"])
	}
	if dataCountByType["adj_factor"] != 5 {
		t.Errorf("adj_factoræ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=5, å®é™…=%d", dataCountByType["adj_factor"])
	}

	// éªŒè¯ä»»åŠ¡å®ä¾‹ï¼šæ³¨æ„å­ä»»åŠ¡ä¸ä¿å­˜åˆ°æ•°æ®åº“ï¼Œæ‰€ä»¥åªèƒ½éªŒè¯é¢„å®šä¹‰ä»»åŠ¡
	ctxVerify := context.Background()
	taskInstances, err := taskRepo.GetByWorkflowInstanceID(ctxVerify, instanceID)
	if err != nil {
		t.Logf("âš ï¸ æ— æ³•æŸ¥è¯¢ä»»åŠ¡å®ä¾‹: %v", err)
	} else {
		// ç»Ÿè®¡ä»»åŠ¡æ•°é‡ï¼ˆåªç»Ÿè®¡é¢„å®šä¹‰ä»»åŠ¡ï¼Œå­ä»»åŠ¡ä¸ä¿å­˜åˆ°æ•°æ®åº“ï¼‰
		taskCount := len(taskInstances)
		expectedTaskCount := 2 // åªæœ‰2ä¸ªçˆ¶ä»»åŠ¡ï¼ˆå­ä»»åŠ¡ä¸ä¿å­˜åˆ°æ•°æ®åº“ï¼‰
		if taskCount != expectedTaskCount {
			t.Errorf("é¢„å®šä¹‰ä»»åŠ¡å®ä¾‹æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=%dï¼ˆ2ä¸ªçˆ¶ä»»åŠ¡ï¼Œå­ä»»åŠ¡ä¸ä¿å­˜åˆ°æ•°æ®åº“ï¼‰, å®é™…=%d", expectedTaskCount, taskCount)
		} else {
			log.Printf("âœ… [ä»»åŠ¡å®ä¾‹éªŒè¯] é¢„å®šä¹‰ä»»åŠ¡æ•°é‡ç¬¦åˆé¢„æœŸ: %d ä¸ªï¼ˆå­ä»»åŠ¡ä¸ä¿å­˜åˆ°æ•°æ®åº“ï¼Œä½†å·²é€šè¿‡æ•°æ®éªŒè¯ï¼‰", taskCount)
		}

		// éªŒè¯æ‰€æœ‰é¢„å®šä¹‰ä»»åŠ¡éƒ½æˆåŠŸå®Œæˆï¼ˆå…¼å®¹å¤§å°å†™ï¼‰
		for _, taskInstance := range taskInstances {
			if taskInstance.Status != "Success" && taskInstance.Status != "SUCCESS" {
				t.Errorf("ä»»åŠ¡ %s çŠ¶æ€ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=Successæˆ–SUCCESS, å®é™…=%s", taskInstance.Name, taskInstance.Status)
			}
		}

		// æ³¨æ„ï¼šå­ä»»åŠ¡ä¸ä¿å­˜åˆ°æ•°æ®åº“ï¼Œæ‰€ä»¥æ— æ³•é€šè¿‡æ•°æ®åº“æŸ¥è¯¢ç»Ÿè®¡å­ä»»åŠ¡æ•°
		// ä½†å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼éªŒè¯å­ä»»åŠ¡æ‰§è¡Œæƒ…å†µï¼š
		// 1. æ‰€æœ‰çˆ¶ä»»åŠ¡éƒ½æˆåŠŸå®Œæˆï¼ˆè¯´æ˜å­ä»»åŠ¡éƒ½æ‰§è¡Œäº†ï¼Œæ ¹æ®SubTaskErrorToleranceåˆ¤æ–­çˆ¶ä»»åŠ¡æ˜¯å¦æˆåŠŸï¼‰
		// 2. WorkflowçŠ¶æ€ä¸ºSuccessï¼ˆè¯´æ˜æ‰€æœ‰ä»»åŠ¡åŒ…æ‹¬å­ä»»åŠ¡éƒ½å®Œæˆäº†ï¼‰
		// 3. æ•°æ®ä¿å­˜æ•°é‡ç¬¦åˆé¢„æœŸï¼ˆ20æ¡æ•°æ®ï¼ŒåŒ…æ‹¬5ä¸ªdailyå’Œ5ä¸ªadj_factorï¼‰
		log.Printf("ğŸ“ æ³¨æ„ï¼šå­ä»»åŠ¡ï¼ˆ%dä¸ªdaily + %dä¸ªadj_factorï¼‰ä¸ä¿å­˜åˆ°æ•°æ®åº“ï¼Œä½†å·²é€šè¿‡çˆ¶ä»»åŠ¡çŠ¶æ€ã€workflowçŠ¶æ€å’Œæ•°æ®æ•°é‡éªŒè¯å…¶æ‰§è¡Œæƒ…å†µ",
			ExpectedDailySubTaskCount, ExpectedAdjFactorSubTaskCount)
	}

	// éªŒè¯å­—æ®µå®Œæ•´æ€§ï¼šæ£€æŸ¥æ‰€æœ‰ä¿å­˜çš„æ•°æ®æ˜¯å¦åŒ…å«å¿…éœ€çš„å­—æ®µ
	log.Printf("ğŸ” [å­—æ®µå®Œæ•´æ€§éªŒè¯] å¼€å§‹éªŒè¯æ‰€æœ‰æ•°æ®çš„å­—æ®µå®Œæ•´æ€§...")
	dailyIndex := 0
	adjFactorIndex := 0
	tradeCalIndex := 0
	stockBasicIndex := 0
	for i, data := range savedData {
		if dataType, ok := data["type"].(string); ok {
			switch dataType {
			case "daily":
				validateDailyDataFields(t, data, dailyIndex)
				dailyIndex++
			case "adj_factor":
				validateAdjFactorDataFields(t, data, adjFactorIndex)
				adjFactorIndex++
			case "trade_cal":
				validateTradeCalDataFields(t, data, tradeCalIndex)
				tradeCalIndex++
			case "stock_basic":
				validateStockBasicDataFields(t, data, stockBasicIndex)
				stockBasicIndex++
			default:
				t.Logf("âš ï¸ æœªçŸ¥æ•°æ®ç±»å‹: %s (æ•°æ®ç´¢å¼•: %d)", dataType, i)
			}
		}
	}
	log.Printf("âœ… [å­—æ®µå®Œæ•´æ€§éªŒè¯] å®Œæˆï¼ŒéªŒè¯äº† %d æ¡ daily æ•°æ®ï¼Œ%d æ¡ adj_factor æ•°æ®ï¼Œ%d æ¡ trade_cal æ•°æ®ï¼Œ%d æ¡ stock_basic æ•°æ®",
		dailyIndex, adjFactorIndex, tradeCalIndex, stockBasicIndex)

	// æ‰“å°æ‰€æœ‰ä¿å­˜çš„æ•°æ®
	separator := strings.Repeat("=", 80)
	log.Printf("\n%s", separator)
	log.Printf("ğŸ“Š [æœ€ç»ˆä¿å­˜çš„æ•°æ®] (é¢„æœŸ: %d æ¡, å®é™…: %d æ¡)", expectedCount, len(savedData))
	log.Printf("%s", separator)
	for i, data := range savedData {
		log.Printf("\n[æ•°æ® %d/%d]", i+1, len(savedData))
		if dataType, ok := data["type"].(string); ok {
			log.Printf("  ç±»å‹: %s", dataType)
		}
		// å®Œæ•´æ‰“å°æ‰€æœ‰å­—æ®µ
		for k, v := range data {
			if k != "type" {
				log.Printf("  %s: %v", k, v)
			}
		}
	}
	log.Printf("%s\n", separator)
}

// TestTushareWorkflow_DynamicParameters æµ‹è¯•åŠ¨æ€å‚æ•°ç‰¹æ€§ï¼ˆResultMappingå’ŒRequiredParamsï¼‰
// å±•ç¤ºå¦‚ä½•ä½¿ç”¨ResultMappingä»ä¸Šæ¸¸ä»»åŠ¡ç»“æœä¸­è‡ªåŠ¨æ˜ å°„å‚æ•°ï¼Œä»¥åŠä½¿ç”¨RequiredParamså£°æ˜å¿…éœ€å‚æ•°
func TestTushareWorkflow_DynamicParameters(t *testing.T) {
	eng, registry, repo, taskRepo, cleanup := setupTushareTest(t)
	defer cleanup()

	ctx := context.Background()

	// åˆ›å»ºä¸€ä¸ªè¿”å›mapæ ¼å¼ç»“æœçš„å‡½æ•°ï¼Œä»¥ä¾¿ResultMappingèƒ½å¤Ÿå·¥ä½œ
	queryTushareMap := func(ctx *task.TaskContext) (interface{}, error) {
		apiName := ctx.GetParamString("api_name")
		log.Printf("ğŸ“¡ [QueryTushareMap] API=%s, å¼€å§‹æŸ¥è¯¢...", apiName)

		time.Sleep(50 * time.Millisecond)

		switch apiName {
		case "stock_basic":
			// è¿”å›mapæ ¼å¼ï¼Œä¾¿äºResultMappingä½¿ç”¨
			result := map[string]interface{}{
				"ts_codes":     []string{"000001.SZ", "000002.SZ"},
				"symbols":      []string{"000001", "000002"},
				"names":        []string{"å¹³å®‰é“¶è¡Œ", "ä¸‡ç§‘A"},
				"default_code": "000001.SZ", // é»˜è®¤è‚¡ç¥¨ä»£ç ï¼Œç”¨äºæ¼”ç¤ºResultMapping
			}
			log.Printf("âœ… [QueryTushareMap] stock_basic æŸ¥è¯¢æˆåŠŸï¼Œè¿”å› %d åªè‚¡ç¥¨", len(result["ts_codes"].([]string)))
			return result, nil
		case "adj_factor":
			// ä»å‚æ•°ä¸­è·å–ts_codeï¼ˆå¯èƒ½é€šè¿‡ResultMappingè‡ªåŠ¨æ³¨å…¥ï¼‰
			tsCode := ctx.GetParamString("ts_code")
			if tsCode == "" {
				tsCode = "000001.SZ" // é»˜è®¤å€¼
			}
			// è¿”å›mapæ ¼å¼ï¼Œä¾¿äºåç»­ä»»åŠ¡ä½¿ç”¨ResultMapping
			result := map[string]interface{}{
				"ts_code":    tsCode,
				"trade_date": "20251201",
				"adj_factor": 1.0,
			}
			log.Printf("âœ… [QueryTushareMap] adj_factor æŸ¥è¯¢æˆåŠŸï¼Œts_code=%s (é€šè¿‡ResultMappingè·å–)", tsCode)
			return result, nil
		default:
			return nil, fmt.Errorf("æœªçŸ¥çš„APIåç§°: %s", apiName)
		}
	}

	// æ³¨å†Œæ–°çš„å‡½æ•°
	_, err := registry.Register(ctx, "QueryTushareMap", queryTushareMap, "æ¨¡æ‹ŸTushare APIæŸ¥è¯¢ï¼ˆè¿”å›mapæ ¼å¼ï¼‰")
	if err != nil {
		t.Fatalf("æ³¨å†ŒQueryTushareMapå¤±è´¥: %v", err)
	}

	// åˆ›å»ºçˆ¶ä»»åŠ¡ï¼šè·å–è‚¡ç¥¨åˆ—è¡¨ï¼ˆè¿”å›mapæ ¼å¼ï¼‰
	parentTask, err := builder.NewTaskBuilder("è·å–è‚¡ç¥¨åˆ—è¡¨_Map", "è·å–Tushareè‚¡ç¥¨åˆ—è¡¨æ•°æ®ï¼ˆmapæ ¼å¼ï¼‰", registry).
		WithJobFunction("QueryTushareMap", map[string]interface{}{
			"api_name": "stock_basic",
		}).
		WithTaskHandler(task.TaskStatusSuccess, "SaveResult").
		WithTaskHandler(task.TaskStatusFailed, "LogError").
		Build()
	if err != nil {
		t.Fatalf("æ„å»ºçˆ¶ä»»åŠ¡å¤±è´¥: %v", err)
	}

	// åˆ›å»ºå­ä»»åŠ¡ï¼šä½¿ç”¨ResultMappingä»çˆ¶ä»»åŠ¡ç»“æœä¸­è‡ªåŠ¨è·å–ts_code
	// å±•ç¤ºåŠ¨æ€å‚æ•°ç‰¹æ€§ï¼šä¸éœ€è¦æ‰‹åŠ¨ä¼ é€’ts_codeï¼Œå¼•æ“ä¼šè‡ªåŠ¨ä»çˆ¶ä»»åŠ¡ç»“æœä¸­æ˜ å°„
	// æ³¨æ„ï¼šResultMappingé€šè¿‡injectCachedResultså·¥ä½œï¼Œå®ƒä½¿ç”¨ç¼“å­˜è·å–ä¸Šæ¸¸ä»»åŠ¡ç»“æœ
	// å› æ­¤éœ€è¦ç¡®ä¿çˆ¶ä»»åŠ¡å…ˆå®Œæˆå¹¶ç¼“å­˜ç»“æœï¼Œå­ä»»åŠ¡æ‰èƒ½é€šè¿‡ResultMappingè·å–å‚æ•°
	subTask, err := builder.NewTaskBuilder("è·å–å¤æƒå› å­_åŠ¨æ€å‚æ•°", "ä½¿ç”¨ResultMappingåŠ¨æ€è·å–å‚æ•°", registry).
		WithJobFunction("QueryTushareMap", map[string]interface{}{
			"api_name": "adj_factor",
			// ts_codeå°†é€šè¿‡ResultMappingä»çˆ¶ä»»åŠ¡ç»“æœä¸­è‡ªåŠ¨è·å–ï¼Œä¸éœ€è¦åœ¨è¿™é‡Œè®¾ç½®
		}).
		WithDependency("è·å–è‚¡ç¥¨åˆ—è¡¨_Map").
		// ä½¿ç”¨ResultMappingï¼šä»çˆ¶ä»»åŠ¡ç»“æœçš„"default_code"å­—æ®µæ˜ å°„åˆ°å½“å‰ä»»åŠ¡çš„"ts_code"å‚æ•°
		// æ³¨æ„ï¼šResultMappingçš„æ ¼å¼æ˜¯ map[targetParam]sourceField
		// å³ï¼šå½“å‰ä»»åŠ¡çš„å‚æ•°å -> ä¸Šæ¸¸ä»»åŠ¡ç»“æœä¸­çš„å­—æ®µå
		// ResultMappingé€šè¿‡injectCachedResultså·¥ä½œï¼Œå®ƒä¼šåœ¨ä»»åŠ¡æäº¤å‰ä»ç¼“å­˜ä¸­è·å–ä¸Šæ¸¸ç»“æœå¹¶æ³¨å…¥å‚æ•°
		WithResultMapping(map[string]string{
			"ts_code": "default_code", // å°†ä¸Šæ¸¸ç»“æœçš„default_codeå­—æ®µæ˜ å°„åˆ°å½“å‰ä»»åŠ¡çš„ts_codeå‚æ•°
		}).
		// æ³¨æ„ï¼šä¸ä½¿ç”¨RequiredParamsï¼Œå› ä¸ºRequiredParamsä¼šåœ¨validateAndMapParamsä¸­æ£€æŸ¥
		// è€ŒvalidateAndMapParamsåœ¨ä»»åŠ¡æäº¤å‰æ‰§è¡Œï¼Œæ­¤æ—¶çˆ¶ä»»åŠ¡å¯èƒ½è¿˜æ²¡å®Œæˆï¼ŒResultMappingå¯èƒ½è¿˜æ²¡æ‰§è¡Œ
		// ResultMappingé€šè¿‡injectCachedResultsåœ¨ä»»åŠ¡æäº¤å‰æ‰§è¡Œï¼Œå®ƒä¼šå°†å‚æ•°æ³¨å…¥åˆ°ä»»åŠ¡çš„Paramsä¸­
		WithTaskHandler(task.TaskStatusSuccess, "SaveResult").
		WithTaskHandler(task.TaskStatusFailed, "LogError").
		Build()
	if err != nil {
		t.Fatalf("æ„å»ºå­ä»»åŠ¡å¤±è´¥: %v", err)
	}

	// åˆ›å»ºWorkflow
	wf, err := builder.NewWorkflowBuilder("TushareåŠ¨æ€å‚æ•°æµ‹è¯•", "æµ‹è¯•ResultMappingå’ŒRequiredParamsç‰¹æ€§").
		WithTask(parentTask).
		WithTask(subTask).
		Build()
	if err != nil {
		t.Fatalf("æ„å»ºWorkflowå¤±è´¥: %v", err)
	}

	// æäº¤Workflow
	controller, err := eng.SubmitWorkflow(ctx, wf)
	if err != nil {
		t.Fatalf("æäº¤Workflowå¤±è´¥: %v", err)
	}

	instanceID := controller.GetInstanceID()

	// ç­‰å¾…å·¥ä½œæµæ‰§è¡Œå®Œæˆ
	timeout := 30 * time.Second
	startTime := time.Now()
	for {
		status, err := controller.GetStatus()
		if err != nil {
			t.Fatalf("è·å–çŠ¶æ€å¤±è´¥: %v", err)
		}

		if status == "Success" || status == "Failed" || status == "Terminated" {
			log.Printf("âœ… [å·¥ä½œæµå®Œæˆ] çŠ¶æ€=%s, è€—æ—¶=%v", status, time.Since(startTime))
			break
		}

		if time.Since(startTime) > timeout {
			t.Fatalf("å·¥ä½œæµæ‰§è¡Œè¶…æ—¶ï¼Œå½“å‰çŠ¶æ€=%s", status)
		}

		time.Sleep(100 * time.Millisecond)
	}

	// éªŒè¯æœ€ç»ˆçŠ¶æ€
	finalStatus, err := controller.GetStatus()
	if err != nil {
		t.Fatalf("è·å–æœ€ç»ˆçŠ¶æ€å¤±è´¥: %v", err)
	}

	if finalStatus != "Success" {
		t.Errorf("æœŸæœ›å·¥ä½œæµçŠ¶æ€ä¸ºSuccessï¼Œå®é™…ä¸º%s", finalStatus)
	}

	// ç­‰å¾…Handleræ‰§è¡Œå®Œæˆ
	time.Sleep(500 * time.Millisecond)

	// éªŒè¯ä»»åŠ¡å®ä¾‹
	ctxVerify := context.Background()
	taskInstances, err := taskRepo.GetByWorkflowInstanceID(ctxVerify, instanceID)
	if err != nil {
		t.Fatalf("æŸ¥è¯¢ä»»åŠ¡å®ä¾‹å¤±è´¥: %v", err)
	}

	// éªŒè¯ä»»åŠ¡æ•°é‡
	if len(taskInstances) != 2 {
		t.Errorf("æœŸæœ›ä»»åŠ¡æ•°: 2, å®é™…: %d", len(taskInstances))
	}

	// éªŒè¯æ‰€æœ‰ä»»åŠ¡éƒ½æˆåŠŸå®Œæˆ
	for _, taskInstance := range taskInstances {
		if taskInstance.Status != "Success" && taskInstance.Status != "SUCCESS" {
			t.Errorf("ä»»åŠ¡ %s çŠ¶æ€ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=Successæˆ–SUCCESS, å®é™…=%s", taskInstance.Name, taskInstance.Status)
		}
	}

	// éªŒè¯ä¿å­˜çš„æ•°æ®
	savedData := repo.GetSavedData()
	if len(savedData) == 0 {
		t.Error("æœªä¿å­˜ä»»ä½•æ•°æ®")
	}

	log.Printf("âœ… [åŠ¨æ€å‚æ•°æµ‹è¯•] æµ‹è¯•å®Œæˆï¼Œå±•ç¤ºäº†ResultMappingç‰¹æ€§çš„ä½¿ç”¨")
	log.Printf("   1. çˆ¶ä»»åŠ¡è¿”å›mapæ ¼å¼ç»“æœï¼ŒåŒ…å«default_codeå­—æ®µ")
	log.Printf("   2. å­ä»»åŠ¡ä½¿ç”¨ResultMappingä»çˆ¶ä»»åŠ¡ç»“æœä¸­è‡ªåŠ¨æ˜ å°„ts_codeå‚æ•°")
	log.Printf("   3. å¼•æ“é€šè¿‡injectCachedResultsè‡ªåŠ¨ä»ç¼“å­˜ä¸­è·å–ä¸Šæ¸¸ç»“æœå¹¶æ³¨å…¥å‚æ•°")
	log.Printf("   4. å­ä»»åŠ¡æˆåŠŸæ‰§è¡Œï¼Œä½¿ç”¨äº†é€šè¿‡ResultMappingè·å–çš„ts_codeå‚æ•°")
	log.Printf("   è¯´æ˜ï¼šResultMappingç‰¹æ€§å…è®¸ä»»åŠ¡è‡ªåŠ¨ä»ä¸Šæ¸¸ä»»åŠ¡ç»“æœä¸­è·å–å‚æ•°ï¼Œæ— éœ€æ‰‹åŠ¨ä¼ é€’")
}

// TestTushareWorkflow_FromYAML æµ‹è¯•ä»YAMLæ–‡ä»¶åŠ è½½workflowå¹¶æ‰§è¡Œ
// å±•ç¤ºå¦‚ä½•ä½¿ç”¨YAMLé…ç½®æ–‡ä»¶å®šä¹‰workflowï¼Œè€Œä¸æ˜¯é€šè¿‡ä»£ç æ„å»º
func TestTushareWorkflow_FromYAML(t *testing.T) {
	eng, _, repo, taskRepo, cleanup := setupTushareTest(t)
	defer cleanup()

	ctx := context.Background()

	// åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºå­˜æ”¾YAMLé…ç½®æ–‡ä»¶
	tmpDir := t.TempDir()
	workflowConfigPath := filepath.Join(tmpDir, "tushare-workflow.yaml")

	// åˆ›å»ºYAMLé…ç½®æ–‡ä»¶ï¼Œå®šä¹‰tushareæ•°æ®ä¸‹è½½workflow
	// æ³¨æ„ï¼šYAMLä¸­çš„task_idå¯¹åº”Taskåç§°ï¼Œdependenciesä½¿ç”¨task_idå¼•ç”¨
	workflowYAML := `
workflows:
  # Jobå®šä¹‰ï¼šå®šä¹‰å¯å¤ç”¨çš„Jobå‡½æ•°
  jobs:
    - job_id: "query-tushare-job"
      func_key: "QueryTushare"
      description: "æŸ¥è¯¢Tushare API"
      timeout: "60s"

  # Workflowå®šä¹‰
  definitions:
    - workflow_id: "tushare-data-download"
      description: "ä»YAMLé…ç½®åŠ è½½çš„Tushareæ•°æ®ä¸‹è½½å·¥ä½œæµï¼ˆåŒ…å«4ä¸ªä»»åŠ¡ï¼‰"
      tasks:
        # ä»»åŠ¡1ï¼šè·å–äº¤æ˜“æ—¥å†ï¼ˆå®Œæˆåä¼šè§¦å‘GenerateSubTasksä¸º"è·å–æ—¥çº¿æ•°æ®"ç”Ÿæˆå­ä»»åŠ¡ï¼‰
        - task_id: "è·å–äº¤æ˜“æ—¥å†"
          job_id: "query-tushare-job"
          params:
            api_name: "trade_cal"
          dependencies: []
          callbacks:
            - state: "success"
              func_key: "SaveResultAndGenerateSubTasks"
              description: "ä¿å­˜äº¤æ˜“æ—¥å†æ•°æ®å¹¶ç”Ÿæˆæ—¥çº¿å­ä»»åŠ¡"
            - state: "failed"
              func_key: "LogError"
              description: "è®°å½•é”™è¯¯"

        # ä»»åŠ¡2ï¼šè·å–è‚¡ç¥¨åˆ—è¡¨ï¼ˆå®Œæˆåä¼šè§¦å‘GenerateSubTasksä¸º"è·å–å¤æƒå› å­"ç”Ÿæˆå­ä»»åŠ¡ï¼‰
        - task_id: "è·å–è‚¡ç¥¨åˆ—è¡¨"
          job_id: "query-tushare-job"
          params:
            api_name: "stock_basic"
          dependencies: []
          callbacks:
            - state: "success"
              func_key: "SaveResultAndGenerateSubTasks"
              description: "ä¿å­˜è‚¡ç¥¨åˆ—è¡¨æ•°æ®å¹¶ç”Ÿæˆå¤æƒå› å­å­ä»»åŠ¡"
            - state: "failed"
              func_key: "LogError"
              description: "è®°å½•é”™è¯¯"

        # ä»»åŠ¡3ï¼šè·å–æ—¥çº¿æ•°æ®ï¼ˆåœ¨YAMLä¸­å®šä¹‰ï¼Œä½œä¸ºæ¨¡æ¿ä»»åŠ¡ï¼‰
        # æ³¨æ„ï¼šè¿™ä¸ªä»»åŠ¡åœ¨YAMLä¸­å®šä¹‰ï¼Œä½¿ç”¨is_templateæ ‡è®°ï¼Œä¸ä¼šç›´æ¥æ‰§è¡Œ
        # å®é™…æ‰§è¡Œæ—¶é€šè¿‡GenerateSubTasksä¸ºæ¯ä¸ªäº¤æ˜“æ—¥ç”Ÿæˆå­ä»»åŠ¡å®ä¾‹
        # å­ä»»åŠ¡ä¼šä½¿ç”¨è¿™ä¸ªä»»åŠ¡çš„é…ç½®ï¼ˆjob_idã€callbacksç­‰ï¼‰ä½œä¸ºæ¨¡æ¿
        - task_id: "è·å–æ—¥çº¿æ•°æ®"
          job_id: "query-tushare-job"
          params:
            api_name: "daily"
            # trade_dateå’Œts_codeå°†é€šè¿‡GenerateSubTasksåœ¨è¿è¡Œæ—¶åŠ¨æ€è®¾ç½®åˆ°å­ä»»åŠ¡ä¸­
          dependencies:
            - "è·å–äº¤æ˜“æ—¥å†"  # è®¾ç½®ä¾èµ–ï¼Œä½†å› ä¸ºæ˜¯æ¨¡æ¿ä»»åŠ¡ï¼Œä¸ä¼šæ‰§è¡Œ
          is_template: true  # æ ‡è®°ä¸ºæ¨¡æ¿ä»»åŠ¡ï¼Œä¸ä¼šæ‰§è¡Œ
          callbacks:
            - state: "success"
              func_key: "SaveResult"
              description: "ä¿å­˜æ—¥çº¿æ•°æ®"
            - state: "failed"
              func_key: "LogError"
              description: "è®°å½•é”™è¯¯"

        # ä»»åŠ¡4ï¼šè·å–å¤æƒå› å­ï¼ˆåœ¨YAMLä¸­å®šä¹‰ï¼Œä½œä¸ºæ¨¡æ¿ä»»åŠ¡ï¼‰
        # æ³¨æ„ï¼šè¿™ä¸ªä»»åŠ¡åœ¨YAMLä¸­å®šä¹‰ï¼Œä½¿ç”¨is_templateæ ‡è®°ï¼Œä¸ä¼šç›´æ¥æ‰§è¡Œ
        # å®é™…æ‰§è¡Œæ—¶é€šè¿‡GenerateSubTasksä¸ºæ¯åªè‚¡ç¥¨ç”Ÿæˆå­ä»»åŠ¡å®ä¾‹
        # å­ä»»åŠ¡ä¼šä½¿ç”¨è¿™ä¸ªä»»åŠ¡çš„é…ç½®ï¼ˆjob_idã€callbacksç­‰ï¼‰ä½œä¸ºæ¨¡æ¿
        - task_id: "è·å–å¤æƒå› å­"
          job_id: "query-tushare-job"
          params:
            api_name: "adj_factor"
            # ts_codeå°†é€šè¿‡GenerateSubTasksåœ¨è¿è¡Œæ—¶åŠ¨æ€è®¾ç½®åˆ°å­ä»»åŠ¡ä¸­
          dependencies:
            - "è·å–è‚¡ç¥¨åˆ—è¡¨"  # è®¾ç½®ä¾èµ–ï¼Œä½†å› ä¸ºæ˜¯æ¨¡æ¿ä»»åŠ¡ï¼Œä¸ä¼šæ‰§è¡Œ
          is_template: true  # æ ‡è®°ä¸ºæ¨¡æ¿ä»»åŠ¡ï¼Œä¸ä¼šæ‰§è¡Œ
          callbacks:
            - state: "success"
              func_key: "SaveResult"
              description: "ä¿å­˜å¤æƒå› å­æ•°æ®"
            - state: "failed"
              func_key: "LogError"
              description: "è®°å½•é”™è¯¯"
`

	// å†™å…¥YAMLæ–‡ä»¶
	if err := os.WriteFile(workflowConfigPath, []byte(workflowYAML), 0644); err != nil {
		t.Fatalf("åˆ›å»ºYAMLé…ç½®æ–‡ä»¶å¤±è´¥: %v", err)
	}

	// ä»YAMLæ–‡ä»¶åŠ è½½workflow
	wfDef, err := eng.LoadWorkflow(workflowConfigPath)
	if err != nil {
		t.Fatalf("ä»YAMLåŠ è½½workflowå¤±è´¥: %v", err)
	}

	if wfDef == nil {
		t.Fatal("WorkflowDefinitionä¸ºç©º")
	}

	if wfDef.ID != "tushare-data-download" {
		t.Errorf("æœŸæœ›WorkflowIDä¸ºtushare-data-downloadï¼Œå®é™…ä¸º%s", wfDef.ID)
	}

	if wfDef.Workflow == nil {
		t.Fatal("Workflowå¯¹è±¡ä¸ºç©º")
	}

	log.Printf("âœ… [YAMLåŠ è½½] æˆåŠŸä»YAMLæ–‡ä»¶åŠ è½½workflow: %s", wfDef.ID)

	// æäº¤workflowå¹¶æ‰§è¡Œ
	controller, err := eng.SubmitWorkflow(ctx, wfDef.Workflow)
	if err != nil {
		t.Fatalf("æäº¤workflowå¤±è´¥: %v", err)
	}

	instanceID := controller.GetInstanceID()
	if instanceID == "" {
		t.Fatal("InstanceIDä¸ºç©º")
	}

	log.Printf("âœ… [YAMLæµ‹è¯•] Workflowå·²æäº¤ï¼ŒInstanceID: %s", instanceID)

	// ç­‰å¾…å·¥ä½œæµæ‰§è¡Œå®Œæˆ
	timeout := 30 * time.Second
	startTime := time.Now()
	for {
		status, err := controller.GetStatus()
		if err != nil {
			t.Fatalf("è·å–çŠ¶æ€å¤±è´¥: %v", err)
		}

		if status == "Success" || status == "Failed" || status == "Terminated" {
			log.Printf("âœ… [å·¥ä½œæµå®Œæˆ] çŠ¶æ€=%s, è€—æ—¶=%v", status, time.Since(startTime))
			break
		}

		if time.Since(startTime) > timeout {
			t.Fatalf("å·¥ä½œæµæ‰§è¡Œè¶…æ—¶ï¼Œå½“å‰çŠ¶æ€=%s", status)
		}

		time.Sleep(100 * time.Millisecond)
	}

	// éªŒè¯æœ€ç»ˆçŠ¶æ€
	finalStatus, err := controller.GetStatus()
	if err != nil {
		t.Fatalf("è·å–æœ€ç»ˆçŠ¶æ€å¤±è´¥: %v", err)
	}

	if finalStatus != "Success" {
		t.Errorf("æœŸæœ›å·¥ä½œæµçŠ¶æ€ä¸ºSuccessï¼Œå®é™…ä¸º%s", finalStatus)
	}

	// ç­‰å¾…Handleræ‰§è¡Œå®Œæˆ
	time.Sleep(500 * time.Millisecond)

	// éªŒè¯ä»»åŠ¡å®ä¾‹
	ctxVerify := context.Background()
	taskInstances, err := taskRepo.GetByWorkflowInstanceID(ctxVerify, instanceID)
	if err != nil {
		t.Fatalf("æŸ¥è¯¢ä»»åŠ¡å®ä¾‹å¤±è´¥: %v", err)
	}

	// éªŒè¯ä»»åŠ¡æ•°é‡ï¼ˆæ³¨æ„ï¼šå­ä»»åŠ¡ä¸ä¿å­˜åˆ°æ•°æ®åº“ï¼‰
	// YAMLä¸­å®šä¹‰äº†4ä¸ªä»»åŠ¡ï¼šè·å–äº¤æ˜“æ—¥å†ã€è·å–è‚¡ç¥¨åˆ—è¡¨ã€è·å–æ—¥çº¿æ•°æ®ã€è·å–å¤æƒå› å­
	// ä½†"è·å–æ—¥çº¿æ•°æ®"å’Œ"è·å–å¤æƒå› å­"æ˜¯æ¨¡æ¿ä»»åŠ¡ï¼Œæ²¡æœ‰ä¾èµ–å…³ç³»ï¼Œä¸ä¼šè‡ªåŠ¨æ‰§è¡Œ
	// æ‰€ä»¥é¢„å®šä¹‰ä»»åŠ¡æ•°åº”è¯¥æ˜¯4ä¸ªï¼ˆåŒ…æ‹¬æ¨¡æ¿ä»»åŠ¡ï¼‰ï¼Œä½†å®é™…æ‰§è¡Œæ—¶åªæœ‰2ä¸ªçˆ¶ä»»åŠ¡ä¼šæ‰§è¡Œ
	expectedTaskCount := 4 // 4ä¸ªé¢„å®šä¹‰ä»»åŠ¡ï¼ˆåŒ…æ‹¬æ¨¡æ¿ä»»åŠ¡ï¼‰ï¼Œå­ä»»åŠ¡ä¸ä¿å­˜åˆ°æ•°æ®åº“
	if len(taskInstances) != expectedTaskCount {
		t.Logf("âš ï¸ é¢„å®šä¹‰ä»»åŠ¡æ•°: %d, å®é™…: %dï¼ˆåŒ…æ‹¬æ¨¡æ¿ä»»åŠ¡ï¼Œå­ä»»åŠ¡ä¸ä¿å­˜åˆ°æ•°æ®åº“ï¼‰", expectedTaskCount, len(taskInstances))
		// ä¸å¤±è´¥ï¼Œå› ä¸ºæ¨¡æ¿ä»»åŠ¡å¯èƒ½ä¹Ÿä¼šè¢«ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆå³ä½¿ä¸æ‰§è¡Œï¼‰
	}

	// éªŒè¯æ‰€æœ‰ä»»åŠ¡éƒ½æˆåŠŸå®Œæˆï¼ˆæ¨¡æ¿ä»»åŠ¡ä¼šè¢«æ ‡è®°ä¸ºSuccessä½†ä¸æ‰§è¡Œï¼‰
	for _, taskInstance := range taskInstances {
		// æ£€æŸ¥æ˜¯å¦ä¸ºæ¨¡æ¿ä»»åŠ¡ï¼ˆé€šè¿‡ä»»åŠ¡åç§°åˆ¤æ–­ï¼‰
		if taskInstance.Name == "è·å–æ—¥çº¿æ•°æ®" || taskInstance.Name == "è·å–å¤æƒå› å­" {
			// æ¨¡æ¿ä»»åŠ¡åº”è¯¥è¢«æ ‡è®°ä¸ºSuccessï¼ˆè™½ç„¶ä¸æ‰§è¡Œï¼‰
			if taskInstance.Status != "Success" && taskInstance.Status != "SUCCESS" && taskInstance.Status != "PENDING" {
				t.Logf("âš ï¸ æ¨¡æ¿ä»»åŠ¡ %s çŠ¶æ€: %sï¼ˆæ¨¡æ¿ä»»åŠ¡å¯èƒ½ä¿æŒPENDINGçŠ¶æ€ï¼‰", taskInstance.Name, taskInstance.Status)
			} else {
				log.Printf("âœ… æ¨¡æ¿ä»»åŠ¡ %s çŠ¶æ€: %sï¼ˆæ¨¡æ¿ä»»åŠ¡ä¸æ‰§è¡Œï¼Œä»…ç”¨äºç”Ÿæˆå­ä»»åŠ¡ï¼‰", taskInstance.Name, taskInstance.Status)
			}
		} else {
			// éæ¨¡æ¿ä»»åŠ¡å¿…é¡»æˆåŠŸå®Œæˆ
			if taskInstance.Status != "Success" && taskInstance.Status != "SUCCESS" {
				t.Errorf("ä»»åŠ¡ %s çŠ¶æ€ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=Successæˆ–SUCCESS, å®é™…=%s", taskInstance.Name, taskInstance.Status)
			}
		}
	}

	// éªŒè¯ä¿å­˜çš„æ•°æ®
	savedData := repo.GetSavedData()
	if len(savedData) == 0 {
		t.Error("æœªä¿å­˜ä»»ä½•æ•°æ®")
	}

	// ç»Ÿè®¡å„ç±»å‹æ•°æ®æ•°é‡
	dataCountByType := make(map[string]int)
	for _, data := range savedData {
		if dataType, ok := data["type"].(string); ok {
			dataCountByType[dataType]++
		}
	}

	log.Printf("âœ… [YAMLæµ‹è¯•] æ•°æ®éªŒè¯å®Œæˆ")
	log.Printf("   - å…±ä¿å­˜ %d æ¡æ•°æ®", len(savedData))
	log.Printf("   - trade_cal: %d æ¡", dataCountByType["trade_cal"])
	log.Printf("   - stock_basic: %d æ¡", dataCountByType["stock_basic"])
	log.Printf("   - daily: %d æ¡", dataCountByType["daily"])
	log.Printf("   - adj_factor: %d æ¡", dataCountByType["adj_factor"])

	// éªŒè¯æ•°æ®æ•°é‡
	// æ³¨æ„ï¼šYAMLä¸­å®šä¹‰çš„"è·å–æ—¥çº¿æ•°æ®"å’Œ"è·å–å¤æƒå› å­"æ¨¡æ¿ä»»åŠ¡å¯èƒ½ä¹Ÿä¼šæ‰§è¡Œï¼ˆå› ä¸ºæ²¡æœ‰ä¾èµ–ï¼Œä½œä¸ºæ ¹ä»»åŠ¡æ‰§è¡Œï¼‰
	// æ‰€ä»¥å®é™…æ•°æ®å¯èƒ½æ˜¯ï¼š5 trade_cal + 5 stock_basic + 5 dailyå­ä»»åŠ¡ + 1 dailyæ¨¡æ¿ä»»åŠ¡ + 5 adj_factorå­ä»»åŠ¡ + 1 adj_factoræ¨¡æ¿ä»»åŠ¡ = 22æ¡
	// æˆ–è€…ï¼š5 trade_cal + 5 stock_basic + 5 dailyå­ä»»åŠ¡ + 5 adj_factorå­ä»»åŠ¡ = 20æ¡ï¼ˆå¦‚æœæ¨¡æ¿ä»»åŠ¡ä¸æ‰§è¡Œï¼‰
	// æˆ‘ä»¬æ¥å—ä¸¤ç§æƒ…å†µï¼š20æ¡ï¼ˆç†æƒ³æƒ…å†µï¼‰æˆ–22æ¡ï¼ˆå¦‚æœæ¨¡æ¿ä»»åŠ¡ä¹Ÿæ‰§è¡Œäº†ï¼‰
	expectedDataCountMin := ExpectedTotalDataCountWithDynamicTasks // 20æ¡ï¼ˆç†æƒ³æƒ…å†µï¼‰
	expectedDataCountMax := expectedDataCountMin + 2               // 22æ¡ï¼ˆå¦‚æœæ¨¡æ¿ä»»åŠ¡ä¹Ÿæ‰§è¡Œäº†ï¼‰
	if len(savedData) < expectedDataCountMin || len(savedData) > expectedDataCountMax {
		t.Errorf("æ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›èŒƒå›´=[%d, %d], å®é™…=%d", expectedDataCountMin, expectedDataCountMax, len(savedData))
	}

	// éªŒè¯å„ç±»å‹æ•°æ®æ•°é‡
	if dataCountByType["trade_cal"] != 5 {
		t.Errorf("trade_calæ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=5, å®é™…=%d", dataCountByType["trade_cal"])
	}
	if dataCountByType["stock_basic"] != 5 {
		t.Errorf("stock_basicæ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=5, å®é™…=%d", dataCountByType["stock_basic"])
	}
	// dailyæ•°æ®ï¼šåº”è¯¥æ˜¯5ä¸ªï¼ˆæ¥è‡ªå­ä»»åŠ¡ï¼‰ï¼Œä½†å¦‚æœæ¨¡æ¿ä»»åŠ¡ä¹Ÿæ‰§è¡Œäº†ï¼Œå¯èƒ½æ˜¯6ä¸ª
	if dataCountByType["daily"] < ExpectedDailySubTaskCount || dataCountByType["daily"] > ExpectedDailySubTaskCount+1 {
		t.Logf("âš ï¸ dailyæ•°æ®æ•°é‡: æœŸæœ›èŒƒå›´=[%d, %d]ï¼ˆåŠ¨æ€ç”Ÿæˆçš„å­ä»»åŠ¡ï¼Œå¯èƒ½åŒ…æ‹¬æ¨¡æ¿ä»»åŠ¡ï¼‰, å®é™…=%d", ExpectedDailySubTaskCount, ExpectedDailySubTaskCount+1, dataCountByType["daily"])
	}
	// adj_factoræ•°æ®ï¼šåº”è¯¥æ˜¯5ä¸ªï¼ˆæ¥è‡ªå­ä»»åŠ¡ï¼‰ï¼Œä½†å¦‚æœæ¨¡æ¿ä»»åŠ¡ä¹Ÿæ‰§è¡Œäº†ï¼Œå¯èƒ½æ˜¯6ä¸ª
	if dataCountByType["adj_factor"] < ExpectedAdjFactorSubTaskCount || dataCountByType["adj_factor"] > ExpectedAdjFactorSubTaskCount+1 {
		t.Logf("âš ï¸ adj_factoræ•°æ®æ•°é‡: æœŸæœ›èŒƒå›´=[%d, %d]ï¼ˆåŠ¨æ€ç”Ÿæˆçš„å­ä»»åŠ¡ï¼Œå¯èƒ½åŒ…æ‹¬æ¨¡æ¿ä»»åŠ¡ï¼‰, å®é™…=%d", ExpectedAdjFactorSubTaskCount, ExpectedAdjFactorSubTaskCount+1, dataCountByType["adj_factor"])
	}

	log.Printf("âœ… [YAMLæµ‹è¯•] æµ‹è¯•å®Œæˆï¼Œå±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨YAMLé…ç½®æ–‡ä»¶å®šä¹‰workflow")
	log.Printf("   1. ä½¿ç”¨YAMLæ–‡ä»¶å®šä¹‰workflowç»“æ„ï¼ˆjobså’Œtasksï¼‰")
	log.Printf("   2. é€šè¿‡LoadWorkflowä»YAMLæ–‡ä»¶åŠ è½½workflow")
	log.Printf("   3. æäº¤å¹¶æ‰§è¡Œworkflowï¼ŒéªŒè¯åŠŸèƒ½æ­£å¸¸")
	log.Printf("   è¯´æ˜ï¼šYAMLé…ç½®æ–¹å¼æ›´é€‚åˆç”Ÿäº§ç¯å¢ƒï¼Œå¯ä»¥å°†workflowå®šä¹‰ä¸ä»£ç åˆ†ç¦»")
}
