package integration

import (
	"context"
	"encoding/json"
	"fmt"
	"log"
	"os"
	"path/filepath"
	"strings"
	"testing"
	"time"

	_ "github.com/mattn/go-sqlite3"
	"github.com/stevelan1995/task-engine/internal/storage/sqlite"
	"github.com/stevelan1995/task-engine/pkg/core/builder"
	"github.com/stevelan1995/task-engine/pkg/core/engine"
	"github.com/stevelan1995/task-engine/pkg/core/task"
	"github.com/stevelan1995/task-engine/pkg/storage"
)

// ==================== æ•°æ®ç»“æ„å®šä¹‰ ====================

// é¢„è®¾æ¨¡æ‹Ÿæ•°æ®æ•°é‡å¸¸é‡
const (
	// äº¤æ˜“æ—¥å†æ•°æ®ï¼š5ä¸ªäº¤æ˜“æ—¥
	ExpectedTradeCalDates = 5

	// è‚¡ç¥¨åˆ—è¡¨æ•°æ®ï¼š5åªè‚¡ç¥¨
	ExpectedStockCount = 5

	// é¢„æœŸå­ä»»åŠ¡ç”Ÿæˆæ•°é‡
	ExpectedDailySubTaskCount     = 5 // dailyåº”è¯¥ä¸º5ä¸ªäº¤æ˜“æ—¥å„ç”Ÿæˆ1ä¸ªå­ä»»åŠ¡
	ExpectedAdjFactorSubTaskCount = 5 // adj_factoråº”è¯¥ä¸º5åªè‚¡ç¥¨å„ç”Ÿæˆ1ä¸ªå­ä»»åŠ¡

	// é¢„æœŸæ•°æ®æ€»æ•°ï¼ˆå¦‚æœåŠ¨æ€å­ä»»åŠ¡å®Œå…¨å®ç°ï¼‰
	// 5ä¸ªtrade_calï¼ˆæ¯ä¸ªäº¤æ˜“æ—¥1æ¡ï¼‰+ 5ä¸ªstock_basicï¼ˆæ¯åªè‚¡ç¥¨1æ¡ï¼‰+ 5ä¸ªdailyï¼ˆæ¯ä¸ªå­ä»»åŠ¡1æ¡ï¼‰+ 5ä¸ªadj_factorï¼ˆæ¯ä¸ªå­ä»»åŠ¡1æ¡ï¼‰= 20æ¡
	ExpectedTotalDataCountWithDynamicTasks = 20

	// é¢„æœŸæ•°æ®æ€»æ•°ï¼ˆåªæ‰§è¡Œç¬¬ä¸€ç»„ä»»åŠ¡ï¼‰
	// TestTushareWorkflow_Basic: 5ä¸ªtrade_calï¼ˆæ¯ä¸ªäº¤æ˜“æ—¥1æ¡ï¼‰+ 5ä¸ªstock_basicï¼ˆæ¯åªè‚¡ç¥¨1æ¡ï¼‰= 10æ¡
	ExpectedTotalDataCountBasic = 10

	// TestTushareWorkflow_WithDependencies: 5ä¸ªtrade_cal + 5ä¸ªstock_basic + 1ä¸ªdaily + 1ä¸ªadj_factor = 12æ¡
	ExpectedTotalDataCountWithDependencies = 12
)

// TradeCalResult äº¤æ˜“æ—¥å†æ•°æ®ç»“æœ
type TradeCalResult struct {
	Exchange string   `json:"exchange"`
	CalDates []string `json:"cal_dates"` // yyyymmddæ ¼å¼
	IsOpen   []string `json:"is_open"`
	PreDates []string `json:"pre_dates"`
}

// StockBasicResult è‚¡ç¥¨åˆ—è¡¨æ•°æ®ç»“æœ
type StockBasicResult struct {
	TSCodes    []string `json:"ts_codes"` // è‚¡ç¥¨ä»£ç åˆ—è¡¨
	Symbols    []string `json:"symbols"`
	Names      []string `json:"names"`
	Areas      []string `json:"areas"`
	Industries []string `json:"industries"`
	ListDates  []string `json:"list_dates"`
}

// DailyResult æ—¥çº¿æ•°æ®ç»“æœ
// æ ¹æ®éœ€æ±‚æ–‡æ¡£ï¼šts_code(str), trade_date(str), open(str), high(float), low(float), close(str), pre_close(float), change(float), pct_chg(float), vol(int), amount(float)
type DailyResult struct {
	TSCode    string  `json:"ts_code"`
	TradeDate string  `json:"trade_date"`
	Open      string  `json:"open"`
	High      float64 `json:"high"`
	Low       float64 `json:"low"`
	Close     string  `json:"close"`
	PreClose  float64 `json:"pre_close"` // éœ€æ±‚æ–‡æ¡£è¦æ±‚æ˜¯ float
	Change    float64 `json:"change"`
	PctChg    float64 `json:"pct_chg"`
	Vol       int     `json:"vol"`
	Amount    float64 `json:"amount"`
}

// AdjFactorResult å¤æƒå› å­ç»“æœ
type AdjFactorResult struct {
	TSCode    string  `json:"ts_code"`
	TradeDate string  `json:"trade_date"`
	AdjFactor float64 `json:"adj_factor"`
}

// QuantDataRepository æ¨¡æ‹Ÿçš„æ•°æ®ä»“åº“ï¼ˆä¾èµ–æ³¨å…¥ï¼‰
type QuantDataRepository struct {
	savedData []map[string]interface{}
}

func NewQuantDataRepository() *QuantDataRepository {
	return &QuantDataRepository{
		savedData: make([]map[string]interface{}, 0),
	}
}

func (r *QuantDataRepository) Save(data map[string]interface{}) error {
	r.savedData = append(r.savedData, data)
	log.Printf("ğŸ’¾ [ä¿å­˜æ•°æ®] ç±»å‹=%v, æ•°æ®=%v", data["type"], data)
	return nil
}

func (r *QuantDataRepository) GetSavedData() []map[string]interface{} {
	return r.savedData
}

// ==================== ä»»åŠ¡å‡½æ•°å®ç° ====================

// QueryTushare æ¨¡æ‹ŸTushare APIæŸ¥è¯¢
func QueryTushare(ctx *task.TaskContext) (interface{}, error) {
	apiName := ctx.GetParamString("api_name")
	log.Printf("ğŸ“¡ [QueryTushare] API=%s, å¼€å§‹æŸ¥è¯¢...", apiName)

	// æ¨¡æ‹ŸAPIè°ƒç”¨å»¶è¿Ÿ
	time.Sleep(50 * time.Millisecond)

	switch apiName {
	case "trade_cal":
		// æ¨¡æ‹Ÿè¿”å›äº¤æ˜“æ—¥å†æ•°æ®
		result := TradeCalResult{
			Exchange: "SSE",
			CalDates: []string{"20251201", "20251202", "20251203", "20251204", "20251205"},
			IsOpen:   []string{"1", "1", "1", "0", "1"},
			PreDates: []string{"20251130", "20251201", "20251202", "20251203", "20251204"},
		}
		log.Printf("âœ… [QueryTushare] trade_cal æŸ¥è¯¢æˆåŠŸï¼Œè¿”å› %d æ¡è®°å½•", len(result.CalDates))
		return result, nil

	case "stock_basic":
		// æ¨¡æ‹Ÿè¿”å›è‚¡ç¥¨åˆ—è¡¨æ•°æ®
		result := StockBasicResult{
			TSCodes:    []string{"000001.SZ", "000002.SZ", "000003.SZ", "000004.SZ", "000005.SZ"},
			Symbols:    []string{"000001", "000002", "000003", "000004", "000005"},
			Names:      []string{"å¹³å®‰é“¶è¡Œ", "ä¸‡ç§‘A", "å›½å†œç§‘æŠ€", "åè”æ§è‚¡", "ä¸–çºªæ˜Ÿæº"},
			Areas:      []string{"æ·±åœ³", "æ·±åœ³", "æ·±åœ³", "æ·±åœ³", "æ·±åœ³"},
			Industries: []string{"é“¶è¡Œ", "æˆ¿åœ°äº§", "ç»¼åˆ", "æˆ¿åœ°äº§", "ç»¼åˆ"},
			ListDates:  []string{"19910403", "19910129", "19910412", "19920106", "19900303"},
		}
		log.Printf("âœ… [QueryTushare] stock_basic æŸ¥è¯¢æˆåŠŸï¼Œè¿”å› %d æ¡è®°å½•", len(result.TSCodes))
		return result, nil

	case "daily":
		// æ¨¡æ‹Ÿè¿”å›æ—¥çº¿æ•°æ®
		// æ ¹æ®éœ€æ±‚æ–‡æ¡£ï¼Œè¿”å›å‚æ•°ï¼šts_code(str), trade_date(str), open(str), high(float), low(float), close(str), pre_close(float), change(float), pct_chg(float), vol(int), amount(float)
		tradeDate := ctx.GetParamString("trade_date")
		result := DailyResult{
			TSCode:    ctx.GetParamString("ts_code"),
			TradeDate: tradeDate,
			Open:      "10.50",
			High:      10.80,
			Low:       10.30,
			Close:     "10.60",
			PreClose:  10.40, // éœ€æ±‚æ–‡æ¡£è¦æ±‚æ˜¯ float
			Change:    0.20,
			PctChg:    1.92,
			Vol:       1000000,
			Amount:    10600000.0,
		}
		log.Printf("âœ… [QueryTushare] daily æŸ¥è¯¢æˆåŠŸï¼Œts_code=%s, trade_date=%s", result.TSCode, result.TradeDate)
		return result, nil

	case "adj_factor":
		// æ¨¡æ‹Ÿè¿”å›å¤æƒå› å­æ•°æ®
		tsCode := ctx.GetParamString("ts_code")
		result := AdjFactorResult{
			TSCode:    tsCode,
			TradeDate: "20251201",
			AdjFactor: 1.0,
		}
		log.Printf("âœ… [QueryTushare] adj_factor æŸ¥è¯¢æˆåŠŸï¼Œts_code=%s", tsCode)
		return result, nil

	default:
		return nil, fmt.Errorf("æœªçŸ¥çš„APIåç§°: %s", apiName)
	}
}

// GenerateSubTasks æ ¹æ®ä¾èµ–ä»»åŠ¡çš„ç»“æœç”Ÿæˆå­ä»»åŠ¡
// è¿™ä¸ªå‡½æ•°ä½œä¸ºSuccess Handlerè¢«è°ƒç”¨ï¼Œä»ç»“æœæ•°æ®ä¸­æå–ä¿¡æ¯å¹¶ç”Ÿæˆå­ä»»åŠ¡
func GenerateSubTasks(ctx *task.TaskContext) {
	// è·å–ä»»åŠ¡ç»“æœæ•°æ®
	resultData := ctx.GetParam("_result_data")
	if resultData == nil {
		log.Printf("âš ï¸ [GenerateSubTasks] æœªæ‰¾åˆ°ç»“æœæ•°æ®")
		return
	}

	// è·å–çˆ¶ä»»åŠ¡åç§°å’ŒID
	parentTaskName := ctx.TaskName
	parentTaskID := ctx.TaskID
	workflowInstanceID := ctx.WorkflowInstanceID
	log.Printf("ğŸ”„ [GenerateSubTasks] çˆ¶ä»»åŠ¡=%s (ID=%s), å¼€å§‹ç”Ÿæˆå­ä»»åŠ¡...", parentTaskName, parentTaskID)

	// è·å–Engineä¾èµ–ï¼ˆé€šè¿‡ä¾èµ–æ³¨å…¥ï¼‰
	engineInterface, ok := ctx.GetDependency("Engine")
	if !ok {
		log.Printf("âš ï¸ [GenerateSubTasks] æœªæ‰¾åˆ°Engineä¾èµ–ï¼Œæ— æ³•æ·»åŠ å­ä»»åŠ¡")
		return
	}
	eng, ok := engineInterface.(*engine.Engine)
	if !ok {
		log.Printf("âš ï¸ [GenerateSubTasks] Engineç±»å‹è½¬æ¢å¤±è´¥")
		return
	}

	// è·å–Registryï¼ˆç”¨äºåˆ›å»ºå­ä»»åŠ¡ï¼‰
	registry := eng.GetRegistry()
	if registry == nil {
		log.Printf("âš ï¸ [GenerateSubTasks] æ— æ³•è·å–Registry")
		return
	}

	// æ ¹æ®çˆ¶ä»»åŠ¡ç±»å‹ç”Ÿæˆä¸åŒçš„å­ä»»åŠ¡
	switch parentTaskName {
	case "è·å–äº¤æ˜“æ—¥å†":
		// ä»äº¤æ˜“æ—¥å†ç»“æœä¸­æå–æ—¥æœŸï¼Œç”Ÿæˆæ—¥çº¿ä»»åŠ¡
		// æ³¨æ„ï¼šåº”è¯¥ä¸ºæ‰€æœ‰5ä¸ªäº¤æ˜“æ—¥ç”Ÿæˆå­ä»»åŠ¡ï¼Œä¸ç®¡æ˜¯å¦å¼€ç›˜
		if tradeCalResult, ok := resultData.(TradeCalResult); ok {
			log.Printf("ğŸ“ [GenerateSubTasks] äº¤æ˜“æ—¥å†ç»“æœ: %d ä¸ªäº¤æ˜“æ—¥", len(tradeCalResult.CalDates))
			generatedCount := 0
			// ä¸ºæ‰€æœ‰äº¤æ˜“æ—¥ç”Ÿæˆå­ä»»åŠ¡ï¼ˆä¸ç®¡æ˜¯å¦å¼€ç›˜ï¼‰
			for _, calDate := range tradeCalResult.CalDates {
				log.Printf("ğŸ“ [GenerateSubTasks] ç”Ÿæˆæ—¥çº¿ä»»åŠ¡: trade_date=%s", calDate)

				// åˆ›å»ºå­ä»»åŠ¡ï¼ˆä½¿ç”¨TaskBuilderï¼‰
				subTaskName := fmt.Sprintf("è·å–æ—¥çº¿æ•°æ®_%s", calDate)
				subTask, err := builder.NewTaskBuilder(subTaskName, fmt.Sprintf("è·å–%sçš„æ—¥çº¿æ•°æ®", calDate), registry).
					WithJobFunction("QueryTushare", map[string]interface{}{
						"api_name":   "daily",
						"trade_date": calDate,
						"ts_code":    "000001.SZ", // é»˜è®¤è‚¡ç¥¨ä»£ç ï¼Œå®é™…åº”è¯¥ä»stock_basicè·å–
					}).
					WithDependency(parentTaskName). // å­ä»»åŠ¡ä¾èµ–çˆ¶ä»»åŠ¡
					WithTaskHandler(task.TaskStatusSuccess, "SaveResult").
					WithTaskHandler(task.TaskStatusFailed, "LogError").
					Build()
				if err != nil {
					log.Printf("âŒ [GenerateSubTasks] åˆ›å»ºdailyå­ä»»åŠ¡å¤±è´¥: trade_date=%s, error=%v", calDate, err)
					continue
				}

				// æ·»åŠ å­ä»»åŠ¡åˆ°WorkflowInstance
				context := context.Background()
				if err := eng.AddSubTaskToInstance(context, workflowInstanceID, subTask, parentTaskID); err != nil {
					log.Printf("âŒ [GenerateSubTasks] æ·»åŠ dailyå­ä»»åŠ¡å¤±è´¥: trade_date=%s, error=%v", calDate, err)
					continue
				}

				generatedCount++
				log.Printf("âœ… [GenerateSubTasks] dailyå­ä»»åŠ¡å·²æ·»åŠ : %s (ID=%s)", subTaskName, subTask.GetID())
			}
			log.Printf("âœ… [GenerateSubTasks] å…±ç”Ÿæˆ %d ä¸ªdailyå­ä»»åŠ¡ï¼ˆé¢„æœŸ: %dï¼‰", generatedCount, ExpectedDailySubTaskCount)
			if generatedCount != ExpectedDailySubTaskCount {
				log.Printf("âš ï¸ [GenerateSubTasks] dailyå­ä»»åŠ¡æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=%d, å®é™…=%d", ExpectedDailySubTaskCount, generatedCount)
			}
		}

	case "è·å–è‚¡ç¥¨åˆ—è¡¨":
		// ä»è‚¡ç¥¨åˆ—è¡¨ç»“æœä¸­æå–è‚¡ç¥¨ä»£ç ï¼Œç”Ÿæˆå¤æƒå› å­ä»»åŠ¡
		if stockBasicResult, ok := resultData.(StockBasicResult); ok {
			log.Printf("ğŸ“ [GenerateSubTasks] è‚¡ç¥¨åˆ—è¡¨ç»“æœ: %d åªè‚¡ç¥¨", len(stockBasicResult.TSCodes))
			generatedCount := 0
			// ä¸ºæ‰€æœ‰è‚¡ç¥¨ç”Ÿæˆå­ä»»åŠ¡
			for _, tsCode := range stockBasicResult.TSCodes {
				log.Printf("ğŸ“ [GenerateSubTasks] ç”Ÿæˆå¤æƒå› å­ä»»åŠ¡: ts_code=%s", tsCode)

				// åˆ›å»ºå­ä»»åŠ¡ï¼ˆä½¿ç”¨TaskBuilderï¼‰
				subTaskName := fmt.Sprintf("è·å–å¤æƒå› å­_%s", tsCode)
				subTask, err := builder.NewTaskBuilder(subTaskName, fmt.Sprintf("è·å–%sçš„å¤æƒå› å­", tsCode), registry).
					WithJobFunction("QueryTushare", map[string]interface{}{
						"api_name": "adj_factor",
						"ts_code":  tsCode,
					}).
					WithDependency(parentTaskName). // å­ä»»åŠ¡ä¾èµ–çˆ¶ä»»åŠ¡
					WithTaskHandler(task.TaskStatusSuccess, "SaveResult").
					WithTaskHandler(task.TaskStatusFailed, "LogError").
					Build()
				if err != nil {
					log.Printf("âŒ [GenerateSubTasks] åˆ›å»ºadj_factorå­ä»»åŠ¡å¤±è´¥: ts_code=%s, error=%v", tsCode, err)
					continue
				}

				// æ·»åŠ å­ä»»åŠ¡åˆ°WorkflowInstance
				context := context.Background()
				if err := eng.AddSubTaskToInstance(context, workflowInstanceID, subTask, parentTaskID); err != nil {
					log.Printf("âŒ [GenerateSubTasks] æ·»åŠ adj_factorå­ä»»åŠ¡å¤±è´¥: ts_code=%s, error=%v", tsCode, err)
					continue
				}

				generatedCount++
				log.Printf("âœ… [GenerateSubTasks] adj_factorå­ä»»åŠ¡å·²æ·»åŠ : %s (ID=%s)", subTaskName, subTask.GetID())
			}
			log.Printf("âœ… [GenerateSubTasks] å…±ç”Ÿæˆ %d ä¸ªadj_factorå­ä»»åŠ¡ï¼ˆé¢„æœŸ: %dï¼‰", generatedCount, ExpectedAdjFactorSubTaskCount)
			if generatedCount != ExpectedAdjFactorSubTaskCount {
				log.Printf("âš ï¸ [GenerateSubTasks] adj_factorå­ä»»åŠ¡æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=%d, å®é™…=%d", ExpectedAdjFactorSubTaskCount, generatedCount)
			}
		}
	}
}

// SaveResult ä¿å­˜ç»“æœæ•°æ®ï¼ˆSuccess Handlerï¼‰
func SaveResult(ctx *task.TaskContext) {
	log.Printf("ğŸ’¾ [SaveResult] è¢«è°ƒç”¨ï¼ŒTaskName=%s, TaskID=%s", ctx.TaskName, ctx.TaskID)

	// è·å–ç»“æœæ•°æ®ï¼ˆå°è¯•å¤šä¸ªå¯èƒ½çš„å‚æ•°åï¼‰
	resultData := ctx.GetParam("_result_data")
	if resultData == nil {
		resultData = ctx.GetParam("result")
	}
	if resultData == nil {
		// å°è¯•ä»æ‰€æœ‰å‚æ•°ä¸­æŸ¥æ‰¾ç»“æœæ•°æ®
		for k, v := range ctx.Params {
			if k != "_status" && k != "_previous_status" && k != "_error_message" {
				resultData = v
				log.Printf("ğŸ“ [SaveResult] ä»å‚æ•° %s è·å–ç»“æœæ•°æ®", k)
				break
			}
		}
	}
	if resultData == nil {
		log.Printf("âš ï¸ [SaveResult] æœªæ‰¾åˆ°ç»“æœæ•°æ®ï¼Œæ‰€æœ‰å‚æ•°é”®: %v", func() []string {
			keys := make([]string, 0, len(ctx.Params))
			for k := range ctx.Params {
				keys = append(keys, k)
			}
			return keys
		}())
		return
	}

	// è·å–æ•°æ®ä»“åº“ï¼ˆé€šè¿‡ä¾èµ–æ³¨å…¥ï¼Œä½¿ç”¨å­—ç¬¦ä¸²keyï¼‰
	repoInterface, ok := ctx.GetDependency("QuantDataRepository")
	if !ok {
		log.Printf("âš ï¸ [SaveResult] æœªæ‰¾åˆ°QuantDataRepositoryä¾èµ–")
		return
	}
	repo, ok := repoInterface.(*QuantDataRepository)
	if !ok {
		log.Printf("âš ï¸ [SaveResult] QuantDataRepositoryç±»å‹è½¬æ¢å¤±è´¥")
		return
	}

	// æ ¹æ®ç»“æœç±»å‹ä¿å­˜æ•°æ®
	// æ³¨æ„ï¼štrade_cal å’Œ stock_basic åº”è¯¥ä¸ºæ¯ä¸ªäº¤æ˜“æ—¥/è‚¡ç¥¨ä¿å­˜ 1 æ¡æ•°æ®
	switch result := resultData.(type) {
	case TradeCalResult:
		// ä¸ºæ¯ä¸ªäº¤æ˜“æ—¥ä¿å­˜ 1 æ¡æ•°æ®
		for i, calDate := range result.CalDates {
			dataToSave := map[string]interface{}{
				"type":     "trade_cal",
				"exchange": result.Exchange,
				"cal_date": calDate,
				"is_open":  result.IsOpen[i],
				"pre_date": result.PreDates[i],
			}
			if err := repo.Save(dataToSave); err != nil {
				log.Printf("âŒ [SaveResult] ä¿å­˜trade_calæ•°æ®å¤±è´¥: %v", err)
			} else {
				log.Printf("âœ… [SaveResult] trade_calæ•°æ®ä¿å­˜æˆåŠŸ: cal_date=%s", calDate)
			}
		}
		// æ³¨æ„ï¼šä¸åœ¨è¿™é‡Œè°ƒç”¨ GenerateSubTasksï¼Œè€Œæ˜¯é€šè¿‡é…ç½® Handler æ¥æ§åˆ¶
		// å¦‚æœéœ€è¦åœ¨ä¿å­˜åç”Ÿæˆå­ä»»åŠ¡ï¼Œåº”è¯¥é…ç½® GenerateSubTasks ä½œä¸º Success Handler
		return
	case StockBasicResult:
		// ä¸ºæ¯åªè‚¡ç¥¨ä¿å­˜ 1 æ¡æ•°æ®
		for i, tsCode := range result.TSCodes {
			dataToSave := map[string]interface{}{
				"type":      "stock_basic",
				"ts_code":   tsCode,
				"symbol":    result.Symbols[i],
				"name":      result.Names[i],
				"area":      result.Areas[i],
				"industry":  result.Industries[i],
				"list_date": result.ListDates[i],
			}
			if err := repo.Save(dataToSave); err != nil {
				log.Printf("âŒ [SaveResult] ä¿å­˜stock_basicæ•°æ®å¤±è´¥: %v", err)
			} else {
				log.Printf("âœ… [SaveResult] stock_basicæ•°æ®ä¿å­˜æˆåŠŸ: ts_code=%s", tsCode)
			}
		}
		// æ³¨æ„ï¼šä¸åœ¨è¿™é‡Œè°ƒç”¨ GenerateSubTasksï¼Œè€Œæ˜¯é€šè¿‡é…ç½® Handler æ¥æ§åˆ¶
		// å¦‚æœéœ€è¦åœ¨ä¿å­˜åç”Ÿæˆå­ä»»åŠ¡ï¼Œåº”è¯¥é…ç½® GenerateSubTasks ä½œä¸º Success Handler
		return
	}

	// å¯¹äºå…¶ä»–ç±»å‹ï¼ˆdailyã€adj_factorï¼‰ï¼Œä¿å­˜å•æ¡æ•°æ®
	var dataType string
	var dataToSave map[string]interface{}

	switch result := resultData.(type) {
	case DailyResult:
		dataType = "daily"
		dataToSave = map[string]interface{}{
			"type":       dataType,
			"ts_code":    result.TSCode,
			"trade_date": result.TradeDate,
			"open":       result.Open,
			"high":       result.High,
			"low":        result.Low,
			"close":      result.Close,
			"pre_close":  result.PreClose,
			"change":     result.Change,
			"pct_chg":    result.PctChg,
			"vol":        result.Vol,
			"amount":     result.Amount,
		}
	case AdjFactorResult:
		dataType = "adj_factor"
		dataToSave = map[string]interface{}{
			"type":       dataType,
			"ts_code":    result.TSCode,
			"trade_date": result.TradeDate,
			"adj_factor": result.AdjFactor,
		}
	default:
		// å°è¯•JSONåºåˆ—åŒ–
		jsonData, err := json.Marshal(result)
		if err != nil {
			log.Printf("âŒ [SaveResult] æ— æ³•åºåˆ—åŒ–ç»“æœæ•°æ®: %v", err)
			return
		}
		dataType = "unknown"
		dataToSave = map[string]interface{}{
			"type": dataType,
			"data": string(jsonData),
		}
	}

	// ä¿å­˜æ•°æ®
	if err := repo.Save(dataToSave); err != nil {
		log.Printf("âŒ [SaveResult] ä¿å­˜æ•°æ®å¤±è´¥: %v", err)
	} else {
		log.Printf("âœ… [SaveResult] æ•°æ®ä¿å­˜æˆåŠŸï¼Œç±»å‹=%s", dataType)
	}
}

// SaveResultAndGenerateSubTasks ä¿å­˜ç»“æœæ•°æ®å¹¶ç”Ÿæˆå­ä»»åŠ¡ï¼ˆSuccess Handlerï¼‰
// è¿™ä¸ª Handler åŒæ—¶æ‰§è¡Œ SaveResult å’Œ GenerateSubTasks
func SaveResultAndGenerateSubTasks(ctx *task.TaskContext) {
	// å…ˆæ‰§è¡Œ SaveResult
	SaveResult(ctx)
	// ç„¶åæ‰§è¡Œ GenerateSubTasksï¼ˆåªæœ‰ trade_cal å’Œ stock_basic ä¼šç”Ÿæˆå­ä»»åŠ¡ï¼‰
	GenerateSubTasks(ctx)
}

// LogError è®°å½•é”™è¯¯ï¼ˆFailed Handlerï¼‰
func LogError(ctx *task.TaskContext) {
	errorMsg := ctx.GetParamString("_error_message")
	taskName := ctx.TaskName
	log.Printf("âŒ [LogError] ä»»åŠ¡=%s, é”™è¯¯=%s", taskName, errorMsg)
}

// ==================== å­—æ®µå®Œæ•´æ€§éªŒè¯å‡½æ•° ====================

// validateDailyDataFields éªŒè¯ daily æ•°æ®å­—æ®µå®Œæ•´æ€§
// æ ¹æ®éœ€æ±‚æ–‡æ¡£ï¼Œdaily åº”è¯¥åŒ…å«ï¼šts_code(str), trade_date(str), open(str), high(float), low(float), close(str), pre_close(float), change(float), pct_chg(float), vol(int), amount(float)
func validateDailyDataFields(t *testing.T, data map[string]interface{}, index int) {
	requiredFields := []string{
		"type",       // é¢å¤–å­—æ®µï¼Œç”¨äºæ ‡è¯†æ•°æ®ç±»å‹
		"ts_code",    // str
		"trade_date", // str
		"open",       // str
		"high",       // float
		"low",        // float
		"close",      // str
		"pre_close",  // float
		"change",     // float
		"pct_chg",    // float
		"vol",        // int
		"amount",     // float
	}

	missingFields := make([]string, 0)
	for _, field := range requiredFields {
		if _, exists := data[field]; !exists {
			missingFields = append(missingFields, field)
		}
	}

	if len(missingFields) > 0 {
		t.Errorf("dailyæ•°æ®[%d]ç¼ºå°‘å¿…éœ€å­—æ®µ: %v", index, missingFields)
	}

	// éªŒè¯å­—æ®µç±»å‹
	if tsCode, ok := data["ts_code"].(string); !ok || tsCode == "" {
		t.Errorf("dailyæ•°æ®[%d] ts_code å­—æ®µç±»å‹é”™è¯¯æˆ–ä¸ºç©º", index)
	}
	if tradeDate, ok := data["trade_date"].(string); !ok || tradeDate == "" {
		t.Errorf("dailyæ•°æ®[%d] trade_date å­—æ®µç±»å‹é”™è¯¯æˆ–ä¸ºç©º", index)
	}
	if open, ok := data["open"].(string); !ok || open == "" {
		t.Errorf("dailyæ•°æ®[%d] open å­—æ®µç±»å‹é”™è¯¯æˆ–ä¸ºç©º", index)
	}
	if _, ok := data["high"].(float64); !ok {
		t.Errorf("dailyæ•°æ®[%d] high å­—æ®µç±»å‹é”™è¯¯ï¼ŒæœŸæœ› float64", index)
	}
	if _, ok := data["low"].(float64); !ok {
		t.Errorf("dailyæ•°æ®[%d] low å­—æ®µç±»å‹é”™è¯¯ï¼ŒæœŸæœ› float64", index)
	}
	if close, ok := data["close"].(string); !ok || close == "" {
		t.Errorf("dailyæ•°æ®[%d] close å­—æ®µç±»å‹é”™è¯¯æˆ–ä¸ºç©º", index)
	}
	if _, ok := data["pre_close"].(float64); !ok {
		t.Errorf("dailyæ•°æ®[%d] pre_close å­—æ®µç±»å‹é”™è¯¯ï¼ŒæœŸæœ› float64", index)
	}
	if _, ok := data["change"].(float64); !ok {
		t.Errorf("dailyæ•°æ®[%d] change å­—æ®µç±»å‹é”™è¯¯ï¼ŒæœŸæœ› float64", index)
	}
	if _, ok := data["pct_chg"].(float64); !ok {
		t.Errorf("dailyæ•°æ®[%d] pct_chg å­—æ®µç±»å‹é”™è¯¯ï¼ŒæœŸæœ› float64", index)
	}
	if _, ok := data["vol"].(int); !ok {
		t.Errorf("dailyæ•°æ®[%d] vol å­—æ®µç±»å‹é”™è¯¯ï¼ŒæœŸæœ› int", index)
	}
	if _, ok := data["amount"].(float64); !ok {
		t.Errorf("dailyæ•°æ®[%d] amount å­—æ®µç±»å‹é”™è¯¯ï¼ŒæœŸæœ› float64", index)
	}
}

// validateAdjFactorDataFields éªŒè¯ adj_factor æ•°æ®å­—æ®µå®Œæ•´æ€§
// æ ¹æ®éœ€æ±‚æ–‡æ¡£ï¼Œadj_factor åº”è¯¥åŒ…å«ï¼šts_code(str), trade_date(str), adj_factor(float)
func validateAdjFactorDataFields(t *testing.T, data map[string]interface{}, index int) {
	requiredFields := []string{
		"type",       // é¢å¤–å­—æ®µï¼Œç”¨äºæ ‡è¯†æ•°æ®ç±»å‹
		"ts_code",    // str
		"trade_date", // str
		"adj_factor", // float
	}

	missingFields := make([]string, 0)
	for _, field := range requiredFields {
		if _, exists := data[field]; !exists {
			missingFields = append(missingFields, field)
		}
	}

	if len(missingFields) > 0 {
		t.Errorf("adj_factoræ•°æ®[%d]ç¼ºå°‘å¿…éœ€å­—æ®µ: %v", index, missingFields)
	}

	// éªŒè¯å­—æ®µç±»å‹
	if tsCode, ok := data["ts_code"].(string); !ok || tsCode == "" {
		t.Errorf("adj_factoræ•°æ®[%d] ts_code å­—æ®µç±»å‹é”™è¯¯æˆ–ä¸ºç©º", index)
	}
	if tradeDate, ok := data["trade_date"].(string); !ok || tradeDate == "" {
		t.Errorf("adj_factoræ•°æ®[%d] trade_date å­—æ®µç±»å‹é”™è¯¯æˆ–ä¸ºç©º", index)
	}
	if _, ok := data["adj_factor"].(float64); !ok {
		t.Errorf("adj_factoræ•°æ®[%d] adj_factor å­—æ®µç±»å‹é”™è¯¯ï¼ŒæœŸæœ› float64", index)
	}
}

// validateTradeCalDataFields éªŒè¯ trade_cal æ•°æ®å­—æ®µå®Œæ•´æ€§
// æ ¹æ®éœ€æ±‚æ–‡æ¡£ï¼Œtrade_cal åº”è¯¥åŒ…å«ï¼šexchange(str), cal_date(str, yyyymmdd), is_open(str), pre_date(str)
func validateTradeCalDataFields(t *testing.T, data map[string]interface{}, index int) {
	requiredFields := []string{
		"type",     // é¢å¤–å­—æ®µ
		"exchange", // str
		"cal_date", // str
		"is_open",  // str
		"pre_date", // str
	}

	missingFields := make([]string, 0)
	for _, field := range requiredFields {
		if _, exists := data[field]; !exists {
			missingFields = append(missingFields, field)
		}
	}

	if len(missingFields) > 0 {
		t.Errorf("trade_calæ•°æ®[%d]ç¼ºå°‘å¿…éœ€å­—æ®µ: %v", index, missingFields)
	}
}

// validateStockBasicDataFields éªŒè¯ stock_basic æ•°æ®å­—æ®µå®Œæ•´æ€§
// æ ¹æ®éœ€æ±‚æ–‡æ¡£ï¼Œstock_basic åº”è¯¥åŒ…å«ï¼šts_code(str), symbol(str), name(str), area(str), industry(str), list_date(str)
func validateStockBasicDataFields(t *testing.T, data map[string]interface{}, index int) {
	requiredFields := []string{
		"type",      // é¢å¤–å­—æ®µ
		"ts_code",   // str
		"symbol",    // str
		"name",      // str
		"area",      // str
		"industry",  // str
		"list_date", // str
	}

	missingFields := make([]string, 0)
	for _, field := range requiredFields {
		if _, exists := data[field]; !exists {
			missingFields = append(missingFields, field)
		}
	}

	if len(missingFields) > 0 {
		t.Errorf("stock_basicæ•°æ®[%d]ç¼ºå°‘å¿…éœ€å­—æ®µ: %v", index, missingFields)
	}
}

// ==================== æµ‹è¯•å‡½æ•° ====================

func setupTushareTest(t *testing.T) (*engine.Engine, *task.FunctionRegistry, *QuantDataRepository, storage.TaskRepository, func()) {
	// åˆ›å»ºä¸´æ—¶æ•°æ®åº“
	tmpDir := t.TempDir()
	dbPath := filepath.Join(tmpDir, "tushare_test.db")

	// åˆ›å»ºRepository
	repos, err := sqlite.NewRepositories(dbPath)
	if err != nil {
		t.Fatalf("åˆ›å»ºRepositoryå¤±è´¥: %v", err)
	}

	// åˆ›å»ºEngine
	eng, err := engine.NewEngine(10, 30, repos.Workflow, repos.WorkflowInstance, repos.Task)
	if err != nil {
		t.Fatalf("åˆ›å»ºEngineå¤±è´¥: %v", err)
	}

	// è·å–Registry
	registry := eng.GetRegistry()
	if registry == nil {
		t.Fatalf("è·å–registryå¤±è´¥")
	}

	// åˆ›å»ºæ•°æ®ä»“åº“
	repo := NewQuantDataRepository()

	// æ³¨å†Œä¾èµ–
	ctx := context.Background()
	if err := registry.RegisterDependencyWithKey("QuantDataRepository", repo); err != nil {
		t.Fatalf("æ³¨å†ŒQuantDataRepositoryä¾èµ–å¤±è´¥: %v", err)
	}
	if err := registry.RegisterDependencyWithKey("Engine", eng); err != nil {
		t.Fatalf("æ³¨å†ŒEngineä¾èµ–å¤±è´¥: %v", err)
	}

	// å¯åŠ¨Engine
	if err := eng.Start(ctx); err != nil {
		t.Fatalf("å¯åŠ¨Engineå¤±è´¥: %v", err)
	}

	// æ³¨å†ŒJobå‡½æ•°
	_, err = registry.Register(ctx, "QueryTushare", QueryTushare, "æ¨¡æ‹ŸTushare APIæŸ¥è¯¢")
	if err != nil {
		t.Fatalf("æ³¨å†ŒQueryTushareå¤±è´¥: %v", err)
	}

	// æ³¨å†ŒTask Handler
	_, err = registry.RegisterTaskHandler(ctx, "SaveResult", SaveResult, "ä¿å­˜ç»“æœæ•°æ®")
	if err != nil {
		t.Fatalf("æ³¨å†ŒSaveResultå¤±è´¥: %v", err)
	}

	_, err = registry.RegisterTaskHandler(ctx, "LogError", LogError, "è®°å½•é”™è¯¯")
	if err != nil {
		t.Fatalf("æ³¨å†ŒLogErrorå¤±è´¥: %v", err)
	}

	_, err = registry.RegisterTaskHandler(ctx, "GenerateSubTasks", GenerateSubTasks, "ç”Ÿæˆå­ä»»åŠ¡")
	if err != nil {
		t.Fatalf("æ³¨å†ŒGenerateSubTaskså¤±è´¥: %v", err)
	}

	_, err = registry.RegisterTaskHandler(ctx, "SaveResultAndGenerateSubTasks", SaveResultAndGenerateSubTasks, "ä¿å­˜ç»“æœæ•°æ®å¹¶ç”Ÿæˆå­ä»»åŠ¡")
	if err != nil {
		t.Fatalf("æ³¨å†ŒSaveResultAndGenerateSubTaskså¤±è´¥: %v", err)
	}

	cleanup := func() {
		eng.Stop()
		repos.Close()
		os.Remove(dbPath)
	}

	return eng, registry, repo, repos.Task, cleanup
}

func TestTushareWorkflow_Basic(t *testing.T) {
	eng, registry, repo, taskRepo, cleanup := setupTushareTest(t)
	defer cleanup()

	ctx := context.Background()

	// åˆ›å»ºä»»åŠ¡ç»„1ï¼šæ— ä¾èµ–ä»»åŠ¡
	// æ³¨æ„ï¼šTestTushareWorkflow_Basic åªæ‰§è¡Œå‰ä¸¤ä¸ªä»»åŠ¡ï¼Œä¸ç”Ÿæˆå­ä»»åŠ¡ï¼Œæ‰€ä»¥åªä½¿ç”¨ SaveResult
	task1, err := builder.NewTaskBuilder("è·å–äº¤æ˜“æ—¥å†", "è·å–Tushareäº¤æ˜“æ—¥å†æ•°æ®", registry).
		WithJobFunction("QueryTushare", map[string]interface{}{
			"api_name": "trade_cal",
		}).
		WithTaskHandler(task.TaskStatusSuccess, "SaveResult"). // åªä¿å­˜æ•°æ®ï¼Œä¸ç”Ÿæˆå­ä»»åŠ¡
		WithTaskHandler(task.TaskStatusFailed, "LogError").
		Build()
	if err != nil {
		t.Fatalf("æ„å»ºTask1å¤±è´¥: %v", err)
	}

	// éªŒè¯StatusHandlersæ˜¯å¦æ­£ç¡®è®¾ç½®
	if len(task1.StatusHandlers) == 0 {
		t.Fatal("Task1çš„StatusHandlersä¸ºç©º")
	}
	log.Printf("âœ… [æµ‹è¯•] Task1 StatusHandlers: %v", task1.StatusHandlers)

	task2, err := builder.NewTaskBuilder("è·å–è‚¡ç¥¨åˆ—è¡¨", "è·å–Tushareè‚¡ç¥¨åˆ—è¡¨æ•°æ®", registry).
		WithJobFunction("QueryTushare", map[string]interface{}{
			"api_name": "stock_basic",
		}).
		WithTaskHandler(task.TaskStatusSuccess, "SaveResult"). // åªä¿å­˜æ•°æ®ï¼Œä¸ç”Ÿæˆå­ä»»åŠ¡
		WithTaskHandler(task.TaskStatusFailed, "LogError").
		Build()
	if err != nil {
		t.Fatalf("æ„å»ºTask2å¤±è´¥: %v", err)
	}

	// åˆ›å»ºWorkflow
	wf, err := builder.NewWorkflowBuilder("Tushareæ•°æ®ä¸‹è½½å·¥ä½œæµ", "æ¨¡æ‹Ÿä»Tushareæ‰¹é‡ä¸‹è½½æ•°æ®çš„æµç¨‹").
		WithTask(task1).
		WithTask(task2).
		Build()
	if err != nil {
		t.Fatalf("æ„å»ºWorkflowå¤±è´¥: %v", err)
	}

	// æäº¤Workflow
	controller, err := eng.SubmitWorkflow(ctx, wf)
	if err != nil {
		t.Fatalf("æäº¤Workflowå¤±è´¥: %v", err)
	}

	instanceID := controller.GetInstanceID()
	if instanceID == "" {
		t.Fatal("InstanceIDä¸ºç©º")
	}

	// ç­‰å¾…å·¥ä½œæµæ‰§è¡Œå®Œæˆï¼ˆæœ€å¤šç­‰å¾…30ç§’ï¼‰
	timeout := 30 * time.Second
	startTime := time.Now()
	for {
		status, err := controller.GetStatus()
		if err != nil {
			t.Fatalf("è·å–çŠ¶æ€å¤±è´¥: %v", err)
		}

		if status == "Success" || status == "Failed" || status == "Terminated" {
			log.Printf("âœ… [å·¥ä½œæµå®Œæˆ] çŠ¶æ€=%s, è€—æ—¶=%v", status, time.Since(startTime))
			break
		}

		if time.Since(startTime) > timeout {
			t.Fatalf("å·¥ä½œæµæ‰§è¡Œè¶…æ—¶ï¼Œå½“å‰çŠ¶æ€=%s", status)
		}

		time.Sleep(100 * time.Millisecond)
	}

	// éªŒè¯æœ€ç»ˆçŠ¶æ€
	finalStatus, err := controller.GetStatus()
	if err != nil {
		t.Fatalf("è·å–æœ€ç»ˆçŠ¶æ€å¤±è´¥: %v", err)
	}

	if finalStatus != "Success" {
		t.Errorf("æœŸæœ›å·¥ä½œæµçŠ¶æ€ä¸ºSuccessï¼Œå®é™…ä¸º%s", finalStatus)
	}

	// ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œç¡®ä¿Handleræ‰§è¡Œå®Œæˆ
	time.Sleep(500 * time.Millisecond)

	// éªŒè¯å¹¶æ‰“å°ä¿å­˜çš„æ•°æ®ï¼ˆéœ€æ±‚ç¬¬7æ¡ï¼šéœ€è¦æ‰“å°æœ€åä¿å­˜çš„æ•°æ®ï¼‰
	savedData := repo.GetSavedData()
	if len(savedData) == 0 {
		t.Logf("âš ï¸ æœªä¿å­˜ä»»ä½•æ•°æ®ï¼Œè¿™å¯èƒ½æ˜¯å› ä¸ºHandleræœªè¢«è°ƒç”¨æˆ–ä¾èµ–æ³¨å…¥å¤±è´¥")
		// æš‚æ—¶ä¸å¤±è´¥ï¼Œå› ä¸ºHandlerè°ƒç”¨å¯èƒ½æœ‰é—®é¢˜
		t.Error("æœªä¿å­˜ä»»ä½•æ•°æ®")
	} else {
		// ç»Ÿè®¡å„ç±»å‹æ•°æ®æ•°é‡
		dataCountByType := make(map[string]int)
		for _, data := range savedData {
			if dataType, ok := data["type"].(string); ok {
				dataCountByType[dataType]++
			}
		}

		log.Printf("âœ… [æ•°æ®éªŒè¯] å…±ä¿å­˜ %d æ¡æ•°æ®", len(savedData))
		log.Printf("ğŸ“Š [æ•°æ®ç»Ÿè®¡] trade_cal=%d, stock_basic=%d, daily=%d, adj_factor=%d",
			dataCountByType["trade_cal"],
			dataCountByType["stock_basic"],
			dataCountByType["daily"],
			dataCountByType["adj_factor"])

		// éªŒè¯æ•°æ®æ•°é‡æ˜¯å¦ç¬¦åˆé¢„æœŸï¼ˆéœ€æ±‚ç¬¬7æ¡ï¼šéœ€è¦ç¬¦åˆé¢„è®¾æ¨¡æ‹Ÿæ•°æ®çš„æ•°é‡ï¼‰
		// åªæ‰§è¡Œç¬¬ä¸€ç»„ä»»åŠ¡ï¼Œåº”è¯¥ä¿å­˜ 10 æ¡æ•°æ®ï¼ˆ5 trade_cal + 5 stock_basicï¼‰
		expectedCount := ExpectedTotalDataCountBasic

		log.Printf("ğŸ“Š [æ•°é‡éªŒè¯] å½“å‰æ•°æ®: %d æ¡, é¢„æœŸ: %d æ¡ï¼ˆ5 trade_cal + 5 stock_basicï¼‰",
			len(savedData), expectedCount)

		if len(savedData) != expectedCount {
			t.Errorf("æ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=%d, å®é™…=%d", expectedCount, len(savedData))
		} else {
			log.Printf("âœ… [æ•°é‡éªŒè¯] æ•°æ®æ•°é‡ç¬¦åˆé¢„æœŸ: %d æ¡", expectedCount)
		}

		// éªŒè¯å„ç±»å‹æ•°æ®æ•°é‡
		if dataCountByType["trade_cal"] != 5 {
			t.Errorf("trade_calæ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=5, å®é™…=%d", dataCountByType["trade_cal"])
		}
		if dataCountByType["stock_basic"] != 5 {
			t.Errorf("stock_basicæ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=5, å®é™…=%d", dataCountByType["stock_basic"])
		}

		// é‡è¦ï¼šéªŒè¯å­ä»»åŠ¡ç¡®å®æ²¡æœ‰ç”Ÿæˆå’Œæ‰§è¡Œ
		// TestTushareWorkflow_Basic åªä½¿ç”¨ SaveResultï¼Œä¸ç”Ÿæˆå­ä»»åŠ¡ï¼Œæ‰€ä»¥ daily å’Œ adj_factor åº”è¯¥ä¸º 0
		if dataCountByType["daily"] != 0 {
			t.Errorf("dailyæ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=0ï¼ˆä¸ç”Ÿæˆå­ä»»åŠ¡ï¼‰, å®é™…=%d", dataCountByType["daily"])
		}
		if dataCountByType["adj_factor"] != 0 {
			t.Errorf("adj_factoræ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=0ï¼ˆä¸ç”Ÿæˆå­ä»»åŠ¡ï¼‰, å®é™…=%d", dataCountByType["adj_factor"])
		}

		// éªŒè¯ä»»åŠ¡å®ä¾‹ï¼šåº”è¯¥åªæœ‰2ä¸ªä»»åŠ¡ï¼ˆtrade_cal å’Œ stock_basicï¼‰ï¼Œæ²¡æœ‰å­ä»»åŠ¡
		ctx := context.Background()
		taskInstances, err := taskRepo.GetByWorkflowInstanceID(ctx, instanceID)
		if err != nil {
			t.Logf("âš ï¸ æ— æ³•æŸ¥è¯¢ä»»åŠ¡å®ä¾‹: %v", err)
		} else {
			// ç»Ÿè®¡ä»»åŠ¡æ•°é‡
			taskCount := len(taskInstances)
			expectedTaskCount := 2 // åªæœ‰ trade_cal å’Œ stock_basic
			if taskCount != expectedTaskCount {
				t.Errorf("ä»»åŠ¡å®ä¾‹æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=%dï¼ˆä¸ç”Ÿæˆå­ä»»åŠ¡ï¼‰, å®é™…=%d", expectedTaskCount, taskCount)
			} else {
				log.Printf("âœ… [ä»»åŠ¡å®ä¾‹éªŒè¯] ä»»åŠ¡æ•°é‡ç¬¦åˆé¢„æœŸ: %d ä¸ªï¼ˆæ— å­ä»»åŠ¡ï¼‰", taskCount)
			}

			// éªŒè¯æ‰€æœ‰ä»»åŠ¡éƒ½æˆåŠŸå®Œæˆ
			for _, taskInstance := range taskInstances {
				if taskInstance.Status != "Success" {
					t.Errorf("ä»»åŠ¡ %s çŠ¶æ€ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=Success, å®é™…=%s", taskInstance.Name, taskInstance.Status)
				}
			}
		}

		// æ‰“å°æ‰€æœ‰ä¿å­˜çš„æ•°æ®ï¼ˆéœ€æ±‚ç¬¬7æ¡ï¼‰
		separator := strings.Repeat("=", 80)
		log.Printf("\n%s", separator)
		log.Printf("ğŸ“Š [æœ€ç»ˆä¿å­˜çš„æ•°æ®] (é¢„æœŸ: %d æ¡, å®é™…: %d æ¡)", expectedCount, len(savedData))
		log.Printf("%s", separator)
		for i, data := range savedData {
			log.Printf("\n[æ•°æ® %d/%d]", i+1, len(savedData))
			if dataType, ok := data["type"].(string); ok {
				log.Printf("  ç±»å‹: %s", dataType)
			}
			// å®Œæ•´æ‰“å°æ‰€æœ‰å­—æ®µ
			for k, v := range data {
				if k != "type" {
					log.Printf("  %s: %v", k, v)
				}
			}
		}
		log.Printf("%s\n", separator)

		// éªŒè¯è‡³å°‘åŒ…å«äº¤æ˜“æ—¥å†å’Œè‚¡ç¥¨åˆ—è¡¨æ•°æ®
		hasTradeCal := false
		hasStockBasic := false
		for _, data := range savedData {
			if dataType, ok := data["type"].(string); ok {
				if dataType == "trade_cal" {
					hasTradeCal = true
				}
				if dataType == "stock_basic" {
					hasStockBasic = true
				}
			}
		}
		if !hasTradeCal {
			t.Error("æœªä¿å­˜äº¤æ˜“æ—¥å†æ•°æ®")
		}
		if !hasStockBasic {
			t.Error("æœªä¿å­˜è‚¡ç¥¨åˆ—è¡¨æ•°æ®")
		}
	}
}

func TestTushareWorkflow_WithDependencies(t *testing.T) {
	eng, registry, repo, _, cleanup := setupTushareTest(t)
	defer cleanup()

	ctx := context.Background()

	// åˆ›å»ºä»»åŠ¡ç»„1ï¼šæ— ä¾èµ–ä»»åŠ¡
	task1, _ := builder.NewTaskBuilder("è·å–äº¤æ˜“æ—¥å†", "è·å–Tushareäº¤æ˜“æ—¥å†æ•°æ®", registry).
		WithJobFunction("QueryTushare", map[string]interface{}{
			"api_name": "trade_cal",
		}).
		WithTaskHandler(task.TaskStatusSuccess, "SaveResult").
		WithTaskHandler(task.TaskStatusFailed, "LogError").
		Build()

	task2, _ := builder.NewTaskBuilder("è·å–è‚¡ç¥¨åˆ—è¡¨", "è·å–Tushareè‚¡ç¥¨åˆ—è¡¨æ•°æ®", registry).
		WithJobFunction("QueryTushare", map[string]interface{}{
			"api_name": "stock_basic",
		}).
		WithTaskHandler(task.TaskStatusSuccess, "SaveResult").
		WithTaskHandler(task.TaskStatusFailed, "LogError").
		Build()

	// åˆ›å»ºä»»åŠ¡ç»„2ï¼šä¾èµ–ä»»åŠ¡ç»„1ï¼ˆæ³¨æ„ï¼šç”±äºåŠ¨æ€å­ä»»åŠ¡æœºåˆ¶å°šæœªå®Œå…¨å®ç°ï¼Œè¿™é‡Œå…ˆæµ‹è¯•é™æ€ä»»åŠ¡ï¼‰
	// å®é™…åœºæ™¯ä¸­ï¼Œè¿™äº›ä»»åŠ¡åº”è¯¥ç”±GenerateSubTasksåŠ¨æ€ç”Ÿæˆ
	task3, _ := builder.NewTaskBuilder("è·å–æ—¥çº¿æ•°æ®_20251201", "è·å–20251201çš„æ—¥çº¿æ•°æ®", registry).
		WithJobFunction("QueryTushare", map[string]interface{}{
			"api_name":   "daily",
			"trade_date": "20251201",
			"ts_code":    "000001.SZ",
		}).
		WithDependency("è·å–äº¤æ˜“æ—¥å†").
		WithTaskHandler(task.TaskStatusSuccess, "SaveResult").
		WithTaskHandler(task.TaskStatusFailed, "LogError").
		Build()

	task4, _ := builder.NewTaskBuilder("è·å–å¤æƒå› å­_000001.SZ", "è·å–000001.SZçš„å¤æƒå› å­", registry).
		WithJobFunction("QueryTushare", map[string]interface{}{
			"api_name": "adj_factor",
			"ts_code":  "000001.SZ",
		}).
		WithDependency("è·å–è‚¡ç¥¨åˆ—è¡¨").
		WithTaskHandler(task.TaskStatusSuccess, "SaveResult").
		WithTaskHandler(task.TaskStatusFailed, "LogError").
		Build()

	// åˆ›å»ºWorkflow
	wf, err := builder.NewWorkflowBuilder("Tushareæ•°æ®ä¸‹è½½å·¥ä½œæµï¼ˆå«ä¾èµ–ï¼‰", "æµ‹è¯•ä¾èµ–å…³ç³»çš„æ­£ç¡®æ‰§è¡Œé¡ºåº").
		WithTask(task1).
		WithTask(task2).
		WithTask(task3).
		WithTask(task4).
		Build()
	if err != nil {
		t.Fatalf("æ„å»ºWorkflowå¤±è´¥: %v", err)
	}

	// æäº¤Workflow
	controller, err := eng.SubmitWorkflow(ctx, wf)
	if err != nil {
		t.Fatalf("æäº¤Workflowå¤±è´¥: %v", err)
	}

	// ç­‰å¾…å·¥ä½œæµæ‰§è¡Œå®Œæˆ
	timeout := 30 * time.Second
	startTime := time.Now()
	for {
		status, err := controller.GetStatus()
		if err != nil {
			t.Fatalf("è·å–çŠ¶æ€å¤±è´¥: %v", err)
		}

		if status == "Success" || status == "Failed" || status == "Terminated" {
			log.Printf("âœ… [å·¥ä½œæµå®Œæˆ] çŠ¶æ€=%s, è€—æ—¶=%v", status, time.Since(startTime))
			break
		}

		if time.Since(startTime) > timeout {
			t.Fatalf("å·¥ä½œæµæ‰§è¡Œè¶…æ—¶ï¼Œå½“å‰çŠ¶æ€=%s", status)
		}

		time.Sleep(100 * time.Millisecond)
	}

	// éªŒè¯æœ€ç»ˆçŠ¶æ€
	finalStatus, err := controller.GetStatus()
	if err != nil {
		t.Fatalf("è·å–æœ€ç»ˆçŠ¶æ€å¤±è´¥: %v", err)
	}

	if finalStatus != "Success" {
		t.Errorf("æœŸæœ›å·¥ä½œæµçŠ¶æ€ä¸ºSuccessï¼Œå®é™…ä¸º%s", finalStatus)
	}

	// ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œç¡®ä¿Handleræ‰§è¡Œå®Œæˆ
	time.Sleep(500 * time.Millisecond)

	// éªŒè¯å¹¶æ‰“å°ä¿å­˜çš„æ•°æ®ï¼ˆéœ€æ±‚ç¬¬7æ¡ï¼šéœ€è¦æ‰“å°æœ€åä¿å­˜çš„æ•°æ®ï¼‰
	savedData := repo.GetSavedData()

	// ç»Ÿè®¡å„ç±»å‹æ•°æ®æ•°é‡
	dataCountByType := make(map[string]int)
	for _, data := range savedData {
		if dataType, ok := data["type"].(string); ok {
			dataCountByType[dataType]++
		}
	}

	log.Printf("âœ… [æ•°æ®éªŒè¯] å…±ä¿å­˜ %d æ¡æ•°æ®", len(savedData))
	log.Printf("ğŸ“Š [æ•°æ®ç»Ÿè®¡] trade_cal=%d, stock_basic=%d, daily=%d, adj_factor=%d",
		dataCountByType["trade_cal"],
		dataCountByType["stock_basic"],
		dataCountByType["daily"],
		dataCountByType["adj_factor"])

	// éªŒè¯æ•°æ®æ•°é‡æ˜¯å¦ç¬¦åˆé¢„æœŸï¼ˆéœ€æ±‚ç¬¬7æ¡ï¼šéœ€è¦ç¬¦åˆé¢„è®¾æ¨¡æ‹Ÿæ•°æ®çš„æ•°é‡ï¼‰
	// é™æ€ä»»åŠ¡åœºæ™¯ï¼š5 trade_cal + 5 stock_basic + 1 daily + 1 adj_factor = 12æ¡
	expectedCount := ExpectedTotalDataCountWithDependencies

	log.Printf("ğŸ“Š [æ•°é‡éªŒè¯] å½“å‰æ•°æ®: %d æ¡, é¢„æœŸ: %d æ¡ï¼ˆ5 trade_cal + 5 stock_basic + 1 daily + 1 adj_factorï¼‰",
		len(savedData), expectedCount)

	if len(savedData) != expectedCount {
		t.Errorf("æ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=%d, å®é™…=%d", expectedCount, len(savedData))
	} else {
		log.Printf("âœ… [æ•°é‡éªŒè¯] æ•°æ®æ•°é‡ç¬¦åˆé¢„æœŸ: %d æ¡", expectedCount)
	}

	// éªŒè¯å„ç±»å‹æ•°æ®æ•°é‡
	if dataCountByType["trade_cal"] != 5 {
		t.Errorf("trade_calæ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=5, å®é™…=%d", dataCountByType["trade_cal"])
	}
	if dataCountByType["stock_basic"] != 5 {
		t.Errorf("stock_basicæ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=5, å®é™…=%d", dataCountByType["stock_basic"])
	}
	if dataCountByType["daily"] != 1 {
		t.Errorf("dailyæ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=1, å®é™…=%d", dataCountByType["daily"])
	}
	if dataCountByType["adj_factor"] != 1 {
		t.Errorf("adj_factoræ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=1, å®é™…=%d", dataCountByType["adj_factor"])
	}

	// éªŒè¯å­—æ®µå®Œæ•´æ€§ï¼šæ£€æŸ¥æ‰€æœ‰ä¿å­˜çš„æ•°æ®æ˜¯å¦åŒ…å«å¿…éœ€çš„å­—æ®µ
	log.Printf("ğŸ” [å­—æ®µå®Œæ•´æ€§éªŒè¯] å¼€å§‹éªŒè¯æ‰€æœ‰æ•°æ®çš„å­—æ®µå®Œæ•´æ€§...")
	dailyIndex := 0
	adjFactorIndex := 0
	tradeCalIndex := 0
	stockBasicIndex := 0
	for i, data := range savedData {
		if dataType, ok := data["type"].(string); ok {
			switch dataType {
			case "daily":
				validateDailyDataFields(t, data, dailyIndex)
				dailyIndex++
			case "adj_factor":
				validateAdjFactorDataFields(t, data, adjFactorIndex)
				adjFactorIndex++
			case "trade_cal":
				validateTradeCalDataFields(t, data, tradeCalIndex)
				tradeCalIndex++
			case "stock_basic":
				validateStockBasicDataFields(t, data, stockBasicIndex)
				stockBasicIndex++
			default:
				t.Logf("âš ï¸ æœªçŸ¥æ•°æ®ç±»å‹: %s (æ•°æ®ç´¢å¼•: %d)", dataType, i)
			}
		}
	}
	log.Printf("âœ… [å­—æ®µå®Œæ•´æ€§éªŒè¯] å®Œæˆï¼ŒéªŒè¯äº† %d æ¡ daily æ•°æ®ï¼Œ%d æ¡ adj_factor æ•°æ®ï¼Œ%d æ¡ trade_cal æ•°æ®ï¼Œ%d æ¡ stock_basic æ•°æ®",
		dailyIndex, adjFactorIndex, tradeCalIndex, stockBasicIndex)

	// æ‰“å°æ‰€æœ‰ä¿å­˜çš„æ•°æ®ï¼ˆéœ€æ±‚ç¬¬7æ¡ï¼‰
	if len(savedData) > 0 {
		separator := strings.Repeat("=", 80)
		log.Printf("\n%s", separator)
		log.Printf("ğŸ“Š [æœ€ç»ˆä¿å­˜çš„æ•°æ®] (é¢„æœŸ: %d æ¡, å®é™…: %d æ¡)", expectedCount, len(savedData))
		log.Printf("%s", separator)
		for i, data := range savedData {
			log.Printf("\n[æ•°æ® %d/%d]", i+1, len(savedData))
			if dataType, ok := data["type"].(string); ok {
				log.Printf("  ç±»å‹: %s", dataType)
			}
			// å®Œæ•´æ‰“å°æ‰€æœ‰å­—æ®µ
			for k, v := range data {
				if k != "type" {
					log.Printf("  %s: %v", k, v)
				}
			}
		}
		log.Printf("%s\n", separator)
	}

	// éªŒè¯æ•°æ®åŒ…å«æ‰€æœ‰ç±»å‹
	dataTypes := make(map[string]bool)
	for _, data := range savedData {
		if dataType, ok := data["type"].(string); ok {
			dataTypes[dataType] = true
		}
	}

	expectedTypes := []string{"trade_cal", "stock_basic", "daily", "adj_factor"}
	for _, expectedType := range expectedTypes {
		if !dataTypes[expectedType] {
			t.Errorf("ç¼ºå°‘æ•°æ®ç±»å‹: %s", expectedType)
		}
	}
}

// TestTushareWorkflow_Full å®Œæ•´æµ‹è¯•ï¼šæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡ï¼ŒåŒ…æ‹¬åŠ¨æ€ç”Ÿæˆçš„å­ä»»åŠ¡
// é¢„æœŸä¿å­˜ 20 æ¡æ•°æ®ï¼š5 trade_cal + 5 stock_basic + 5 daily + 5 adj_factor
func TestTushareWorkflow_Full(t *testing.T) {
	eng, registry, repo, taskRepo, cleanup := setupTushareTest(t)
	defer cleanup()

	ctx := context.Background()

	// åˆ›å»ºä»»åŠ¡ç»„1ï¼šæ— ä¾èµ–ä»»åŠ¡
	// æ³¨æ„ï¼šTestTushareWorkflow_Full éœ€è¦ç”Ÿæˆå­ä»»åŠ¡ï¼Œæ‰€ä»¥ä½¿ç”¨ SaveResultAndGenerateSubTasks
	task1, err := builder.NewTaskBuilder("è·å–äº¤æ˜“æ—¥å†", "è·å–Tushareäº¤æ˜“æ—¥å†æ•°æ®", registry).
		WithJobFunction("QueryTushare", map[string]interface{}{
			"api_name": "trade_cal",
		}).
		WithTaskHandler(task.TaskStatusSuccess, "SaveResultAndGenerateSubTasks"). // ä¿å­˜æ•°æ®å¹¶ç”Ÿæˆå­ä»»åŠ¡
		WithTaskHandler(task.TaskStatusFailed, "LogError").
		Build()
	if err != nil {
		t.Fatalf("æ„å»ºTask1å¤±è´¥: %v", err)
	}

	task2, err := builder.NewTaskBuilder("è·å–è‚¡ç¥¨åˆ—è¡¨", "è·å–Tushareè‚¡ç¥¨åˆ—è¡¨æ•°æ®", registry).
		WithJobFunction("QueryTushare", map[string]interface{}{
			"api_name": "stock_basic",
		}).
		WithTaskHandler(task.TaskStatusSuccess, "SaveResultAndGenerateSubTasks"). // ä¿å­˜æ•°æ®å¹¶ç”Ÿæˆå­ä»»åŠ¡
		WithTaskHandler(task.TaskStatusFailed, "LogError").
		Build()
	if err != nil {
		t.Fatalf("æ„å»ºTask2å¤±è´¥: %v", err)
	}

	// åˆ›å»ºWorkflow
	wf, err := builder.NewWorkflowBuilder("Tushareæ•°æ®ä¸‹è½½å·¥ä½œæµï¼ˆå®Œæ•´ï¼‰", "æµ‹è¯•å®Œæ•´æµç¨‹ï¼ŒåŒ…æ‹¬åŠ¨æ€å­ä»»åŠ¡").
		WithTask(task1).
		WithTask(task2).
		Build()
	if err != nil {
		t.Fatalf("æ„å»ºWorkflowå¤±è´¥: %v", err)
	}

	// æäº¤Workflow
	controller, err := eng.SubmitWorkflow(ctx, wf)
	if err != nil {
		t.Fatalf("æäº¤Workflowå¤±è´¥: %v", err)
	}

	instanceID := controller.GetInstanceID()
	if instanceID == "" {
		t.Fatal("InstanceIDä¸ºç©º")
	}

	// ç­‰å¾…å·¥ä½œæµæ‰§è¡Œå®Œæˆï¼ˆæœ€å¤šç­‰å¾…60ç§’ï¼Œå› ä¸ºéœ€è¦æ‰§è¡Œæ›´å¤šä»»åŠ¡ï¼‰
	timeout := 60 * time.Second
	startTime := time.Now()
	for {
		status, err := controller.GetStatus()
		if err != nil {
			t.Fatalf("è·å–çŠ¶æ€å¤±è´¥: %v", err)
		}

		if status == "Success" || status == "Failed" || status == "Terminated" {
			log.Printf("âœ… [å·¥ä½œæµå®Œæˆ] çŠ¶æ€=%s, è€—æ—¶=%v", status, time.Since(startTime))
			break
		}

		if time.Since(startTime) > timeout {
			t.Fatalf("å·¥ä½œæµæ‰§è¡Œè¶…æ—¶ï¼Œå½“å‰çŠ¶æ€=%s", status)
		}

		time.Sleep(100 * time.Millisecond)
	}

	// éªŒè¯æœ€ç»ˆçŠ¶æ€
	finalStatus, err := controller.GetStatus()
	if err != nil {
		t.Fatalf("è·å–æœ€ç»ˆçŠ¶æ€å¤±è´¥: %v", err)
	}

	if finalStatus != "Success" {
		t.Errorf("æœŸæœ›å·¥ä½œæµçŠ¶æ€ä¸ºSuccessï¼Œå®é™…ä¸º%s", finalStatus)
	}

	// ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œç¡®ä¿æ‰€æœ‰Handleræ‰§è¡Œå®Œæˆ
	time.Sleep(1 * time.Second)

	// éªŒè¯å¹¶æ‰“å°ä¿å­˜çš„æ•°æ®
	savedData := repo.GetSavedData()
	if len(savedData) == 0 {
		t.Fatal("æœªä¿å­˜ä»»ä½•æ•°æ®")
	}

	// ç»Ÿè®¡å„ç±»å‹æ•°æ®æ•°é‡
	dataCountByType := make(map[string]int)
	for _, data := range savedData {
		if dataType, ok := data["type"].(string); ok {
			dataCountByType[dataType]++
		}
	}

	log.Printf("âœ… [æ•°æ®éªŒè¯] å…±ä¿å­˜ %d æ¡æ•°æ®", len(savedData))
	log.Printf("ğŸ“Š [æ•°æ®ç»Ÿè®¡] trade_cal=%d, stock_basic=%d, daily=%d, adj_factor=%d",
		dataCountByType["trade_cal"],
		dataCountByType["stock_basic"],
		dataCountByType["daily"],
		dataCountByType["adj_factor"])

	// éªŒè¯æ•°æ®æ•°é‡æ˜¯å¦ç¬¦åˆé¢„æœŸï¼š20æ¡ï¼ˆ5 trade_cal + 5 stock_basic + 5 daily + 5 adj_factorï¼‰
	expectedCount := ExpectedTotalDataCountWithDynamicTasks

	log.Printf("ğŸ“Š [æ•°é‡éªŒè¯] å½“å‰æ•°æ®: %d æ¡, é¢„æœŸ: %d æ¡ï¼ˆ5 trade_cal + 5 stock_basic + 5 daily + 5 adj_factorï¼‰",
		len(savedData), expectedCount)

	if len(savedData) != expectedCount {
		t.Errorf("æ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=%d, å®é™…=%d", expectedCount, len(savedData))
	} else {
		log.Printf("âœ… [æ•°é‡éªŒè¯] æ•°æ®æ•°é‡ç¬¦åˆé¢„æœŸ: %d æ¡", expectedCount)
	}

	// éªŒè¯å„ç±»å‹æ•°æ®æ•°é‡
	if dataCountByType["trade_cal"] != 5 {
		t.Errorf("trade_calæ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=5, å®é™…=%d", dataCountByType["trade_cal"])
	}
	if dataCountByType["stock_basic"] != 5 {
		t.Errorf("stock_basicæ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=5, å®é™…=%d", dataCountByType["stock_basic"])
	}
	if dataCountByType["daily"] != 5 {
		t.Errorf("dailyæ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=5, å®é™…=%d", dataCountByType["daily"])
	}
	if dataCountByType["adj_factor"] != 5 {
		t.Errorf("adj_factoræ•°æ®æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=5, å®é™…=%d", dataCountByType["adj_factor"])
	}

	// éªŒè¯ä»»åŠ¡å®ä¾‹ï¼šåº”è¯¥åŒ…å«çˆ¶ä»»åŠ¡å’Œæ‰€æœ‰å­ä»»åŠ¡
	ctxVerify := context.Background()
	taskInstances, err := taskRepo.GetByWorkflowInstanceID(ctxVerify, instanceID)
	if err != nil {
		t.Logf("âš ï¸ æ— æ³•æŸ¥è¯¢ä»»åŠ¡å®ä¾‹: %v", err)
	} else {
		// ç»Ÿè®¡ä»»åŠ¡æ•°é‡
		taskCount := len(taskInstances)
		expectedTaskCount := 2 + ExpectedDailySubTaskCount + ExpectedAdjFactorSubTaskCount // 2ä¸ªçˆ¶ä»»åŠ¡ + 5ä¸ªdailyå­ä»»åŠ¡ + 5ä¸ªadj_factorå­ä»»åŠ¡
		if taskCount != expectedTaskCount {
			t.Errorf("ä»»åŠ¡å®ä¾‹æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=%dï¼ˆ2ä¸ªçˆ¶ä»»åŠ¡ + %dä¸ªå­ä»»åŠ¡ï¼‰, å®é™…=%d", expectedTaskCount, ExpectedDailySubTaskCount+ExpectedAdjFactorSubTaskCount, taskCount)
		} else {
			log.Printf("âœ… [ä»»åŠ¡å®ä¾‹éªŒè¯] ä»»åŠ¡æ•°é‡ç¬¦åˆé¢„æœŸ: %d ä¸ªï¼ˆåŒ…å« %d ä¸ªå­ä»»åŠ¡ï¼‰", taskCount, ExpectedDailySubTaskCount+ExpectedAdjFactorSubTaskCount)
		}

		// ç»Ÿè®¡å­ä»»åŠ¡æ•°é‡
		dailySubTaskCount := 0
		adjFactorSubTaskCount := 0
		for _, taskInstance := range taskInstances {
			if strings.HasPrefix(taskInstance.Name, "è·å–æ—¥çº¿æ•°æ®_") {
				dailySubTaskCount++
			} else if strings.HasPrefix(taskInstance.Name, "è·å–å¤æƒå› å­_") {
				adjFactorSubTaskCount++
			}
			// éªŒè¯æ‰€æœ‰ä»»åŠ¡éƒ½æˆåŠŸå®Œæˆ
			if taskInstance.Status != "Success" {
				t.Errorf("ä»»åŠ¡ %s çŠ¶æ€ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=Success, å®é™…=%s", taskInstance.Name, taskInstance.Status)
			}
		}

		// éªŒè¯å­ä»»åŠ¡æ•°é‡
		if dailySubTaskCount != ExpectedDailySubTaskCount {
			t.Errorf("dailyå­ä»»åŠ¡æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=%d, å®é™…=%d", ExpectedDailySubTaskCount, dailySubTaskCount)
		}
		if adjFactorSubTaskCount != ExpectedAdjFactorSubTaskCount {
			t.Errorf("adj_factorå­ä»»åŠ¡æ•°é‡ä¸ç¬¦åˆé¢„æœŸ: æœŸæœ›=%d, å®é™…=%d", ExpectedAdjFactorSubTaskCount, adjFactorSubTaskCount)
		}

		log.Printf("âœ… [å­ä»»åŠ¡éªŒè¯] dailyå­ä»»åŠ¡=%dä¸ª, adj_factorå­ä»»åŠ¡=%dä¸ª", dailySubTaskCount, adjFactorSubTaskCount)
	}

	// éªŒè¯å­—æ®µå®Œæ•´æ€§ï¼šæ£€æŸ¥æ‰€æœ‰ä¿å­˜çš„æ•°æ®æ˜¯å¦åŒ…å«å¿…éœ€çš„å­—æ®µ
	log.Printf("ğŸ” [å­—æ®µå®Œæ•´æ€§éªŒè¯] å¼€å§‹éªŒè¯æ‰€æœ‰æ•°æ®çš„å­—æ®µå®Œæ•´æ€§...")
	dailyIndex := 0
	adjFactorIndex := 0
	tradeCalIndex := 0
	stockBasicIndex := 0
	for i, data := range savedData {
		if dataType, ok := data["type"].(string); ok {
			switch dataType {
			case "daily":
				validateDailyDataFields(t, data, dailyIndex)
				dailyIndex++
			case "adj_factor":
				validateAdjFactorDataFields(t, data, adjFactorIndex)
				adjFactorIndex++
			case "trade_cal":
				validateTradeCalDataFields(t, data, tradeCalIndex)
				tradeCalIndex++
			case "stock_basic":
				validateStockBasicDataFields(t, data, stockBasicIndex)
				stockBasicIndex++
			default:
				t.Logf("âš ï¸ æœªçŸ¥æ•°æ®ç±»å‹: %s (æ•°æ®ç´¢å¼•: %d)", dataType, i)
			}
		}
	}
	log.Printf("âœ… [å­—æ®µå®Œæ•´æ€§éªŒè¯] å®Œæˆï¼ŒéªŒè¯äº† %d æ¡ daily æ•°æ®ï¼Œ%d æ¡ adj_factor æ•°æ®ï¼Œ%d æ¡ trade_cal æ•°æ®ï¼Œ%d æ¡ stock_basic æ•°æ®",
		dailyIndex, adjFactorIndex, tradeCalIndex, stockBasicIndex)

	// æ‰“å°æ‰€æœ‰ä¿å­˜çš„æ•°æ®
	separator := strings.Repeat("=", 80)
	log.Printf("\n%s", separator)
	log.Printf("ğŸ“Š [æœ€ç»ˆä¿å­˜çš„æ•°æ®] (é¢„æœŸ: %d æ¡, å®é™…: %d æ¡)", expectedCount, len(savedData))
	log.Printf("%s", separator)
	for i, data := range savedData {
		log.Printf("\n[æ•°æ® %d/%d]", i+1, len(savedData))
		if dataType, ok := data["type"].(string); ok {
			log.Printf("  ç±»å‹: %s", dataType)
		}
		// å®Œæ•´æ‰“å°æ‰€æœ‰å­—æ®µ
		for k, v := range data {
			if k != "type" {
				log.Printf("  %s: %v", k, v)
			}
		}
	}
	log.Printf("%s\n", separator)
}
