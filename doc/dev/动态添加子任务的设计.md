# 动态子任务生成/添加：业务规则 + 技术实现

结合量化数据下载场景（如 `pro_bar` 父任务生成交易日维度子任务），以下完整阐述**动态子任务生成/添加的业务规则**，以及**DAG拓扑自动调整的技术实现细节**，核心解决「子任务插入后DAG依赖关系重构」的核心诉求。

## 一、核心业务规则（动态子任务生成/添加）

### 1. 子任务生成触发规则（什么时候生成）

子任务仅在**父容器Task运行阶段（Run方法执行时）** 触发生成，满足以下前置条件：

| 触发条件           | 说明                                                                  | 示例（pro_bar场景）                                                         |
| ------------------ | --------------------------------------------------------------------- | --------------------------------------------------------------------------- |
| 父任务依赖校验通过 | 父任务的上游依赖（如trade_cal/stock_basic）已执行完成，且依赖数据可用 | pro_bar父任务确认trade_cal的交易日列表、stock_basic的股票代码列表已存入存储 |
| 用户参数合法       | 父任务接收的用户参数（如日期范围、市场）符合API元数据的参数规则       | 用户指定的start_date/end_date格式为YYYYMMDD，且在trade_cal的有效范围内      |
| 未触发缓存短路     | 未命中「全量数据缓存」（避免重复生成子任务）                          | 缓存中无pro_bar 20250101-20250131的全量数据，需生成子任务                   |

### 2. 子任务生成规则（生成什么样的子任务）

子任务的生成遵循「**维度拆分 + 粒度最小化**」原则，确保单个子任务职责单一、可独立重试/补偿：

| 生成规则             | 量化场景示例                                                                                                                                 |
| -------------------- | -------------------------------------------------------------------------------------------------------------------------------------------- |
| 基于依赖数据拆分维度 | 父任务（pro_bar）基于trade_cal的 `trade_date` + stock_basic的 `stock_code`双维度拆分，每个子任务对应「单交易日+单股票」的pro_bar数据下载 |
| 子任务参数完全注入   | 子任务参数 = 父任务用户参数（日期范围） + 拆分维度参数（trade_date/stock_code） + 固定参数（API Key/字段列表）                               |
| 子任务ID唯一化       | 子任务ID =`父任务ID + _sub + 维度值`（如 `task_pro_bar_sub_20250101_000001`），避免冲突                                                  |
| 子任务并发限制       | 按「批次大小（batchSize）」控制生成的子任务并发数，避免压垮API/存储                                                                          |

### 3. 子任务添加规则（如何添加到Workflow/DAG）

子任务添加后，**强制重构DAG拓扑**，核心规则如下（核心诉求落地）：

| 核心规则                                          | 可视化示例（pro_bar场景）                                                                                                       |
| ------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------- |
| 规则1：子任务作为独立节点插入到父任务之后         | 原DAG：`trade_cal → pro_bar（父） → index` `<br>` 插入后：`trade_cal → pro_bar（父） → pro_bar_sub_20250101 → index` |
| 规则2：子任务强依赖父任务                         | 父任务执行失败/未执行时，所有子任务无法启动                                                                                     |
| 规则3：原依赖父任务的下游节点，改为依赖所有子任务 | 原 `index`依赖 `pro_bar（父）` → 改为 `index`依赖 `pro_bar_sub_20250101`/`pro_bar_sub_20250102`等所有子任务          |
| 规则4：子任务间无依赖（同层级并行）               | 同批次子任务（如不同交易日的pro_bar子任务）之间无依赖，可并发执行                                                               |
| 规则5：子任务执行结果关联父任务状态               | 父任务状态 = 子任务执行结果的「聚合判断」（如90%子任务成功则父任务成功）                                                        |

### 4. 子任务补偿规则

| 补偿规则                     | 说明                                                                            |
| ---------------------------- | ------------------------------------------------------------------------------- |
| 子任务独立补偿               | 单个子任务失败，仅补偿该子任务（如删除单交易日的pro_bar数据），不影响其他子任务 |
| 父任务补偿触发全量子任务补偿 | 父任务触发补偿时，遍历所有生成的子任务执行补偿逻辑                              |
| 子任务补偿不影响DAG拓扑      | 补偿仅修改任务状态，不调整DAG节点/依赖关系                                      |

## 二、技术实现细节（核心模块+算法）

### 1. 核心数据结构扩展（支持DAG动态调整）

首先扩展Workflow/DAG的核心结构体，支持节点的动态增删和依赖关系修改：

```go
// qdhub/internal/engine/core/workflow.go
package core

// Node DAG节点（兼容父任务/子任务）
type Node struct {
	ID           string            // 节点ID（父任务/子任务ID）
	Type         string            // 节点类型（parent/sub）
	ParentID     string            // 父任务ID（子任务特有）
	Status       TaskStatus        // 执行状态
	Deps         []string          // 依赖的节点ID
	Downstreams  []string          // 下游依赖的节点ID（关键：快速定位父任务的下游）
	Task         SagaStep          // 关联的Task实例
}

// DAG Workflow的有向无环图（支持动态调整）
type DAG struct {
	Nodes       map[string]*Node   // 节点注册表（ID→Node）
	TopoOrder   []string           // 拓扑排序结果（执行顺序）
}

// Workflow 扩展Workflow，关联动态DAG
type Workflow struct {
	ID          string
	Name        string
	DAG         *DAG               // 动态DAG（核心）
	// 其他原有字段...
}

// 初始化DAG
func NewDAG() *DAG {
	return &DAG{
		Nodes:      make(map[string]*Node),
		TopoOrder:  []string{},
	}
}
```

### 2. 子任务生成器（接口化，适配不同API）

设计通用子任务生成器接口，不同API（pro_bar/index）实现各自的生成逻辑：

```go
// qdhub/internal/task/sub_task_generator.go
package task

import (
	"context"
	"fmt"

	"github.com/your-username/qdhub/internal/engine/core"
	"github.com/your-username/qdhub/internal/meta"
)

// SubTaskGenerator 子任务生成器接口
type SubTaskGenerator interface {
	// Generate 生成子任务（返回子任务列表+子任务Node）
	Generate(
		ctx context.Context,
		parentTask core.SagaStep,       // 父任务实例
		parentNodeID string,            // 父任务Node ID
		depData map[string]interface{}, // 父任务的依赖数据（如trade_cal的交易日列表）
		userParams map[string]interface{}, // 用户参数
	) ([]core.SagaStep, []*core.Node, error)
}

// ProBarSubTaskGenerator pro_bar子任务生成器（实现接口）
type ProBarSubTaskGenerator struct{}

func (g *ProBarSubTaskGenerator) Generate(
	ctx context.Context,
	parentTask core.SagaStep,
	parentNodeID string,
	depData map[string]interface{},
	userParams map[string]interface{},
) ([]core.SagaStep, []*core.Node, error) {
	// 1. 提取依赖数据（trade_date列表 + stock_code列表）
	tradeDates, ok := depData["trade_dates"].([]string)
	if !ok {
		return nil, nil, fmt.Errorf("缺失trade_dates依赖数据")
	}
	stockCodes, ok := depData["stock_codes"].([]string)
	if !ok {
		return nil, nil, fmt.Errorf("缺失stock_codes依赖数据")
	}

	// 2. 生成子任务实例 + Node（单交易日+单股票）
	subTasks := make([]core.SagaStep, 0)
	subNodes := make([]*core.Node, 0)
	for _, tradeDate := range tradeDates {
		for _, stockCode := range stockCodes {
			// 2.1 生成子任务ID（唯一化）
			subTaskID := fmt.Sprintf("%s_sub_%s_%s", parentNodeID, tradeDate, stockCode)
			// 2.2 创建子任务实例（ProBarSubTask）
			subTask := NewProBarSubTask(
				parentTask.(*ProBarContainerTask).GetAPIKey(),
				tradeDate,
				stockCode,
				parentTask.(*ProBarContainerTask).GetStorage(),
			)
			subTasks = append(subTasks, subTask)

			// 2.3 创建子任务Node（核心：设置依赖为父任务）
			subNode := &core.Node{
				ID:          subTaskID,
				Type:        "sub",
				ParentID:    parentNodeID,
				Status:      core.TaskStatusPending,
				Deps:        []string{parentNodeID}, // 规则2：子任务依赖父任务
				Downstreams: []string{},             // 初始无下游，后续调整
				Task:        subTask,
			}
			subNodes = append(subNodes, subNode)
		}
	}

	return subTasks, subNodes, nil
}
```

### 3. 核心算法：DAG拓扑动态调整（子任务插入）

这是实现「子任务添加后重构DAG」的核心，算法步骤清晰可落地：

```go
// qdhub/internal/engine/core/dag_adjuster.go
package core

import (
	"fmt"
	"sort"
)

// InsertSubNodes 插入子任务节点并重构DAG（核心算法）
func (d *DAG) InsertSubNodes(parentNodeID string, subNodes []*Node) error {
	// 步骤1：校验父节点存在
	parentNode, exists := d.Nodes[parentNodeID]
	if !exists {
		return fmt.Errorf("父节点%s不存在", parentNodeID)
	}

	// 步骤2：获取父节点的下游节点（原依赖父节点的节点）
	parentDownstreams := parentNode.Downstreams
	if len(parentDownstreams) == 0 {
		// 父节点无下游：直接插入子节点到父节点后
		d.insertSubNodesWithoutDownstream(parentNode, subNodes)
	} else {
		// 父节点有下游：重构依赖关系（规则3）
		d.insertSubNodesWithDownstream(parentNode, subNodes, parentDownstreams)
	}

	// 步骤3：重新执行拓扑排序（更新执行顺序）
	newTopoOrder, err := d.reTopologize()
	if err != nil {
		return fmt.Errorf("重新拓扑排序失败：%v", err)
	}
	d.TopoOrder = newTopoOrder

	return nil
}

// 场景1：父节点无下游（直接插入子节点）
func (d *DAG) insertSubNodesWithoutDownstream(parentNode *Node, subNodes []*Node) {
	// 1. 注册子节点到DAG
	for _, subNode := range subNodes {
		d.Nodes[subNode.ID] = subNode
	}

	// 2. 更新父节点的下游为所有子节点
	parentNode.Downstreams = make([]string, 0, len(subNodes))
	for _, subNode := range subNodes {
		parentNode.Downstreams = append(parentNode.Downstreams, subNode.ID)
	}
}

// 场景2：父节点有下游（重构依赖关系，核心：规则3）
func (d *DAG) insertSubNodesWithDownstream(parentNode *Node, subNodes []*Node, parentDownstreams []string) {
	// 步骤1：注册子节点到DAG
	subNodeIDs := make([]string, 0, len(subNodes))
	for _, subNode := range subNodes {
		d.Nodes[subNode.ID] = subNode
		subNodeIDs = append(subNodeIDs, subNode.ID)
	}

	// 步骤2：父节点的下游改为子节点（规则1：子节点在父节点后）
	parentNode.Downstreams = subNodeIDs

	// 步骤3：原下游节点的依赖改为子节点（规则3：原依赖父的节点→依赖子）
	for _, downstreamID := range parentDownstreams {
		downstreamNode := d.Nodes[downstreamID]
		// 移除下游节点对父节点的依赖
		newDeps := make([]string, 0)
		for _, dep := range downstreamNode.Deps {
			if dep != parentNode.ID {
				newDeps = append(newDeps, dep)
			}
		}
		// 添加下游节点对所有子节点的依赖
		newDeps = append(newDeps, subNodeIDs...)
		downstreamNode.Deps = newDeps

		// 更新子节点的下游为原下游节点
		for _, subNode := range subNodes {
			subNode.Downstreams = append(subNode.Downstreams, downstreamID)
		}
	}
}

// 重新拓扑排序（基于调整后的DAG）
func (d *DAG) reTopologize() ([]string, error) {
	// 算法：Kahn算法（处理有向无环图的拓扑排序）
	inDegree := make(map[string]int) // 入度表
	queue := []string{}              // 入度为0的节点队列
	result := []string{}             // 拓扑排序结果

	// 初始化入度表
	for nodeID, node := range d.Nodes {
		inDegree[nodeID] = len(node.Deps)
		if inDegree[nodeID] == 0 {
			queue = append(queue, nodeID)
		}
	}

	// 执行Kahn算法
	for len(queue) > 0 {
		// 取出队首节点
		currNodeID := queue[0]
		queue = queue[1:]
		result = append(result, currNodeID)

		// 遍历当前节点的下游，入度-1
		currNode := d.Nodes[currNodeID]
		for _, downstreamID := range currNode.Downstreams {
			inDegree[downstreamID]--
			if inDegree[downstreamID] == 0 {
				queue = append(queue, downstreamID)
			}
		}
	}

	// 校验是否有环（拓扑排序结果长度≠节点数）
	if len(result) != len(d.Nodes) {
		return nil, fmt.Errorf("DAG存在环，拓扑排序失败")
	}

	return result, nil
}
```

### 4. 父任务中触发子任务生成+DAG调整（完整链路）

在父容器Task的 `Run`方法中，集成「依赖数据获取→子任务生成→DAG调整→子任务执行」的完整逻辑：

```go
// qdhub/internal/task/pro_bar_container_task.go
package task

import (
	"context"
	"fmt"

	"github.com/your-username/qdhub/internal/engine/core"
	"github.com/your-username/qdhub/internal/meta"
	"github.com/your-username/qdhub/internal/storage"
)

func (t *ProBarContainerTask) Run(ctx context.Context) (bool, map[string]interface{}, error) {
	// 步骤1：触发父任务开始钩子
	t.hookManager.TriggerHook(ctx, HookTypeTaskStart, map[string]interface{}{
		"parent_task_id": t.SagaStepID(),
	})

	// 步骤2：获取父任务的依赖数据（trade_cal + stock_basic）
	depData := make(map[string]interface{})
	// 2.1 获取trade_cal的交易日列表
	tradeCalData, err := t.storage.GetDependencyData(ctx, meta.APIIDTradeCal)
	if err != nil {
		return false, nil, fmt.Errorf("获取trade_cal依赖数据失败：%v", err)
	}
	depData["trade_dates"] = tradeCalData["trade_dates"]
	// 2.2 获取stock_basic的股票代码列表
	stockBasicData, err := t.storage.GetDependencyData(ctx, meta.APIIDStockBasic)
	if err != nil {
		return false, nil, fmt.Errorf("获取stock_basic依赖数据失败：%v", err)
	}
	depData["stock_codes"] = stockBasicData["stock_codes"]

	// 步骤3：生成子任务实例 + Node
	generator := &ProBarSubTaskGenerator{}
	subTasks, subNodes, err := generator.Generate(
		ctx,
		t,
		t.SagaStepID(),
		depData,
		t.UserParams,
	)
	if err != nil {
		return false, nil, fmt.Errorf("生成子任务失败：%v", err)
	}
	t.SetSubTasks(subTasks) // 父任务保存子任务列表

	// 步骤4：动态调整Workflow的DAG（核心）
	workflow := ctx.Value("current_workflow").(*core.Workflow) // 从上下文获取当前Workflow
	if err := workflow.DAG.InsertSubNodes(t.SagaStepID(), subNodes); err != nil {
		return false, nil, fmt.Errorf("调整DAG失败：%v", err)
	}

	// 步骤5：执行子任务（按新的拓扑顺序）
	if err := t.executeSubTasks(ctx, workflow.DAG); err != nil {
		return false, nil, fmt.Errorf("执行子任务失败：%v", err)
	}

	// 步骤6：汇总子任务结果 + 判断父任务状态
	summary, err := t.collectSubTaskResults(ctx)
	if err != nil {
		return false, nil, fmt.Errorf("汇总子任务结果失败：%v", err)
	}

	// 步骤7：触发父任务成功钩子
	t.hookManager.TriggerHook(ctx, HookTypeTaskSuccess, map[string]interface{}{
		"parent_task_id": t.SagaStepID(),
		"summary":        summary,
	})

	return true, summary, nil
}

// 执行子任务（按新的拓扑顺序）
func (t *ProBarContainerTask) executeSubTasks(ctx context.Context, dag *core.DAG) error {
	// 从拓扑排序中筛选出当前父任务的子任务
	subTaskIDs := make([]string, 0)
	for _, nodeID := range dag.TopoOrder {
		node := dag.Nodes[nodeID]
		if node.ParentID == t.SagaStepID() {
			subTaskIDs = append(subTaskIDs, nodeID)
		}
	}

	// 并发执行子任务（控制batchSize）
	sem := make(chan struct{}, t.BatchSize)
	var wg sync.WaitGroup
	var errMu sync.Mutex
	var executeErr error

	for _, subTaskID := range subTaskIDs {
		sem <- struct{}{}
		wg.Add(1)

		go func(subNodeID string) {
			defer func() {
				<-sem
				wg.Done()
			}()

			subNode := dag.Nodes[subNodeID]
			subTask := subNode.Task
			// 执行子任务Run方法
			success, _, err := subTask.Run(ctx)
			if err != nil || !success {
				errMu.Lock()
				executeErr = fmt.Errorf("子任务%s执行失败：%v", subNodeID, err)
				errMu.Unlock()
				// 更新子节点状态
				subNode.Status = core.TaskStatusFailed
				return
			}

			// 更新子节点状态
			subNode.Status = core.TaskStatusSuccess
		}(subTaskID)
	}

	wg.Wait()
	close(sem)

	return executeErr
}
```

### 5. 关键补充：子任务生成后的状态联动

#### （1）父任务状态聚合逻辑

```go
// 汇总子任务结果，判断父任务状态
func (t *ProBarContainerTask) collectSubTaskResults(ctx context.Context) (map[string]interface{}, error) {
	total := len(t.GetSubTasks())
	success := 0
	failed := 0

	for _, subTask := range t.GetSubTasks() {
		subNodeID := subTask.SagaStepID()
		subNode := t.Workflow().DAG.Nodes[subNodeID]
		if subNode.Status == core.TaskStatusSuccess {
			success++
		} else {
			failed++
		}
	}

	successRate := float64(success) / float64(total)
	parentStatus := core.TaskStatusSuccess
	if successRate < t.SuccessThreshold { // 如90%成功率阈值
		parentStatus = core.TaskStatusFailed
	}

	// 更新父节点状态
	parentNode := t.Workflow().DAG.Nodes[t.SagaStepID()]
	parentNode.Status = parentStatus

	summary := map[string]interface{}{
		"total_sub_tasks": total,
		"success":         success,
		"failed":          failed,
		"success_rate":    successRate,
		"parent_status":   parentStatus,
	}

	return summary, nil
}
```

#### （2）子任务补偿的DAG适配

```go
// 父任务补偿：遍历子任务执行补偿
func (t *ProBarContainerTask) Compensate(ctx context.Context) error {
	workflow := ctx.Value("current_workflow").(*core.Workflow)
	// 筛选父任务的子任务
	for _, nodeID := range workflow.DAG.TopoOrder {
		node := workflow.DAG.Nodes[nodeID]
		if node.ParentID == t.SagaStepID() && node.Status == core.TaskStatusSuccess {
			// 执行子任务补偿
			if err := node.Task.Compensate(ctx); err != nil {
				fmt.Printf("子任务%s补偿失败：%v\n", nodeID, err)
			}
			// 更新子节点状态为已补偿
			node.Status = core.TaskStatusCompensated
		}
	}
	return nil
}
```

## 三、DAG调整前后对比示例（可视化）

### 1. 调整前（子任务未生成）

```
DAG节点：trade_cal → stock_basic → pro_bar（父） → index
拓扑顺序：trade_cal → stock_basic → pro_bar → index
依赖关系：
- pro_bar依赖：trade_cal、stock_basic
- index依赖：pro_bar
```

### 2. 调整后（生成2个pro_bar子任务）

```
DAG节点：trade_cal → stock_basic → pro_bar（父） → pro_bar_sub_20250101 → pro_bar_sub_20250102 → index
拓扑顺序：trade_cal → stock_basic → pro_bar → pro_bar_sub_20250101 → pro_bar_sub_20250102 → index
依赖关系：
- pro_bar依赖：trade_cal、stock_basic
- pro_bar_sub_20250101依赖：pro_bar
- pro_bar_sub_20250102依赖：pro_bar
- index依赖：pro_bar_sub_20250101、pro_bar_sub_20250102
```

## 四、技术实现关键点总结

| 关键点         | 实现核心                                   | 解决的问题                                 |
| -------------- | ------------------------------------------ | ------------------------------------------ |
| 子任务ID唯一化 | 父任务ID + 维度值（trade_date+stock_code） | 避免子任务ID冲突                           |
| DAG下游缓存    | 父节点维护Downstreams字段                  | 快速定位原依赖父任务的节点，减少遍历开销   |
| Kahn算法重排序 | 基于入度的拓扑排序                         | 保证子任务插入后DAG无环，执行顺序正确      |
| 并发控制       | 带缓冲的通道（sem）                        | 控制子任务并发数，避免压垮API/存储         |
| 状态联动       | 父节点聚合子节点状态                       | 父任务状态与子任务执行结果强关联           |
| 钩子解耦       | 子任务生命周期钩子                         | 附加逻辑（日志/告警）不侵入核心DAG调整逻辑 |

## 五、异常处理边界

1. **子任务生成失败**：直接终止父任务，触发父任务失败钩子，DAG不调整；
2. **DAG调整失败（有环）**：回滚子任务生成，恢复原DAG结构，父任务失败；
3. **部分子任务执行失败**：按成功率阈值判断父任务状态，失败子任务触发独立补偿；
4. **子任务执行超时**：标记为失败，计入父任务成功率统计，支持子任务独立重试。

这套实现完全落地了你提出的核心诉求：**子任务动态生成后成为独立DAG节点、插入父任务后、原父任务的下游依赖改为依赖子任务**，同时兼顾量化数据下载的业务特性（维度拆分、并发执行、状态聚合）。
