// Package e2e æä¾›ç«¯åˆ°ç«¯æµ‹è¯•
// æœ¬æ–‡ä»¶æµ‹è¯•ä¸Šä¸‹æ¸¸å‚æ•°ä¼ é€’ API çš„å®Œæ•´å·¥ä½œæµ
package e2e

import (
	"context"
	"fmt"
	"os"
	"path/filepath"
	"sync"
	"testing"
	"time"

	_ "github.com/mattn/go-sqlite3"

	"github.com/LENAX/task-engine/internal/storage/sqlite"
	"github.com/LENAX/task-engine/pkg/core/builder"
	"github.com/LENAX/task-engine/pkg/core/engine"
	"github.com/LENAX/task-engine/pkg/core/task"
	"github.com/LENAX/task-engine/pkg/core/types"
	"github.com/LENAX/task-engine/pkg/core/workflow"
)

// TestE2E_UpstreamResultPassing_StockDataPipeline æµ‹è¯•å®Œæ•´çš„è‚¡ç¥¨æ•°æ®å¤„ç†ç®¡é“
// åœºæ™¯ï¼š
// 1. FetchStockList - è·å–è‚¡ç¥¨åˆ—è¡¨
// 2. FetchDailyData (æ¨¡æ¿ä»»åŠ¡) - ä¸ºæ¯ä¸ªè‚¡ç¥¨ç”Ÿæˆå­ä»»åŠ¡è·å–æ—¥çº¿æ•°æ®
// 3. AggregateData - ä½¿ç”¨æ–° API è·å–æ‰€æœ‰å­ä»»åŠ¡ç»“æœå¹¶èšåˆ
func TestE2E_UpstreamResultPassing_StockDataPipeline(t *testing.T) {
	// è®¾ç½®æµ‹è¯•ç¯å¢ƒ
	dataDir := filepath.Join(os.TempDir(), "task-engine-e2e-upstream", time.Now().Format("20060102150405"))
	os.MkdirAll(dataDir, 0755)
	dbPath := filepath.Join(dataDir, "test.db")

	repos, err := sqlite.NewRepositories(dbPath)
	if err != nil {
		t.Fatalf("åˆ›å»º Repository å¤±è´¥: %v", err)
	}
	defer repos.Close()

	eng, err := engine.NewEngine(10, 30, repos.Workflow, repos.WorkflowInstance, repos.Task)
	if err != nil {
		t.Fatalf("åˆ›å»º Engine å¤±è´¥: %v", err)
	}

	ctx := context.Background()
	if err := eng.Start(ctx); err != nil {
		t.Fatalf("å¯åŠ¨ Engine å¤±è´¥: %v", err)
	}
	defer eng.Stop()

	registry := eng.GetRegistry()

	// ç»“æœæ•è·
	var capturedStockCodes []string
	var capturedDailyDataCount int
	var capturedAllSucceeded bool
	var capturedAggregatedData []map[string]interface{}
	capturedMutex := sync.Mutex{}

	// ========== æ³¨å†Œ Job Functions ==========

	// 1. è·å–è‚¡ç¥¨åˆ—è¡¨
	fetchStockListFunc := func(tc *task.TaskContext) (interface{}, error) {
		// æ¨¡æ‹Ÿè·å–è‚¡ç¥¨åˆ—è¡¨
		stockCodes := []string{"000001.SZ", "000002.SZ", "600000.SH", "600036.SH", "601398.SH"}
		t.Logf("ğŸ“Š [FetchStockList] è·å–åˆ° %d åªè‚¡ç¥¨", len(stockCodes))

		return map[string]interface{}{
			"stock_codes": stockCodes,
			"count":       len(stockCodes),
			"source":      "mock",
		}, nil
	}
	registry.Register(ctx, "fetchStockListFunc", fetchStockListFunc, "è·å–è‚¡ç¥¨åˆ—è¡¨")

	// 2. æ¨¡æ¿ä»»åŠ¡ - ç”Ÿæˆæ—¥çº¿æ•°æ®å­ä»»åŠ¡
	fetchDailyTemplateFunc := func(tc *task.TaskContext) (interface{}, error) {
		// ä½¿ç”¨æ–° API è·å–ä¸Šæ¸¸ç»“æœ
		stockCodes := tc.GetUpstreamStringSlice("FetchStockList", "stock_codes")
		if len(stockCodes) == 0 {
			return nil, fmt.Errorf("æœªè·å–åˆ°è‚¡ç¥¨ä»£ç åˆ—è¡¨")
		}

		capturedMutex.Lock()
		capturedStockCodes = stockCodes
		capturedMutex.Unlock()

		t.Logf("ğŸ“Š [FetchDailyTemplate] ä½¿ç”¨æ–° API è·å–åˆ° %d åªè‚¡ç¥¨: %v", len(stockCodes), stockCodes)

		// è·å– InstanceManager æ·»åŠ å­ä»»åŠ¡
		type ManagerInterface interface {
			AtomicAddSubTasks(subTasks []types.Task, parentTaskID string) error
		}
		managerRaw := tc.GetInstanceManager()
		if managerRaw == nil {
			return nil, fmt.Errorf("æ— æ³•è·å– InstanceManager")
		}
		manager := managerRaw.(ManagerInterface)

		// ä¸ºæ¯ä¸ªè‚¡ç¥¨ç”Ÿæˆå­ä»»åŠ¡
		subTasks := make([]types.Task, 0, len(stockCodes))
		for i, code := range stockCodes {
			subTask, err := builder.NewTaskBuilder(
				fmt.Sprintf("fetch-daily-%d", i),
				fmt.Sprintf("è·å– %s æ—¥çº¿æ•°æ®", code),
				registry,
			).
				WithJobFunction("fetchDailySubFunc", map[string]interface{}{
					"stock_code": code,
					"index":      i,
				}).
				Build()
			if err != nil {
				continue
			}
			subTasks = append(subTasks, subTask)
		}

		if err := manager.AtomicAddSubTasks(subTasks, tc.TaskID); err != nil {
			return nil, fmt.Errorf("æ·»åŠ å­ä»»åŠ¡å¤±è´¥: %v", err)
		}

		t.Logf("ğŸ“Š [FetchDailyTemplate] ç”Ÿæˆ %d ä¸ªå­ä»»åŠ¡", len(subTasks))

		return map[string]interface{}{
			"generated_count": len(subTasks),
		}, nil
	}
	registry.Register(ctx, "fetchDailyTemplateFunc", fetchDailyTemplateFunc, "ç”Ÿæˆæ—¥çº¿æ•°æ®å­ä»»åŠ¡")

	// 3. å­ä»»åŠ¡ - è·å–å•åªè‚¡ç¥¨æ—¥çº¿æ•°æ®
	fetchDailySubFunc := func(tc *task.TaskContext) (interface{}, error) {
		stockCode := tc.GetParamString("stock_code")
		index, _ := tc.GetParamInt("index")

		// æ¨¡æ‹Ÿè·å–æ—¥çº¿æ•°æ®
		dailyData := map[string]interface{}{
			"stock_code": stockCode,
			"open":       10.5 + float64(index)*0.1,
			"close":      10.8 + float64(index)*0.1,
			"high":       11.0 + float64(index)*0.1,
			"low":        10.2 + float64(index)*0.1,
			"volume":     1000000 + index*100000,
			"trade_date": "20251220",
		}

		t.Logf("ğŸ“Š [FetchDailySub] è·å– %s æ—¥çº¿æ•°æ®å®Œæˆ", stockCode)

		return map[string]interface{}{
			"daily_data": dailyData,
		}, nil
	}
	registry.Register(ctx, "fetchDailySubFunc", fetchDailySubFunc, "è·å–å•åªè‚¡ç¥¨æ—¥çº¿æ•°æ®")

	// 4. èšåˆä»»åŠ¡ - ä½¿ç”¨æ–° API è·å–æ‰€æœ‰å­ä»»åŠ¡ç»“æœ
	aggregateDataFunc := func(tc *task.TaskContext) (interface{}, error) {
		// ä½¿ç”¨æ–° API è·å–å­ä»»åŠ¡ç»“æœ
		allResults := tc.GetSubTaskResults()
		successResults := tc.GetSuccessfulSubTaskResults()
		allSucceeded := tc.AllSubTasksSucceeded()
		subtaskCount := tc.GetSubTaskCount()

		t.Logf("ğŸ“Š [AggregateData] ä½¿ç”¨æ–° API:")
		t.Logf("   - å­ä»»åŠ¡æ€»æ•°: %d", subtaskCount)
		t.Logf("   - æ‰€æœ‰ç»“æœæ•°: %d", len(allResults))
		t.Logf("   - æˆåŠŸç»“æœæ•°: %d", len(successResults))
		t.Logf("   - å…¨éƒ¨æˆåŠŸ: %v", allSucceeded)

		// ä½¿ç”¨ ExtractMapsFromSubTasks æå– daily_data
		dailyDataMaps := tc.ExtractMapsFromSubTasks("daily_data")
		t.Logf("ğŸ“Š [AggregateData] æå–åˆ° %d æ¡æ—¥çº¿æ•°æ®", len(dailyDataMaps))

		for _, data := range dailyDataMaps {
			t.Logf("   - %s: open=%.2f, close=%.2f",
				data["stock_code"], data["open"], data["close"])
		}

		capturedMutex.Lock()
		capturedDailyDataCount = len(dailyDataMaps)
		capturedAllSucceeded = allSucceeded
		capturedAggregatedData = dailyDataMaps
		capturedMutex.Unlock()

		return map[string]interface{}{
			"aggregated_count": len(dailyDataMaps),
			"all_succeeded":    allSucceeded,
		}, nil
	}
	registry.Register(ctx, "aggregateDataFunc", aggregateDataFunc, "èšåˆæ—¥çº¿æ•°æ®")

	// ========== æ„å»º Workflow ==========
	wf := workflow.NewWorkflow("stock-data-pipeline", "è‚¡ç¥¨æ•°æ®å¤„ç†ç®¡é“")

	// Task 1: è·å–è‚¡ç¥¨åˆ—è¡¨
	task1, _ := builder.NewTaskBuilder("FetchStockList", "è·å–è‚¡ç¥¨åˆ—è¡¨", registry).
		WithJobFunction("fetchStockListFunc", nil).
		Build()

	// Task 2: æ¨¡æ¿ä»»åŠ¡ - ç”Ÿæˆæ—¥çº¿æ•°æ®å­ä»»åŠ¡
	task2, _ := builder.NewTaskBuilder("FetchDailyData", "è·å–æ—¥çº¿æ•°æ®", registry).
		WithJobFunction("fetchDailyTemplateFunc", nil).
		WithDependency("FetchStockList").
		WithTemplate(true).
		Build()

	// Task 3: èšåˆæ•°æ®
	task3, _ := builder.NewTaskBuilder("AggregateData", "èšåˆæ•°æ®", registry).
		WithJobFunction("aggregateDataFunc", nil).
		WithDependency("FetchDailyData").
		Build()

	wf.AddTask(task1)
	wf.AddTask(task2)
	wf.AddTask(task3)

	// ========== æ‰§è¡Œ Workflow ==========
	controller, err := eng.SubmitWorkflow(ctx, wf)
	if err != nil {
		t.Fatalf("æäº¤ Workflow å¤±è´¥: %v", err)
	}

	// ç­‰å¾…å®Œæˆ
	deadline := time.Now().Add(60 * time.Second)
	ticker := time.NewTicker(500 * time.Millisecond)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			if time.Now().After(deadline) {
				t.Fatalf("Workflow æ‰§è¡Œè¶…æ—¶")
			}

			status, err := controller.GetStatus()
			if err != nil {
				continue
			}

			if status == "Success" || status == "Failed" || status == "Completed" {
				t.Logf("ğŸ“Š Workflow å®Œæˆï¼ŒçŠ¶æ€: %s", status)
				goto verify
			}
		}
	}

verify:
	// ========== éªŒè¯ç»“æœ ==========
	capturedMutex.Lock()
	defer capturedMutex.Unlock()

	// éªŒè¯è·å–åˆ°è‚¡ç¥¨ä»£ç 
	if len(capturedStockCodes) != 5 {
		t.Errorf("æœŸæœ›è·å– 5 åªè‚¡ç¥¨ä»£ç ï¼Œå®é™…è·å– %d åª", len(capturedStockCodes))
	}

	// éªŒè¯æ—¥çº¿æ•°æ®èšåˆ
	if capturedDailyDataCount != 5 {
		t.Errorf("æœŸæœ›èšåˆ 5 æ¡æ—¥çº¿æ•°æ®ï¼Œå®é™…èšåˆ %d æ¡", capturedDailyDataCount)
	}

	// éªŒè¯å…¨éƒ¨æˆåŠŸ
	if !capturedAllSucceeded {
		t.Error("æœŸæœ›æ‰€æœ‰å­ä»»åŠ¡æˆåŠŸï¼Œå®é™…æœ‰å¤±è´¥")
	}

	// éªŒè¯èšåˆæ•°æ®å†…å®¹
	if len(capturedAggregatedData) > 0 {
		for _, data := range capturedAggregatedData {
			if data["stock_code"] == nil {
				t.Error("èšåˆæ•°æ®ç¼ºå°‘ stock_code å­—æ®µ")
			}
			if data["close"] == nil {
				t.Error("èšåˆæ•°æ®ç¼ºå°‘ close å­—æ®µ")
			}
		}
	}

	t.Log("âœ… E2E æµ‹è¯•é€šè¿‡ï¼šè‚¡ç¥¨æ•°æ®å¤„ç†ç®¡é“")
}

// TestE2E_UpstreamResultPassing_MultiLevelDependency æµ‹è¯•å¤šå±‚ä¾èµ–çš„å‚æ•°ä¼ é€’
// åœºæ™¯ï¼šA -> B -> Cï¼ŒéªŒè¯ C èƒ½å¦è·å– A å’Œ B çš„ç»“æœ
func TestE2E_UpstreamResultPassing_MultiLevelDependency(t *testing.T) {
	// è®¾ç½®æµ‹è¯•ç¯å¢ƒ
	dataDir := filepath.Join(os.TempDir(), "task-engine-e2e-multi", time.Now().Format("20060102150405"))
	os.MkdirAll(dataDir, 0755)
	dbPath := filepath.Join(dataDir, "test.db")

	repos, err := sqlite.NewRepositories(dbPath)
	if err != nil {
		t.Fatalf("åˆ›å»º Repository å¤±è´¥: %v", err)
	}
	defer repos.Close()

	eng, err := engine.NewEngine(10, 30, repos.Workflow, repos.WorkflowInstance, repos.Task)
	if err != nil {
		t.Fatalf("åˆ›å»º Engine å¤±è´¥: %v", err)
	}

	ctx := context.Background()
	if err := eng.Start(ctx); err != nil {
		t.Fatalf("å¯åŠ¨ Engine å¤±è´¥: %v", err)
	}
	defer eng.Stop()

	registry := eng.GetRegistry()

	// ç»“æœæ•è·
	var capturedFromA string
	var capturedFromB string
	var capturedUpstreamCount int
	capturedMutex := sync.Mutex{}

	// Task A
	taskAFunc := func(tc *task.TaskContext) (interface{}, error) {
		return map[string]interface{}{
			"message": "from_task_A",
			"level":   1,
		}, nil
	}
	registry.Register(ctx, "taskAFunc", taskAFunc, "ä»»åŠ¡A")

	// Task B (ä¾èµ– A)
	taskBFunc := func(tc *task.TaskContext) (interface{}, error) {
		// ä½¿ç”¨æ–° API è·å– A çš„ç»“æœ
		messageFromA := tc.GetUpstreamString("TaskA", "message")
		t.Logf("ğŸ“Š [TaskB] ä» TaskA è·å–: message=%s", messageFromA)

		return map[string]interface{}{
			"message":       "from_task_B",
			"level":         2,
			"received_from": messageFromA,
		}, nil
	}
	registry.Register(ctx, "taskBFunc", taskBFunc, "ä»»åŠ¡B")

	// Task C (ä¾èµ– Bï¼Œé—´æ¥ä¾èµ– A)
	taskCFunc := func(tc *task.TaskContext) (interface{}, error) {
		// ä½¿ç”¨æ–° API è·å–æ‰€æœ‰ä¸Šæ¸¸ç»“æœ
		allUpstream := tc.GetAllUpstreamResults()
		t.Logf("ğŸ“Š [TaskC] è·å–åˆ° %d ä¸ªä¸Šæ¸¸ç»“æœ", len(allUpstream))

		// è·å– B çš„ç»“æœ
		messageFromB := tc.GetUpstreamString("TaskB", "message")
		receivedFromA := tc.GetUpstreamString("TaskB", "received_from")

		t.Logf("ğŸ“Š [TaskC] ä» TaskB è·å–: message=%s, received_from=%s", messageFromB, receivedFromA)

		capturedMutex.Lock()
		capturedFromA = receivedFromA
		capturedFromB = messageFromB
		capturedUpstreamCount = len(allUpstream)
		capturedMutex.Unlock()

		return map[string]interface{}{
			"final_message": fmt.Sprintf("%s -> %s", receivedFromA, messageFromB),
		}, nil
	}
	registry.Register(ctx, "taskCFunc", taskCFunc, "ä»»åŠ¡C")

	// æ„å»º Workflow
	wf := workflow.NewWorkflow("multi-level-test", "å¤šå±‚ä¾èµ–æµ‹è¯•")

	taskA, _ := builder.NewTaskBuilder("TaskA", "ä»»åŠ¡A", registry).
		WithJobFunction("taskAFunc", nil).
		Build()

	taskB, _ := builder.NewTaskBuilder("TaskB", "ä»»åŠ¡B", registry).
		WithJobFunction("taskBFunc", nil).
		WithDependency("TaskA").
		Build()

	taskC, _ := builder.NewTaskBuilder("TaskC", "ä»»åŠ¡C", registry).
		WithJobFunction("taskCFunc", nil).
		WithDependency("TaskB").
		Build()

	wf.AddTask(taskA)
	wf.AddTask(taskB)
	wf.AddTask(taskC)

	// æ‰§è¡Œ
	controller, err := eng.SubmitWorkflow(ctx, wf)
	if err != nil {
		t.Fatalf("æäº¤ Workflow å¤±è´¥: %v", err)
	}

	// ç­‰å¾…å®Œæˆ
	deadline := time.Now().Add(30 * time.Second)
	ticker := time.NewTicker(200 * time.Millisecond)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			if time.Now().After(deadline) {
				t.Fatalf("Workflow æ‰§è¡Œè¶…æ—¶")
			}

			status, _ := controller.GetStatus()
			if status == "Success" || status == "Failed" {
				t.Logf("ğŸ“Š Workflow å®Œæˆï¼ŒçŠ¶æ€: %s", status)
				goto verify
			}
		}
	}

verify:
	capturedMutex.Lock()
	defer capturedMutex.Unlock()

	// éªŒè¯ C æ”¶åˆ°äº† B ä¼ é€’çš„ A çš„æ•°æ®
	if capturedFromA != "from_task_A" {
		t.Errorf("æœŸæœ› capturedFromA='from_task_A'ï¼Œå®é™…ä¸º '%s'", capturedFromA)
	}

	if capturedFromB != "from_task_B" {
		t.Errorf("æœŸæœ› capturedFromB='from_task_B'ï¼Œå®é™…ä¸º '%s'", capturedFromB)
	}

	// C åªç›´æ¥ä¾èµ– Bï¼Œæ‰€ä»¥åªæœ‰ 1 ä¸ªç›´æ¥ä¸Šæ¸¸
	if capturedUpstreamCount < 1 {
		t.Errorf("æœŸæœ›è‡³å°‘ 1 ä¸ªä¸Šæ¸¸ç»“æœï¼Œå®é™…ä¸º %d", capturedUpstreamCount)
	}

	t.Log("âœ… E2E æµ‹è¯•é€šè¿‡ï¼šå¤šå±‚ä¾èµ–å‚æ•°ä¼ é€’")
}

// TestE2E_UpstreamResultPassing_ParallelSubTasks æµ‹è¯•å¹¶è¡Œå­ä»»åŠ¡çš„ç»“æœèšåˆ
// åœºæ™¯ï¼šæ¨¡æ¿ä»»åŠ¡ç”Ÿæˆå¤šä¸ªå¹¶è¡Œå­ä»»åŠ¡ï¼Œéƒ¨åˆ†æˆåŠŸéƒ¨åˆ†å¤±è´¥ï¼ŒéªŒè¯èšåˆç»“æœ
func TestE2E_UpstreamResultPassing_ParallelSubTasks(t *testing.T) {
	// è®¾ç½®æµ‹è¯•ç¯å¢ƒ
	dataDir := filepath.Join(os.TempDir(), "task-engine-e2e-parallel", time.Now().Format("20060102150405"))
	os.MkdirAll(dataDir, 0755)
	dbPath := filepath.Join(dataDir, "test.db")

	repos, err := sqlite.NewRepositories(dbPath)
	if err != nil {
		t.Fatalf("åˆ›å»º Repository å¤±è´¥: %v", err)
	}
	defer repos.Close()

	eng, err := engine.NewEngine(10, 30, repos.Workflow, repos.WorkflowInstance, repos.Task)
	if err != nil {
		t.Fatalf("åˆ›å»º Engine å¤±è´¥: %v", err)
	}

	ctx := context.Background()
	if err := eng.Start(ctx); err != nil {
		t.Fatalf("å¯åŠ¨ Engine å¤±è´¥: %v", err)
	}
	defer eng.Stop()

	registry := eng.GetRegistry()

	// ç»“æœæ•è·
	var capturedSuccessCount int
	var capturedFailedCount int
	var capturedSubTaskCount int
	var capturedAllSucceeded bool
	capturedMutex := sync.Mutex{}

	// æ¨¡æ¿ä»»åŠ¡
	templateFunc := func(tc *task.TaskContext) (interface{}, error) {
		type ManagerInterface interface {
			AtomicAddSubTasks(subTasks []types.Task, parentTaskID string) error
		}
		manager := tc.GetInstanceManager().(ManagerInterface)

		// ç”Ÿæˆ 10 ä¸ªå­ä»»åŠ¡ï¼Œå…¶ä¸­ index=3 å’Œ index=7 ä¼šå¤±è´¥
		subTasks := make([]types.Task, 0, 10)
		for i := 0; i < 10; i++ {
			subTask, _ := builder.NewTaskBuilder(
				fmt.Sprintf("parallel-sub-%d", i),
				fmt.Sprintf("å¹¶è¡Œå­ä»»åŠ¡ %d", i),
				registry,
			).
				WithJobFunction("parallelSubFunc", map[string]interface{}{
					"index": i,
				}).
				Build()
			subTasks = append(subTasks, subTask)
		}

		manager.AtomicAddSubTasks(subTasks, tc.TaskID)
		t.Logf("ğŸ“Š [Template] ç”Ÿæˆ %d ä¸ªå¹¶è¡Œå­ä»»åŠ¡", len(subTasks))

		return map[string]interface{}{"generated": len(subTasks)}, nil
	}
	registry.Register(ctx, "templateFunc", templateFunc, "æ¨¡æ¿ä»»åŠ¡")

	// å­ä»»åŠ¡ (index=3 å’Œ index=7 å¤±è´¥)
	parallelSubFunc := func(tc *task.TaskContext) (interface{}, error) {
		index, _ := tc.GetParamInt("index")

		// æ¨¡æ‹Ÿéƒ¨åˆ†å¤±è´¥
		if index == 3 || index == 7 {
			return nil, fmt.Errorf("å­ä»»åŠ¡ %d æ¨¡æ‹Ÿå¤±è´¥", index)
		}

		return map[string]interface{}{
			"result": fmt.Sprintf("success_%d", index),
			"index":  index,
		}, nil
	}
	registry.Register(ctx, "parallelSubFunc", parallelSubFunc, "å¹¶è¡Œå­ä»»åŠ¡")

	// èšåˆä»»åŠ¡
	aggregateFunc := func(tc *task.TaskContext) (interface{}, error) {
		successResults := tc.GetSuccessfulSubTaskResults()
		failedResults := tc.GetFailedSubTaskResults()
		allSucceeded := tc.AllSubTasksSucceeded()
		subtaskCount := tc.GetSubTaskCount()

		t.Logf("ğŸ“Š [Aggregate] ç»“æœç»Ÿè®¡:")
		t.Logf("   - å­ä»»åŠ¡æ€»æ•°: %d", subtaskCount)
		t.Logf("   - æˆåŠŸ: %d", len(successResults))
		t.Logf("   - å¤±è´¥: %d", len(failedResults))
		t.Logf("   - å…¨éƒ¨æˆåŠŸ: %v", allSucceeded)

		// æ‰“å°å¤±è´¥è¯¦æƒ…
		for _, r := range failedResults {
			t.Logf("   - å¤±è´¥ä»»åŠ¡: %s, é”™è¯¯: %s", r.TaskName, r.Error)
		}

		capturedMutex.Lock()
		capturedSuccessCount = len(successResults)
		capturedFailedCount = len(failedResults)
		capturedSubTaskCount = subtaskCount
		capturedAllSucceeded = allSucceeded
		capturedMutex.Unlock()

		return map[string]interface{}{
			"success_count": len(successResults),
			"failed_count":  len(failedResults),
		}, nil
	}
	registry.Register(ctx, "aggregateFunc", aggregateFunc, "èšåˆä»»åŠ¡")

	// æ„å»º Workflow
	wf := workflow.NewWorkflow("parallel-subtasks-test", "å¹¶è¡Œå­ä»»åŠ¡æµ‹è¯•")

	task1, _ := builder.NewTaskBuilder("ParallelTemplate", "å¹¶è¡Œæ¨¡æ¿ä»»åŠ¡", registry).
		WithJobFunction("templateFunc", nil).
		WithTemplate(true).
		Build()

	task2, _ := builder.NewTaskBuilder("Aggregate", "èšåˆç»“æœ", registry).
		WithJobFunction("aggregateFunc", nil).
		WithDependency("ParallelTemplate").
		Build()

	wf.AddTask(task1)
	wf.AddTask(task2)

	// æ‰§è¡Œ
	controller, _ := eng.SubmitWorkflow(ctx, wf)

	// ç­‰å¾…å®Œæˆ
	deadline := time.Now().Add(60 * time.Second)
	ticker := time.NewTicker(500 * time.Millisecond)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			if time.Now().After(deadline) {
				t.Fatalf("Workflow æ‰§è¡Œè¶…æ—¶")
			}

			status, _ := controller.GetStatus()
			if status == "Success" || status == "Failed" {
				t.Logf("ğŸ“Š Workflow å®Œæˆï¼ŒçŠ¶æ€: %s", status)
				goto verify
			}
		}
	}

verify:
	capturedMutex.Lock()
	defer capturedMutex.Unlock()

	// éªŒè¯ç»“æœ
	if capturedSubTaskCount != 10 {
		t.Errorf("æœŸæœ› 10 ä¸ªå­ä»»åŠ¡ï¼Œå®é™… %d ä¸ª", capturedSubTaskCount)
	}

	if capturedSuccessCount != 8 {
		t.Errorf("æœŸæœ› 8 ä¸ªæˆåŠŸå­ä»»åŠ¡ï¼Œå®é™… %d ä¸ª", capturedSuccessCount)
	}

	if capturedFailedCount != 2 {
		t.Errorf("æœŸæœ› 2 ä¸ªå¤±è´¥å­ä»»åŠ¡ï¼Œå®é™… %d ä¸ª", capturedFailedCount)
	}

	if capturedAllSucceeded {
		t.Error("æœŸæœ› AllSubTasksSucceeded=falseï¼Œå®é™…ä¸º true")
	}

	t.Log("âœ… E2E æµ‹è¯•é€šè¿‡ï¼šå¹¶è¡Œå­ä»»åŠ¡ç»“æœèšåˆ")
}
